// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/predict.proto

#include "tensorflow_serving/apis/predict.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG

namespace _pb = ::PROTOBUF_NAMESPACE_ID;
namespace _pbi = _pb::internal;

namespace tensorflow {
namespace serving {
PROTOBUF_CONSTEXPR PredictRequest_InputsEntry_DoNotUse::PredictRequest_InputsEntry_DoNotUse(
    ::_pbi::ConstantInitialized) {}
struct PredictRequest_InputsEntry_DoNotUseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PredictRequest_InputsEntry_DoNotUseDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~PredictRequest_InputsEntry_DoNotUseDefaultTypeInternal() {}
  union {
    PredictRequest_InputsEntry_DoNotUse _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PredictRequest_InputsEntry_DoNotUseDefaultTypeInternal _PredictRequest_InputsEntry_DoNotUse_default_instance_;
PROTOBUF_CONSTEXPR PredictRequest_RequestOptions::PredictRequest_RequestOptions(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_._has_bits_)*/{}
  , /*decltype(_impl_._cached_size_)*/{}
  , /*decltype(_impl_.client_id_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.deterministic_mode_)*/0} {}
struct PredictRequest_RequestOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PredictRequest_RequestOptionsDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~PredictRequest_RequestOptionsDefaultTypeInternal() {}
  union {
    PredictRequest_RequestOptions _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PredictRequest_RequestOptionsDefaultTypeInternal _PredictRequest_RequestOptions_default_instance_;
PROTOBUF_CONSTEXPR PredictRequest::PredictRequest(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_._has_bits_)*/{}
  , /*decltype(_impl_._cached_size_)*/{}
  , /*decltype(_impl_.inputs_)*/{::_pbi::ConstantInitialized()}
  , /*decltype(_impl_.output_filter_)*/{}
  , /*decltype(_impl_.client_id_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.model_spec_)*/nullptr
  , /*decltype(_impl_.predict_streamed_options_)*/nullptr
  , /*decltype(_impl_.request_options_)*/nullptr} {}
struct PredictRequestDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PredictRequestDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~PredictRequestDefaultTypeInternal() {}
  union {
    PredictRequest _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PredictRequestDefaultTypeInternal _PredictRequest_default_instance_;
PROTOBUF_CONSTEXPR PredictStreamedOptions_SplitDimensionsEntry_DoNotUse::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse(
    ::_pbi::ConstantInitialized) {}
struct PredictStreamedOptions_SplitDimensionsEntry_DoNotUseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PredictStreamedOptions_SplitDimensionsEntry_DoNotUseDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~PredictStreamedOptions_SplitDimensionsEntry_DoNotUseDefaultTypeInternal() {}
  union {
    PredictStreamedOptions_SplitDimensionsEntry_DoNotUse _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PredictStreamedOptions_SplitDimensionsEntry_DoNotUseDefaultTypeInternal _PredictStreamedOptions_SplitDimensionsEntry_DoNotUse_default_instance_;
PROTOBUF_CONSTEXPR PredictStreamedOptions::PredictStreamedOptions(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.split_dimensions_)*/{::_pbi::ConstantInitialized()}
  , /*decltype(_impl_.request_state_)*/0
  , /*decltype(_impl_.return_single_response_)*/false
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct PredictStreamedOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PredictStreamedOptionsDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~PredictStreamedOptionsDefaultTypeInternal() {}
  union {
    PredictStreamedOptions _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PredictStreamedOptionsDefaultTypeInternal _PredictStreamedOptions_default_instance_;
PROTOBUF_CONSTEXPR PredictResponse_OutputsEntry_DoNotUse::PredictResponse_OutputsEntry_DoNotUse(
    ::_pbi::ConstantInitialized) {}
struct PredictResponse_OutputsEntry_DoNotUseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PredictResponse_OutputsEntry_DoNotUseDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~PredictResponse_OutputsEntry_DoNotUseDefaultTypeInternal() {}
  union {
    PredictResponse_OutputsEntry_DoNotUse _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PredictResponse_OutputsEntry_DoNotUseDefaultTypeInternal _PredictResponse_OutputsEntry_DoNotUse_default_instance_;
PROTOBUF_CONSTEXPR PredictResponse::PredictResponse(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.outputs_)*/{::_pbi::ConstantInitialized()}
  , /*decltype(_impl_.model_spec_)*/nullptr
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct PredictResponseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PredictResponseDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~PredictResponseDefaultTypeInternal() {}
  union {
    PredictResponse _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PredictResponseDefaultTypeInternal _PredictResponse_default_instance_;
}  // namespace serving
}  // namespace tensorflow
static ::_pb::Metadata file_level_metadata_tensorflow_5fserving_2fapis_2fpredict_2eproto[7];
static const ::_pb::EnumDescriptor* file_level_enum_descriptors_tensorflow_5fserving_2fapis_2fpredict_2eproto[2];
static constexpr ::_pb::ServiceDescriptor const** file_level_service_descriptors_tensorflow_5fserving_2fapis_2fpredict_2eproto = nullptr;

const uint32_t TableStruct_tensorflow_5fserving_2fapis_2fpredict_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest_InputsEntry_DoNotUse, _has_bits_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest_InputsEntry_DoNotUse, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest_InputsEntry_DoNotUse, key_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest_InputsEntry_DoNotUse, value_),
  0,
  1,
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest_RequestOptions, _impl_._has_bits_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest_RequestOptions, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest_RequestOptions, _impl_.client_id_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest_RequestOptions, _impl_.deterministic_mode_),
  0,
  1,
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest, _impl_._has_bits_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest, _impl_.model_spec_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest, _impl_.inputs_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest, _impl_.output_filter_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest, _impl_.predict_streamed_options_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest, _impl_.client_id_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictRequest, _impl_.request_options_),
  ~0u,
  ~0u,
  ~0u,
  ~0u,
  0,
  1,
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse, _has_bits_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse, key_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse, value_),
  0,
  1,
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedOptions, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedOptions, _impl_.request_state_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedOptions, _impl_.split_dimensions_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedOptions, _impl_.return_single_response_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictResponse_OutputsEntry_DoNotUse, _has_bits_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictResponse_OutputsEntry_DoNotUse, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictResponse_OutputsEntry_DoNotUse, key_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictResponse_OutputsEntry_DoNotUse, value_),
  0,
  1,
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictResponse, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictResponse, _impl_.model_spec_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictResponse, _impl_.outputs_),
};
static const ::_pbi::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, 8, -1, sizeof(::tensorflow::serving::PredictRequest_InputsEntry_DoNotUse)},
  { 10, 18, -1, sizeof(::tensorflow::serving::PredictRequest_RequestOptions)},
  { 20, 32, -1, sizeof(::tensorflow::serving::PredictRequest)},
  { 38, 46, -1, sizeof(::tensorflow::serving::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse)},
  { 48, -1, -1, sizeof(::tensorflow::serving::PredictStreamedOptions)},
  { 57, 65, -1, sizeof(::tensorflow::serving::PredictResponse_OutputsEntry_DoNotUse)},
  { 67, -1, -1, sizeof(::tensorflow::serving::PredictResponse)},
};

static const ::_pb::Message* const file_default_instances[] = {
  &::tensorflow::serving::_PredictRequest_InputsEntry_DoNotUse_default_instance_._instance,
  &::tensorflow::serving::_PredictRequest_RequestOptions_default_instance_._instance,
  &::tensorflow::serving::_PredictRequest_default_instance_._instance,
  &::tensorflow::serving::_PredictStreamedOptions_SplitDimensionsEntry_DoNotUse_default_instance_._instance,
  &::tensorflow::serving::_PredictStreamedOptions_default_instance_._instance,
  &::tensorflow::serving::_PredictResponse_OutputsEntry_DoNotUse_default_instance_._instance,
  &::tensorflow::serving::_PredictResponse_default_instance_._instance,
};

const char descriptor_table_protodef_tensorflow_5fserving_2fapis_2fpredict_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n%tensorflow_serving/apis/predict.proto\022"
  "\022tensorflow.serving\032&tensorflow/core/fra"
  "mework/tensor.proto\032#tensorflow_serving/"
  "apis/model.proto\"\310\005\n\016PredictRequest\0221\n\nm"
  "odel_spec\030\001 \001(\0132\035.tensorflow.serving.Mod"
  "elSpec\022>\n\006inputs\030\002 \003(\0132..tensorflow.serv"
  "ing.PredictRequest.InputsEntry\022\025\n\routput"
  "_filter\030\003 \003(\t\022L\n\030predict_streamed_option"
  "s\030\005 \001(\0132*.tensorflow.serving.PredictStre"
  "amedOptions\022\026\n\tclient_id\030\006 \001(\014H\000\210\001\001\022O\n\017r"
  "equest_options\030\007 \001(\01321.tensorflow.servin"
  "g.PredictRequest.RequestOptionsH\001\210\001\001\032F\n\013"
  "InputsEntry\022\013\n\003key\030\001 \001(\t\022&\n\005value\030\002 \001(\0132"
  "\027.tensorflow.TensorProto:\0028\001\032\204\002\n\016Request"
  "Options\022\026\n\tclient_id\030\001 \001(\014H\000\210\001\001\022d\n\022deter"
  "ministic_mode\030\002 \001(\0162C.tensorflow.serving"
  ".PredictRequest.RequestOptions.Determini"
  "sticModeH\001\210\001\001\"O\n\021DeterministicMode\022\"\n\036DE"
  "TERMINISTIC_MODE_UNSPECIFIED\020\000\022\026\n\022FIXED_"
  "DECODER_SLOT\020\001B\014\n\n_client_idB\025\n\023_determi"
  "nistic_modeB\014\n\n_client_idB\022\n\020_request_op"
  "tionsJ\004\010\004\020\005\"\317\002\n\026PredictStreamedOptions\022N"
  "\n\rrequest_state\030\001 \001(\01627.tensorflow.servi"
  "ng.PredictStreamedOptions.RequestState\022Y"
  "\n\020split_dimensions\030\002 \003(\0132\?.tensorflow.se"
  "rving.PredictStreamedOptions.SplitDimens"
  "ionsEntry\022\036\n\026return_single_response\030\003 \001("
  "\010\0326\n\024SplitDimensionsEntry\022\013\n\003key\030\001 \001(\t\022\r"
  "\n\005value\030\002 \001(\005:\0028\001\"2\n\014RequestState\022\010\n\004NON"
  "E\020\000\022\t\n\005SPLIT\020\001\022\r\n\tEND_SPLIT\020\002\"\320\001\n\017Predic"
  "tResponse\0221\n\nmodel_spec\030\002 \001(\0132\035.tensorfl"
  "ow.serving.ModelSpec\022A\n\007outputs\030\001 \003(\01320."
  "tensorflow.serving.PredictResponse.Outpu"
  "tsEntry\032G\n\014OutputsEntry\022\013\n\003key\030\001 \001(\t\022&\n\005"
  "value\030\002 \001(\0132\027.tensorflow.TensorProto:\0028\001"
  "B\003\370\001\001b\006proto3"
  ;
static const ::_pbi::DescriptorTable* const descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_deps[2] = {
  &::descriptor_table_tensorflow_2fcore_2fframework_2ftensor_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fapis_2fmodel_2eproto,
};
static ::_pbi::once_flag descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_once;
const ::_pbi::DescriptorTable descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto = {
    false, false, 1413, descriptor_table_protodef_tensorflow_5fserving_2fapis_2fpredict_2eproto,
    "tensorflow_serving/apis/predict.proto",
    &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_once, descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_deps, 2, 7,
    schemas, file_default_instances, TableStruct_tensorflow_5fserving_2fapis_2fpredict_2eproto::offsets,
    file_level_metadata_tensorflow_5fserving_2fapis_2fpredict_2eproto, file_level_enum_descriptors_tensorflow_5fserving_2fapis_2fpredict_2eproto,
    file_level_service_descriptors_tensorflow_5fserving_2fapis_2fpredict_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::_pbi::DescriptorTable* descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_getter() {
  return &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::_pbi::AddDescriptorsRunner dynamic_init_dummy_tensorflow_5fserving_2fapis_2fpredict_2eproto(&descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto);
namespace tensorflow {
namespace serving {
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* PredictRequest_RequestOptions_DeterministicMode_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto);
  return file_level_enum_descriptors_tensorflow_5fserving_2fapis_2fpredict_2eproto[0];
}
bool PredictRequest_RequestOptions_DeterministicMode_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr PredictRequest_RequestOptions_DeterministicMode PredictRequest_RequestOptions::DETERMINISTIC_MODE_UNSPECIFIED;
constexpr PredictRequest_RequestOptions_DeterministicMode PredictRequest_RequestOptions::FIXED_DECODER_SLOT;
constexpr PredictRequest_RequestOptions_DeterministicMode PredictRequest_RequestOptions::DeterministicMode_MIN;
constexpr PredictRequest_RequestOptions_DeterministicMode PredictRequest_RequestOptions::DeterministicMode_MAX;
constexpr int PredictRequest_RequestOptions::DeterministicMode_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* PredictStreamedOptions_RequestState_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto);
  return file_level_enum_descriptors_tensorflow_5fserving_2fapis_2fpredict_2eproto[1];
}
bool PredictStreamedOptions_RequestState_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr PredictStreamedOptions_RequestState PredictStreamedOptions::NONE;
constexpr PredictStreamedOptions_RequestState PredictStreamedOptions::SPLIT;
constexpr PredictStreamedOptions_RequestState PredictStreamedOptions::END_SPLIT;
constexpr PredictStreamedOptions_RequestState PredictStreamedOptions::RequestState_MIN;
constexpr PredictStreamedOptions_RequestState PredictStreamedOptions::RequestState_MAX;
constexpr int PredictStreamedOptions::RequestState_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

// ===================================================================

PredictRequest_InputsEntry_DoNotUse::PredictRequest_InputsEntry_DoNotUse() {}
PredictRequest_InputsEntry_DoNotUse::PredictRequest_InputsEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena)
    : SuperType(arena) {}
void PredictRequest_InputsEntry_DoNotUse::MergeFrom(const PredictRequest_InputsEntry_DoNotUse& other) {
  MergeFromInternal(other);
}
::PROTOBUF_NAMESPACE_ID::Metadata PredictRequest_InputsEntry_DoNotUse::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fpredict_2eproto[0]);
}

// ===================================================================

class PredictRequest_RequestOptions::_Internal {
 public:
  using HasBits = decltype(std::declval<PredictRequest_RequestOptions>()._impl_._has_bits_);
  static void set_has_client_id(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static void set_has_deterministic_mode(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
};

PredictRequest_RequestOptions::PredictRequest_RequestOptions(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictRequest.RequestOptions)
}
PredictRequest_RequestOptions::PredictRequest_RequestOptions(const PredictRequest_RequestOptions& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  PredictRequest_RequestOptions* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_._has_bits_){from._impl_._has_bits_}
    , /*decltype(_impl_._cached_size_)*/{}
    , decltype(_impl_.client_id_){}
    , decltype(_impl_.deterministic_mode_){}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.client_id_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.client_id_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (from._internal_has_client_id()) {
    _this->_impl_.client_id_.Set(from._internal_client_id(), 
      _this->GetArenaForAllocation());
  }
  _this->_impl_.deterministic_mode_ = from._impl_.deterministic_mode_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictRequest.RequestOptions)
}

inline void PredictRequest_RequestOptions::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_._has_bits_){}
    , /*decltype(_impl_._cached_size_)*/{}
    , decltype(_impl_.client_id_){}
    , decltype(_impl_.deterministic_mode_){0}
  };
  _impl_.client_id_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.client_id_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

PredictRequest_RequestOptions::~PredictRequest_RequestOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictRequest.RequestOptions)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void PredictRequest_RequestOptions::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.client_id_.Destroy();
}

void PredictRequest_RequestOptions::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void PredictRequest_RequestOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictRequest.RequestOptions)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    _impl_.client_id_.ClearNonDefaultToEmpty();
  }
  _impl_.deterministic_mode_ = 0;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* PredictRequest_RequestOptions::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  _Internal::HasBits has_bits{};
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // optional bytes client_id = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_client_id();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional .tensorflow.serving.PredictRequest.RequestOptions.DeterministicMode deterministic_mode = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_deterministic_mode(static_cast<::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode>(val));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  _impl_._has_bits_.Or(has_bits);
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* PredictRequest_RequestOptions::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictRequest.RequestOptions)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // optional bytes client_id = 1;
  if (_internal_has_client_id()) {
    target = stream->WriteBytesMaybeAliased(
        1, this->_internal_client_id(), target);
  }

  // optional .tensorflow.serving.PredictRequest.RequestOptions.DeterministicMode deterministic_mode = 2;
  if (_internal_has_deterministic_mode()) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      2, this->_internal_deterministic_mode(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictRequest.RequestOptions)
  return target;
}

size_t PredictRequest_RequestOptions::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictRequest.RequestOptions)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    // optional bytes client_id = 1;
    if (cached_has_bits & 0x00000001u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::BytesSize(
          this->_internal_client_id());
    }

    // optional .tensorflow.serving.PredictRequest.RequestOptions.DeterministicMode deterministic_mode = 2;
    if (cached_has_bits & 0x00000002u) {
      total_size += 1 +
        ::_pbi::WireFormatLite::EnumSize(this->_internal_deterministic_mode());
    }

  }
  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData PredictRequest_RequestOptions::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    PredictRequest_RequestOptions::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*PredictRequest_RequestOptions::GetClassData() const { return &_class_data_; }


void PredictRequest_RequestOptions::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<PredictRequest_RequestOptions*>(&to_msg);
  auto& from = static_cast<const PredictRequest_RequestOptions&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictRequest.RequestOptions)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      _this->_internal_set_client_id(from._internal_client_id());
    }
    if (cached_has_bits & 0x00000002u) {
      _this->_impl_.deterministic_mode_ = from._impl_.deterministic_mode_;
    }
    _this->_impl_._has_bits_[0] |= cached_has_bits;
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void PredictRequest_RequestOptions::CopyFrom(const PredictRequest_RequestOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictRequest.RequestOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictRequest_RequestOptions::IsInitialized() const {
  return true;
}

void PredictRequest_RequestOptions::InternalSwap(PredictRequest_RequestOptions* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.client_id_, lhs_arena,
      &other->_impl_.client_id_, rhs_arena
  );
  swap(_impl_.deterministic_mode_, other->_impl_.deterministic_mode_);
}

::PROTOBUF_NAMESPACE_ID::Metadata PredictRequest_RequestOptions::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fpredict_2eproto[1]);
}

// ===================================================================

class PredictRequest::_Internal {
 public:
  using HasBits = decltype(std::declval<PredictRequest>()._impl_._has_bits_);
  static const ::tensorflow::serving::ModelSpec& model_spec(const PredictRequest* msg);
  static const ::tensorflow::serving::PredictStreamedOptions& predict_streamed_options(const PredictRequest* msg);
  static void set_has_client_id(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static const ::tensorflow::serving::PredictRequest_RequestOptions& request_options(const PredictRequest* msg);
  static void set_has_request_options(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
};

const ::tensorflow::serving::ModelSpec&
PredictRequest::_Internal::model_spec(const PredictRequest* msg) {
  return *msg->_impl_.model_spec_;
}
const ::tensorflow::serving::PredictStreamedOptions&
PredictRequest::_Internal::predict_streamed_options(const PredictRequest* msg) {
  return *msg->_impl_.predict_streamed_options_;
}
const ::tensorflow::serving::PredictRequest_RequestOptions&
PredictRequest::_Internal::request_options(const PredictRequest* msg) {
  return *msg->_impl_.request_options_;
}
void PredictRequest::clear_model_spec() {
  if (GetArenaForAllocation() == nullptr && _impl_.model_spec_ != nullptr) {
    delete _impl_.model_spec_;
  }
  _impl_.model_spec_ = nullptr;
}
void PredictRequest::clear_inputs() {
  _impl_.inputs_.Clear();
}
PredictRequest::PredictRequest(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  if (arena != nullptr && !is_message_owned) {
    arena->OwnCustomDestructor(this, &PredictRequest::ArenaDtor);
  }
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictRequest)
}
PredictRequest::PredictRequest(const PredictRequest& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  PredictRequest* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_._has_bits_){from._impl_._has_bits_}
    , /*decltype(_impl_._cached_size_)*/{}
    , /*decltype(_impl_.inputs_)*/{}
    , decltype(_impl_.output_filter_){from._impl_.output_filter_}
    , decltype(_impl_.client_id_){}
    , decltype(_impl_.model_spec_){nullptr}
    , decltype(_impl_.predict_streamed_options_){nullptr}
    , decltype(_impl_.request_options_){nullptr}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _this->_impl_.inputs_.MergeFrom(from._impl_.inputs_);
  _impl_.client_id_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.client_id_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (from._internal_has_client_id()) {
    _this->_impl_.client_id_.Set(from._internal_client_id(), 
      _this->GetArenaForAllocation());
  }
  if (from._internal_has_model_spec()) {
    _this->_impl_.model_spec_ = new ::tensorflow::serving::ModelSpec(*from._impl_.model_spec_);
  }
  if (from._internal_has_predict_streamed_options()) {
    _this->_impl_.predict_streamed_options_ = new ::tensorflow::serving::PredictStreamedOptions(*from._impl_.predict_streamed_options_);
  }
  if (from._internal_has_request_options()) {
    _this->_impl_.request_options_ = new ::tensorflow::serving::PredictRequest_RequestOptions(*from._impl_.request_options_);
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictRequest)
}

inline void PredictRequest::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_._has_bits_){}
    , /*decltype(_impl_._cached_size_)*/{}
    , /*decltype(_impl_.inputs_)*/{::_pbi::ArenaInitialized(), arena}
    , decltype(_impl_.output_filter_){arena}
    , decltype(_impl_.client_id_){}
    , decltype(_impl_.model_spec_){nullptr}
    , decltype(_impl_.predict_streamed_options_){nullptr}
    , decltype(_impl_.request_options_){nullptr}
  };
  _impl_.client_id_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.client_id_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

PredictRequest::~PredictRequest() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictRequest)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    ArenaDtor(this);
    return;
  }
  SharedDtor();
}

inline void PredictRequest::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.inputs_.Destruct();
  _impl_.inputs_.~MapField();
  _impl_.output_filter_.~RepeatedPtrField();
  _impl_.client_id_.Destroy();
  if (this != internal_default_instance()) delete _impl_.model_spec_;
  if (this != internal_default_instance()) delete _impl_.predict_streamed_options_;
  if (this != internal_default_instance()) delete _impl_.request_options_;
}

void PredictRequest::ArenaDtor(void* object) {
  PredictRequest* _this = reinterpret_cast< PredictRequest* >(object);
  _this->_impl_.inputs_.Destruct();
}
void PredictRequest::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void PredictRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictRequest)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.inputs_.Clear();
  _impl_.output_filter_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    _impl_.client_id_.ClearNonDefaultToEmpty();
  }
  if (GetArenaForAllocation() == nullptr && _impl_.model_spec_ != nullptr) {
    delete _impl_.model_spec_;
  }
  _impl_.model_spec_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.predict_streamed_options_ != nullptr) {
    delete _impl_.predict_streamed_options_;
  }
  _impl_.predict_streamed_options_ = nullptr;
  if (cached_has_bits & 0x00000002u) {
    GOOGLE_DCHECK(_impl_.request_options_ != nullptr);
    _impl_.request_options_->Clear();
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* PredictRequest::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  _Internal::HasBits has_bits{};
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.serving.ModelSpec model_spec = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_model_spec(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // map<string, .tensorflow.TensorProto> inputs = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(&_impl_.inputs_, ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<18>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated string output_filter = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr -= 1;
          do {
            ptr += 1;
            auto str = _internal_add_output_filter();
            ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
            CHK_(ptr);
            CHK_(::_pbi::VerifyUTF8(str, "tensorflow.serving.PredictRequest.output_filter"));
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<26>(ptr));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.PredictStreamedOptions predict_streamed_options = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 42)) {
          ptr = ctx->ParseMessage(_internal_mutable_predict_streamed_options(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional bytes client_id = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 50)) {
          auto str = _internal_mutable_client_id();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional .tensorflow.serving.PredictRequest.RequestOptions request_options = 7;
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 58)) {
          ptr = ctx->ParseMessage(_internal_mutable_request_options(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  _impl_._has_bits_.Or(has_bits);
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* PredictRequest::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictRequest)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->_internal_has_model_spec()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, _Internal::model_spec(this),
        _Internal::model_spec(this).GetCachedSize(), target, stream);
  }

  // map<string, .tensorflow.TensorProto> inputs = 2;
  if (!this->_internal_inputs().empty()) {
    using MapType = ::_pb::Map<std::string, ::tensorflow::TensorProto>;
    using WireHelper = PredictRequest_InputsEntry_DoNotUse::Funcs;
    const auto& map_field = this->_internal_inputs();
    auto check_utf8 = [](const MapType::value_type& entry) {
      (void)entry;
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
        entry.first.data(), static_cast<int>(entry.first.length()),
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
        "tensorflow.serving.PredictRequest.InputsEntry.key");
    };

    if (stream->IsSerializationDeterministic() && map_field.size() > 1) {
      for (const auto& entry : ::_pbi::MapSorterPtr<MapType>(map_field)) {
        target = WireHelper::InternalSerialize(2, entry.first, entry.second, target, stream);
        check_utf8(entry);
      }
    } else {
      for (const auto& entry : map_field) {
        target = WireHelper::InternalSerialize(2, entry.first, entry.second, target, stream);
        check_utf8(entry);
      }
    }
  }

  // repeated string output_filter = 3;
  for (int i = 0, n = this->_internal_output_filter_size(); i < n; i++) {
    const auto& s = this->_internal_output_filter(i);
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      s.data(), static_cast<int>(s.length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.PredictRequest.output_filter");
    target = stream->WriteString(3, s, target);
  }

  // .tensorflow.serving.PredictStreamedOptions predict_streamed_options = 5;
  if (this->_internal_has_predict_streamed_options()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(5, _Internal::predict_streamed_options(this),
        _Internal::predict_streamed_options(this).GetCachedSize(), target, stream);
  }

  // optional bytes client_id = 6;
  if (_internal_has_client_id()) {
    target = stream->WriteBytesMaybeAliased(
        6, this->_internal_client_id(), target);
  }

  // optional .tensorflow.serving.PredictRequest.RequestOptions request_options = 7;
  if (_internal_has_request_options()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(7, _Internal::request_options(this),
        _Internal::request_options(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictRequest)
  return target;
}

size_t PredictRequest::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictRequest)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // map<string, .tensorflow.TensorProto> inputs = 2;
  total_size += 1 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(this->_internal_inputs_size());
  for (::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >::const_iterator
      it = this->_internal_inputs().begin();
      it != this->_internal_inputs().end(); ++it) {
    total_size += PredictRequest_InputsEntry_DoNotUse::Funcs::ByteSizeLong(it->first, it->second);
  }

  // repeated string output_filter = 3;
  total_size += 1 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(_impl_.output_filter_.size());
  for (int i = 0, n = _impl_.output_filter_.size(); i < n; i++) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
      _impl_.output_filter_.Get(i));
  }

  // optional bytes client_id = 6;
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::BytesSize(
        this->_internal_client_id());
  }

  // .tensorflow.serving.ModelSpec model_spec = 1;
  if (this->_internal_has_model_spec()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.model_spec_);
  }

  // .tensorflow.serving.PredictStreamedOptions predict_streamed_options = 5;
  if (this->_internal_has_predict_streamed_options()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.predict_streamed_options_);
  }

  // optional .tensorflow.serving.PredictRequest.RequestOptions request_options = 7;
  if (cached_has_bits & 0x00000002u) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.request_options_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData PredictRequest::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    PredictRequest::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*PredictRequest::GetClassData() const { return &_class_data_; }


void PredictRequest::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<PredictRequest*>(&to_msg);
  auto& from = static_cast<const PredictRequest&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictRequest)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.inputs_.MergeFrom(from._impl_.inputs_);
  _this->_impl_.output_filter_.MergeFrom(from._impl_.output_filter_);
  if (from._internal_has_client_id()) {
    _this->_internal_set_client_id(from._internal_client_id());
  }
  if (from._internal_has_model_spec()) {
    _this->_internal_mutable_model_spec()->::tensorflow::serving::ModelSpec::MergeFrom(
        from._internal_model_spec());
  }
  if (from._internal_has_predict_streamed_options()) {
    _this->_internal_mutable_predict_streamed_options()->::tensorflow::serving::PredictStreamedOptions::MergeFrom(
        from._internal_predict_streamed_options());
  }
  if (from._internal_has_request_options()) {
    _this->_internal_mutable_request_options()->::tensorflow::serving::PredictRequest_RequestOptions::MergeFrom(
        from._internal_request_options());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void PredictRequest::CopyFrom(const PredictRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictRequest::IsInitialized() const {
  return true;
}

void PredictRequest::InternalSwap(PredictRequest* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.inputs_.InternalSwap(&other->_impl_.inputs_);
  _impl_.output_filter_.InternalSwap(&other->_impl_.output_filter_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.client_id_, lhs_arena,
      &other->_impl_.client_id_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(PredictRequest, _impl_.request_options_)
      + sizeof(PredictRequest::_impl_.request_options_)
      - PROTOBUF_FIELD_OFFSET(PredictRequest, _impl_.model_spec_)>(
          reinterpret_cast<char*>(&_impl_.model_spec_),
          reinterpret_cast<char*>(&other->_impl_.model_spec_));
}

::PROTOBUF_NAMESPACE_ID::Metadata PredictRequest::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fpredict_2eproto[2]);
}

// ===================================================================

PredictStreamedOptions_SplitDimensionsEntry_DoNotUse::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse() {}
PredictStreamedOptions_SplitDimensionsEntry_DoNotUse::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena)
    : SuperType(arena) {}
void PredictStreamedOptions_SplitDimensionsEntry_DoNotUse::MergeFrom(const PredictStreamedOptions_SplitDimensionsEntry_DoNotUse& other) {
  MergeFromInternal(other);
}
::PROTOBUF_NAMESPACE_ID::Metadata PredictStreamedOptions_SplitDimensionsEntry_DoNotUse::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fpredict_2eproto[3]);
}

// ===================================================================

class PredictStreamedOptions::_Internal {
 public:
};

PredictStreamedOptions::PredictStreamedOptions(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  if (arena != nullptr && !is_message_owned) {
    arena->OwnCustomDestructor(this, &PredictStreamedOptions::ArenaDtor);
  }
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictStreamedOptions)
}
PredictStreamedOptions::PredictStreamedOptions(const PredictStreamedOptions& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  PredictStreamedOptions* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      /*decltype(_impl_.split_dimensions_)*/{}
    , decltype(_impl_.request_state_){}
    , decltype(_impl_.return_single_response_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _this->_impl_.split_dimensions_.MergeFrom(from._impl_.split_dimensions_);
  ::memcpy(&_impl_.request_state_, &from._impl_.request_state_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.return_single_response_) -
    reinterpret_cast<char*>(&_impl_.request_state_)) + sizeof(_impl_.return_single_response_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictStreamedOptions)
}

inline void PredictStreamedOptions::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      /*decltype(_impl_.split_dimensions_)*/{::_pbi::ArenaInitialized(), arena}
    , decltype(_impl_.request_state_){0}
    , decltype(_impl_.return_single_response_){false}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

PredictStreamedOptions::~PredictStreamedOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictStreamedOptions)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    ArenaDtor(this);
    return;
  }
  SharedDtor();
}

inline void PredictStreamedOptions::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.split_dimensions_.Destruct();
  _impl_.split_dimensions_.~MapField();
}

void PredictStreamedOptions::ArenaDtor(void* object) {
  PredictStreamedOptions* _this = reinterpret_cast< PredictStreamedOptions* >(object);
  _this->_impl_.split_dimensions_.Destruct();
}
void PredictStreamedOptions::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void PredictStreamedOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictStreamedOptions)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.split_dimensions_.Clear();
  ::memset(&_impl_.request_state_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.return_single_response_) -
      reinterpret_cast<char*>(&_impl_.request_state_)) + sizeof(_impl_.return_single_response_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* PredictStreamedOptions::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.serving.PredictStreamedOptions.RequestState request_state = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_request_state(static_cast<::tensorflow::serving::PredictStreamedOptions_RequestState>(val));
        } else
          goto handle_unusual;
        continue;
      // map<string, int32> split_dimensions = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(&_impl_.split_dimensions_, ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<18>(ptr));
        } else
          goto handle_unusual;
        continue;
      // bool return_single_response = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.return_single_response_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* PredictStreamedOptions::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictStreamedOptions)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.PredictStreamedOptions.RequestState request_state = 1;
  if (this->_internal_request_state() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteEnumToArray(
      1, this->_internal_request_state(), target);
  }

  // map<string, int32> split_dimensions = 2;
  if (!this->_internal_split_dimensions().empty()) {
    using MapType = ::_pb::Map<std::string, int32_t>;
    using WireHelper = PredictStreamedOptions_SplitDimensionsEntry_DoNotUse::Funcs;
    const auto& map_field = this->_internal_split_dimensions();
    auto check_utf8 = [](const MapType::value_type& entry) {
      (void)entry;
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
        entry.first.data(), static_cast<int>(entry.first.length()),
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
        "tensorflow.serving.PredictStreamedOptions.SplitDimensionsEntry.key");
    };

    if (stream->IsSerializationDeterministic() && map_field.size() > 1) {
      for (const auto& entry : ::_pbi::MapSorterPtr<MapType>(map_field)) {
        target = WireHelper::InternalSerialize(2, entry.first, entry.second, target, stream);
        check_utf8(entry);
      }
    } else {
      for (const auto& entry : map_field) {
        target = WireHelper::InternalSerialize(2, entry.first, entry.second, target, stream);
        check_utf8(entry);
      }
    }
  }

  // bool return_single_response = 3;
  if (this->_internal_return_single_response() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteBoolToArray(3, this->_internal_return_single_response(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictStreamedOptions)
  return target;
}

size_t PredictStreamedOptions::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictStreamedOptions)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // map<string, int32> split_dimensions = 2;
  total_size += 1 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(this->_internal_split_dimensions_size());
  for (::PROTOBUF_NAMESPACE_ID::Map< std::string, int32_t >::const_iterator
      it = this->_internal_split_dimensions().begin();
      it != this->_internal_split_dimensions().end(); ++it) {
    total_size += PredictStreamedOptions_SplitDimensionsEntry_DoNotUse::Funcs::ByteSizeLong(it->first, it->second);
  }

  // .tensorflow.serving.PredictStreamedOptions.RequestState request_state = 1;
  if (this->_internal_request_state() != 0) {
    total_size += 1 +
      ::_pbi::WireFormatLite::EnumSize(this->_internal_request_state());
  }

  // bool return_single_response = 3;
  if (this->_internal_return_single_response() != 0) {
    total_size += 1 + 1;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData PredictStreamedOptions::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    PredictStreamedOptions::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*PredictStreamedOptions::GetClassData() const { return &_class_data_; }


void PredictStreamedOptions::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<PredictStreamedOptions*>(&to_msg);
  auto& from = static_cast<const PredictStreamedOptions&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictStreamedOptions)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.split_dimensions_.MergeFrom(from._impl_.split_dimensions_);
  if (from._internal_request_state() != 0) {
    _this->_internal_set_request_state(from._internal_request_state());
  }
  if (from._internal_return_single_response() != 0) {
    _this->_internal_set_return_single_response(from._internal_return_single_response());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void PredictStreamedOptions::CopyFrom(const PredictStreamedOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictStreamedOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictStreamedOptions::IsInitialized() const {
  return true;
}

void PredictStreamedOptions::InternalSwap(PredictStreamedOptions* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.split_dimensions_.InternalSwap(&other->_impl_.split_dimensions_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(PredictStreamedOptions, _impl_.return_single_response_)
      + sizeof(PredictStreamedOptions::_impl_.return_single_response_)
      - PROTOBUF_FIELD_OFFSET(PredictStreamedOptions, _impl_.request_state_)>(
          reinterpret_cast<char*>(&_impl_.request_state_),
          reinterpret_cast<char*>(&other->_impl_.request_state_));
}

::PROTOBUF_NAMESPACE_ID::Metadata PredictStreamedOptions::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fpredict_2eproto[4]);
}

// ===================================================================

PredictResponse_OutputsEntry_DoNotUse::PredictResponse_OutputsEntry_DoNotUse() {}
PredictResponse_OutputsEntry_DoNotUse::PredictResponse_OutputsEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena)
    : SuperType(arena) {}
void PredictResponse_OutputsEntry_DoNotUse::MergeFrom(const PredictResponse_OutputsEntry_DoNotUse& other) {
  MergeFromInternal(other);
}
::PROTOBUF_NAMESPACE_ID::Metadata PredictResponse_OutputsEntry_DoNotUse::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fpredict_2eproto[5]);
}

// ===================================================================

class PredictResponse::_Internal {
 public:
  static const ::tensorflow::serving::ModelSpec& model_spec(const PredictResponse* msg);
};

const ::tensorflow::serving::ModelSpec&
PredictResponse::_Internal::model_spec(const PredictResponse* msg) {
  return *msg->_impl_.model_spec_;
}
void PredictResponse::clear_model_spec() {
  if (GetArenaForAllocation() == nullptr && _impl_.model_spec_ != nullptr) {
    delete _impl_.model_spec_;
  }
  _impl_.model_spec_ = nullptr;
}
void PredictResponse::clear_outputs() {
  _impl_.outputs_.Clear();
}
PredictResponse::PredictResponse(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  if (arena != nullptr && !is_message_owned) {
    arena->OwnCustomDestructor(this, &PredictResponse::ArenaDtor);
  }
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictResponse)
}
PredictResponse::PredictResponse(const PredictResponse& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  PredictResponse* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      /*decltype(_impl_.outputs_)*/{}
    , decltype(_impl_.model_spec_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _this->_impl_.outputs_.MergeFrom(from._impl_.outputs_);
  if (from._internal_has_model_spec()) {
    _this->_impl_.model_spec_ = new ::tensorflow::serving::ModelSpec(*from._impl_.model_spec_);
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictResponse)
}

inline void PredictResponse::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      /*decltype(_impl_.outputs_)*/{::_pbi::ArenaInitialized(), arena}
    , decltype(_impl_.model_spec_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

PredictResponse::~PredictResponse() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictResponse)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    ArenaDtor(this);
    return;
  }
  SharedDtor();
}

inline void PredictResponse::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.outputs_.Destruct();
  _impl_.outputs_.~MapField();
  if (this != internal_default_instance()) delete _impl_.model_spec_;
}

void PredictResponse::ArenaDtor(void* object) {
  PredictResponse* _this = reinterpret_cast< PredictResponse* >(object);
  _this->_impl_.outputs_.Destruct();
}
void PredictResponse::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void PredictResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictResponse)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.outputs_.Clear();
  if (GetArenaForAllocation() == nullptr && _impl_.model_spec_ != nullptr) {
    delete _impl_.model_spec_;
  }
  _impl_.model_spec_ = nullptr;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* PredictResponse::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // map<string, .tensorflow.TensorProto> outputs = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(&_impl_.outputs_, ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<10>(ptr));
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.ModelSpec model_spec = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_model_spec(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* PredictResponse::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictResponse)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // map<string, .tensorflow.TensorProto> outputs = 1;
  if (!this->_internal_outputs().empty()) {
    using MapType = ::_pb::Map<std::string, ::tensorflow::TensorProto>;
    using WireHelper = PredictResponse_OutputsEntry_DoNotUse::Funcs;
    const auto& map_field = this->_internal_outputs();
    auto check_utf8 = [](const MapType::value_type& entry) {
      (void)entry;
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
        entry.first.data(), static_cast<int>(entry.first.length()),
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
        "tensorflow.serving.PredictResponse.OutputsEntry.key");
    };

    if (stream->IsSerializationDeterministic() && map_field.size() > 1) {
      for (const auto& entry : ::_pbi::MapSorterPtr<MapType>(map_field)) {
        target = WireHelper::InternalSerialize(1, entry.first, entry.second, target, stream);
        check_utf8(entry);
      }
    } else {
      for (const auto& entry : map_field) {
        target = WireHelper::InternalSerialize(1, entry.first, entry.second, target, stream);
        check_utf8(entry);
      }
    }
  }

  // .tensorflow.serving.ModelSpec model_spec = 2;
  if (this->_internal_has_model_spec()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::model_spec(this),
        _Internal::model_spec(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictResponse)
  return target;
}

size_t PredictResponse::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictResponse)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // map<string, .tensorflow.TensorProto> outputs = 1;
  total_size += 1 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(this->_internal_outputs_size());
  for (::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >::const_iterator
      it = this->_internal_outputs().begin();
      it != this->_internal_outputs().end(); ++it) {
    total_size += PredictResponse_OutputsEntry_DoNotUse::Funcs::ByteSizeLong(it->first, it->second);
  }

  // .tensorflow.serving.ModelSpec model_spec = 2;
  if (this->_internal_has_model_spec()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.model_spec_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData PredictResponse::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    PredictResponse::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*PredictResponse::GetClassData() const { return &_class_data_; }


void PredictResponse::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<PredictResponse*>(&to_msg);
  auto& from = static_cast<const PredictResponse&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictResponse)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.outputs_.MergeFrom(from._impl_.outputs_);
  if (from._internal_has_model_spec()) {
    _this->_internal_mutable_model_spec()->::tensorflow::serving::ModelSpec::MergeFrom(
        from._internal_model_spec());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void PredictResponse::CopyFrom(const PredictResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictResponse::IsInitialized() const {
  return true;
}

void PredictResponse::InternalSwap(PredictResponse* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.outputs_.InternalSwap(&other->_impl_.outputs_);
  swap(_impl_.model_spec_, other->_impl_.model_spec_);
}

::PROTOBUF_NAMESPACE_ID::Metadata PredictResponse::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fpredict_2eproto[6]);
}

// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictRequest_InputsEntry_DoNotUse*
Arena::CreateMaybeMessage< ::tensorflow::serving::PredictRequest_InputsEntry_DoNotUse >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictRequest_InputsEntry_DoNotUse >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictRequest_RequestOptions*
Arena::CreateMaybeMessage< ::tensorflow::serving::PredictRequest_RequestOptions >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictRequest_RequestOptions >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictRequest*
Arena::CreateMaybeMessage< ::tensorflow::serving::PredictRequest >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictRequest >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse*
Arena::CreateMaybeMessage< ::tensorflow::serving::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictStreamedOptions*
Arena::CreateMaybeMessage< ::tensorflow::serving::PredictStreamedOptions >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictStreamedOptions >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictResponse_OutputsEntry_DoNotUse*
Arena::CreateMaybeMessage< ::tensorflow::serving::PredictResponse_OutputsEntry_DoNotUse >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictResponse_OutputsEntry_DoNotUse >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictResponse*
Arena::CreateMaybeMessage< ::tensorflow::serving::PredictResponse >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictResponse >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
