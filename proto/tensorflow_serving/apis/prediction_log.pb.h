// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/prediction_log.proto

#ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto
#define GOOGLE_PROTOBUF_INCLUDED_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto

#include <limits>
#include <string>

#include <google/protobuf/port_def.inc>
#if PROTOBUF_VERSION < 3021000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers. Please update
#error your headers.
#endif
#if 3021012 < PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers. Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/port_undef.inc>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/metadata_lite.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/unknown_field_set.h>
#include "tensorflow_serving/apis/classification.pb.h"
#include "tensorflow_serving/apis/inference.pb.h"
#include "tensorflow_serving/apis/logging.pb.h"
#include "tensorflow_serving/apis/predict.pb.h"
#include "tensorflow_serving/apis/regression.pb.h"
#include "tensorflow_serving/apis/session_service.pb.h"
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
#define PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto
PROTOBUF_NAMESPACE_OPEN
namespace internal {
class AnyMetadata;
}  // namespace internal
PROTOBUF_NAMESPACE_CLOSE

// Internal implementation detail -- do not use these members.
struct TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto {
  static const uint32_t offsets[];
};
extern const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
namespace tensorflow {
namespace serving {
class ClassifyLog;
struct ClassifyLogDefaultTypeInternal;
extern ClassifyLogDefaultTypeInternal _ClassifyLog_default_instance_;
class MultiInferenceLog;
struct MultiInferenceLogDefaultTypeInternal;
extern MultiInferenceLogDefaultTypeInternal _MultiInferenceLog_default_instance_;
class PredictLog;
struct PredictLogDefaultTypeInternal;
extern PredictLogDefaultTypeInternal _PredictLog_default_instance_;
class PredictStreamedLog;
struct PredictStreamedLogDefaultTypeInternal;
extern PredictStreamedLogDefaultTypeInternal _PredictStreamedLog_default_instance_;
class PredictionLog;
struct PredictionLogDefaultTypeInternal;
extern PredictionLogDefaultTypeInternal _PredictionLog_default_instance_;
class RegressLog;
struct RegressLogDefaultTypeInternal;
extern RegressLogDefaultTypeInternal _RegressLog_default_instance_;
class SessionRunLog;
struct SessionRunLogDefaultTypeInternal;
extern SessionRunLogDefaultTypeInternal _SessionRunLog_default_instance_;
}  // namespace serving
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
template<> ::tensorflow::serving::ClassifyLog* Arena::CreateMaybeMessage<::tensorflow::serving::ClassifyLog>(Arena*);
template<> ::tensorflow::serving::MultiInferenceLog* Arena::CreateMaybeMessage<::tensorflow::serving::MultiInferenceLog>(Arena*);
template<> ::tensorflow::serving::PredictLog* Arena::CreateMaybeMessage<::tensorflow::serving::PredictLog>(Arena*);
template<> ::tensorflow::serving::PredictStreamedLog* Arena::CreateMaybeMessage<::tensorflow::serving::PredictStreamedLog>(Arena*);
template<> ::tensorflow::serving::PredictionLog* Arena::CreateMaybeMessage<::tensorflow::serving::PredictionLog>(Arena*);
template<> ::tensorflow::serving::RegressLog* Arena::CreateMaybeMessage<::tensorflow::serving::RegressLog>(Arena*);
template<> ::tensorflow::serving::SessionRunLog* Arena::CreateMaybeMessage<::tensorflow::serving::SessionRunLog>(Arena*);
PROTOBUF_NAMESPACE_CLOSE
namespace tensorflow {
namespace serving {

// ===================================================================

class ClassifyLog final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.ClassifyLog) */ {
 public:
  inline ClassifyLog() : ClassifyLog(nullptr) {}
  ~ClassifyLog() override;
  explicit PROTOBUF_CONSTEXPR ClassifyLog(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  ClassifyLog(const ClassifyLog& from);
  ClassifyLog(ClassifyLog&& from) noexcept
    : ClassifyLog() {
    *this = ::std::move(from);
  }

  inline ClassifyLog& operator=(const ClassifyLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline ClassifyLog& operator=(ClassifyLog&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const ClassifyLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const ClassifyLog* internal_default_instance() {
    return reinterpret_cast<const ClassifyLog*>(
               &_ClassifyLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  friend void swap(ClassifyLog& a, ClassifyLog& b) {
    a.Swap(&b);
  }
  inline void Swap(ClassifyLog* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(ClassifyLog* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  ClassifyLog* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<ClassifyLog>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const ClassifyLog& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const ClassifyLog& from) {
    ClassifyLog::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ClassifyLog* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.ClassifyLog";
  }
  protected:
  explicit ClassifyLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // .tensorflow.serving.ClassificationRequest request = 1;
  bool has_request() const;
  private:
  bool _internal_has_request() const;
  public:
  void clear_request();
  const ::tensorflow::serving::ClassificationRequest& request() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::ClassificationRequest* release_request();
  ::tensorflow::serving::ClassificationRequest* mutable_request();
  void set_allocated_request(::tensorflow::serving::ClassificationRequest* request);
  private:
  const ::tensorflow::serving::ClassificationRequest& _internal_request() const;
  ::tensorflow::serving::ClassificationRequest* _internal_mutable_request();
  public:
  void unsafe_arena_set_allocated_request(
      ::tensorflow::serving::ClassificationRequest* request);
  ::tensorflow::serving::ClassificationRequest* unsafe_arena_release_request();

  // .tensorflow.serving.ClassificationResponse response = 2;
  bool has_response() const;
  private:
  bool _internal_has_response() const;
  public:
  void clear_response();
  const ::tensorflow::serving::ClassificationResponse& response() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::ClassificationResponse* release_response();
  ::tensorflow::serving::ClassificationResponse* mutable_response();
  void set_allocated_response(::tensorflow::serving::ClassificationResponse* response);
  private:
  const ::tensorflow::serving::ClassificationResponse& _internal_response() const;
  ::tensorflow::serving::ClassificationResponse* _internal_mutable_response();
  public:
  void unsafe_arena_set_allocated_response(
      ::tensorflow::serving::ClassificationResponse* response);
  ::tensorflow::serving::ClassificationResponse* unsafe_arena_release_response();

  // @@protoc_insertion_point(class_scope:tensorflow.serving.ClassifyLog)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::tensorflow::serving::ClassificationRequest* request_;
    ::tensorflow::serving::ClassificationResponse* response_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class RegressLog final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.RegressLog) */ {
 public:
  inline RegressLog() : RegressLog(nullptr) {}
  ~RegressLog() override;
  explicit PROTOBUF_CONSTEXPR RegressLog(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  RegressLog(const RegressLog& from);
  RegressLog(RegressLog&& from) noexcept
    : RegressLog() {
    *this = ::std::move(from);
  }

  inline RegressLog& operator=(const RegressLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline RegressLog& operator=(RegressLog&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const RegressLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const RegressLog* internal_default_instance() {
    return reinterpret_cast<const RegressLog*>(
               &_RegressLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  friend void swap(RegressLog& a, RegressLog& b) {
    a.Swap(&b);
  }
  inline void Swap(RegressLog* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(RegressLog* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  RegressLog* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<RegressLog>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const RegressLog& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const RegressLog& from) {
    RegressLog::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(RegressLog* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.RegressLog";
  }
  protected:
  explicit RegressLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // .tensorflow.serving.RegressionRequest request = 1;
  bool has_request() const;
  private:
  bool _internal_has_request() const;
  public:
  void clear_request();
  const ::tensorflow::serving::RegressionRequest& request() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::RegressionRequest* release_request();
  ::tensorflow::serving::RegressionRequest* mutable_request();
  void set_allocated_request(::tensorflow::serving::RegressionRequest* request);
  private:
  const ::tensorflow::serving::RegressionRequest& _internal_request() const;
  ::tensorflow::serving::RegressionRequest* _internal_mutable_request();
  public:
  void unsafe_arena_set_allocated_request(
      ::tensorflow::serving::RegressionRequest* request);
  ::tensorflow::serving::RegressionRequest* unsafe_arena_release_request();

  // .tensorflow.serving.RegressionResponse response = 2;
  bool has_response() const;
  private:
  bool _internal_has_response() const;
  public:
  void clear_response();
  const ::tensorflow::serving::RegressionResponse& response() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::RegressionResponse* release_response();
  ::tensorflow::serving::RegressionResponse* mutable_response();
  void set_allocated_response(::tensorflow::serving::RegressionResponse* response);
  private:
  const ::tensorflow::serving::RegressionResponse& _internal_response() const;
  ::tensorflow::serving::RegressionResponse* _internal_mutable_response();
  public:
  void unsafe_arena_set_allocated_response(
      ::tensorflow::serving::RegressionResponse* response);
  ::tensorflow::serving::RegressionResponse* unsafe_arena_release_response();

  // @@protoc_insertion_point(class_scope:tensorflow.serving.RegressLog)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::tensorflow::serving::RegressionRequest* request_;
    ::tensorflow::serving::RegressionResponse* response_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class PredictLog final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.PredictLog) */ {
 public:
  inline PredictLog() : PredictLog(nullptr) {}
  ~PredictLog() override;
  explicit PROTOBUF_CONSTEXPR PredictLog(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  PredictLog(const PredictLog& from);
  PredictLog(PredictLog&& from) noexcept
    : PredictLog() {
    *this = ::std::move(from);
  }

  inline PredictLog& operator=(const PredictLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline PredictLog& operator=(PredictLog&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const PredictLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const PredictLog* internal_default_instance() {
    return reinterpret_cast<const PredictLog*>(
               &_PredictLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  friend void swap(PredictLog& a, PredictLog& b) {
    a.Swap(&b);
  }
  inline void Swap(PredictLog* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(PredictLog* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  PredictLog* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<PredictLog>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const PredictLog& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const PredictLog& from) {
    PredictLog::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(PredictLog* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.PredictLog";
  }
  protected:
  explicit PredictLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // .tensorflow.serving.PredictRequest request = 1;
  bool has_request() const;
  private:
  bool _internal_has_request() const;
  public:
  void clear_request();
  const ::tensorflow::serving::PredictRequest& request() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::PredictRequest* release_request();
  ::tensorflow::serving::PredictRequest* mutable_request();
  void set_allocated_request(::tensorflow::serving::PredictRequest* request);
  private:
  const ::tensorflow::serving::PredictRequest& _internal_request() const;
  ::tensorflow::serving::PredictRequest* _internal_mutable_request();
  public:
  void unsafe_arena_set_allocated_request(
      ::tensorflow::serving::PredictRequest* request);
  ::tensorflow::serving::PredictRequest* unsafe_arena_release_request();

  // .tensorflow.serving.PredictResponse response = 2;
  bool has_response() const;
  private:
  bool _internal_has_response() const;
  public:
  void clear_response();
  const ::tensorflow::serving::PredictResponse& response() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::PredictResponse* release_response();
  ::tensorflow::serving::PredictResponse* mutable_response();
  void set_allocated_response(::tensorflow::serving::PredictResponse* response);
  private:
  const ::tensorflow::serving::PredictResponse& _internal_response() const;
  ::tensorflow::serving::PredictResponse* _internal_mutable_response();
  public:
  void unsafe_arena_set_allocated_response(
      ::tensorflow::serving::PredictResponse* response);
  ::tensorflow::serving::PredictResponse* unsafe_arena_release_response();

  // @@protoc_insertion_point(class_scope:tensorflow.serving.PredictLog)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::tensorflow::serving::PredictRequest* request_;
    ::tensorflow::serving::PredictResponse* response_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class PredictStreamedLog final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.PredictStreamedLog) */ {
 public:
  inline PredictStreamedLog() : PredictStreamedLog(nullptr) {}
  ~PredictStreamedLog() override;
  explicit PROTOBUF_CONSTEXPR PredictStreamedLog(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  PredictStreamedLog(const PredictStreamedLog& from);
  PredictStreamedLog(PredictStreamedLog&& from) noexcept
    : PredictStreamedLog() {
    *this = ::std::move(from);
  }

  inline PredictStreamedLog& operator=(const PredictStreamedLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline PredictStreamedLog& operator=(PredictStreamedLog&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const PredictStreamedLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const PredictStreamedLog* internal_default_instance() {
    return reinterpret_cast<const PredictStreamedLog*>(
               &_PredictStreamedLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  friend void swap(PredictStreamedLog& a, PredictStreamedLog& b) {
    a.Swap(&b);
  }
  inline void Swap(PredictStreamedLog* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(PredictStreamedLog* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  PredictStreamedLog* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<PredictStreamedLog>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const PredictStreamedLog& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const PredictStreamedLog& from) {
    PredictStreamedLog::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(PredictStreamedLog* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.PredictStreamedLog";
  }
  protected:
  explicit PredictStreamedLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // repeated .tensorflow.serving.PredictRequest request = 1;
  int request_size() const;
  private:
  int _internal_request_size() const;
  public:
  void clear_request();
  ::tensorflow::serving::PredictRequest* mutable_request(int index);
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::tensorflow::serving::PredictRequest >*
      mutable_request();
  private:
  const ::tensorflow::serving::PredictRequest& _internal_request(int index) const;
  ::tensorflow::serving::PredictRequest* _internal_add_request();
  public:
  const ::tensorflow::serving::PredictRequest& request(int index) const;
  ::tensorflow::serving::PredictRequest* add_request();
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::tensorflow::serving::PredictRequest >&
      request() const;

  // repeated .tensorflow.serving.PredictResponse response = 2;
  int response_size() const;
  private:
  int _internal_response_size() const;
  public:
  void clear_response();
  ::tensorflow::serving::PredictResponse* mutable_response(int index);
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::tensorflow::serving::PredictResponse >*
      mutable_response();
  private:
  const ::tensorflow::serving::PredictResponse& _internal_response(int index) const;
  ::tensorflow::serving::PredictResponse* _internal_add_response();
  public:
  const ::tensorflow::serving::PredictResponse& response(int index) const;
  ::tensorflow::serving::PredictResponse* add_response();
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::tensorflow::serving::PredictResponse >&
      response() const;

  // @@protoc_insertion_point(class_scope:tensorflow.serving.PredictStreamedLog)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::tensorflow::serving::PredictRequest > request_;
    ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::tensorflow::serving::PredictResponse > response_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class MultiInferenceLog final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.MultiInferenceLog) */ {
 public:
  inline MultiInferenceLog() : MultiInferenceLog(nullptr) {}
  ~MultiInferenceLog() override;
  explicit PROTOBUF_CONSTEXPR MultiInferenceLog(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  MultiInferenceLog(const MultiInferenceLog& from);
  MultiInferenceLog(MultiInferenceLog&& from) noexcept
    : MultiInferenceLog() {
    *this = ::std::move(from);
  }

  inline MultiInferenceLog& operator=(const MultiInferenceLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline MultiInferenceLog& operator=(MultiInferenceLog&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const MultiInferenceLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const MultiInferenceLog* internal_default_instance() {
    return reinterpret_cast<const MultiInferenceLog*>(
               &_MultiInferenceLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    4;

  friend void swap(MultiInferenceLog& a, MultiInferenceLog& b) {
    a.Swap(&b);
  }
  inline void Swap(MultiInferenceLog* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(MultiInferenceLog* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  MultiInferenceLog* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<MultiInferenceLog>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const MultiInferenceLog& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const MultiInferenceLog& from) {
    MultiInferenceLog::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(MultiInferenceLog* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.MultiInferenceLog";
  }
  protected:
  explicit MultiInferenceLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // .tensorflow.serving.MultiInferenceRequest request = 1;
  bool has_request() const;
  private:
  bool _internal_has_request() const;
  public:
  void clear_request();
  const ::tensorflow::serving::MultiInferenceRequest& request() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::MultiInferenceRequest* release_request();
  ::tensorflow::serving::MultiInferenceRequest* mutable_request();
  void set_allocated_request(::tensorflow::serving::MultiInferenceRequest* request);
  private:
  const ::tensorflow::serving::MultiInferenceRequest& _internal_request() const;
  ::tensorflow::serving::MultiInferenceRequest* _internal_mutable_request();
  public:
  void unsafe_arena_set_allocated_request(
      ::tensorflow::serving::MultiInferenceRequest* request);
  ::tensorflow::serving::MultiInferenceRequest* unsafe_arena_release_request();

  // .tensorflow.serving.MultiInferenceResponse response = 2;
  bool has_response() const;
  private:
  bool _internal_has_response() const;
  public:
  void clear_response();
  const ::tensorflow::serving::MultiInferenceResponse& response() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::MultiInferenceResponse* release_response();
  ::tensorflow::serving::MultiInferenceResponse* mutable_response();
  void set_allocated_response(::tensorflow::serving::MultiInferenceResponse* response);
  private:
  const ::tensorflow::serving::MultiInferenceResponse& _internal_response() const;
  ::tensorflow::serving::MultiInferenceResponse* _internal_mutable_response();
  public:
  void unsafe_arena_set_allocated_response(
      ::tensorflow::serving::MultiInferenceResponse* response);
  ::tensorflow::serving::MultiInferenceResponse* unsafe_arena_release_response();

  // @@protoc_insertion_point(class_scope:tensorflow.serving.MultiInferenceLog)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::tensorflow::serving::MultiInferenceRequest* request_;
    ::tensorflow::serving::MultiInferenceResponse* response_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class SessionRunLog final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.SessionRunLog) */ {
 public:
  inline SessionRunLog() : SessionRunLog(nullptr) {}
  ~SessionRunLog() override;
  explicit PROTOBUF_CONSTEXPR SessionRunLog(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  SessionRunLog(const SessionRunLog& from);
  SessionRunLog(SessionRunLog&& from) noexcept
    : SessionRunLog() {
    *this = ::std::move(from);
  }

  inline SessionRunLog& operator=(const SessionRunLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline SessionRunLog& operator=(SessionRunLog&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const SessionRunLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const SessionRunLog* internal_default_instance() {
    return reinterpret_cast<const SessionRunLog*>(
               &_SessionRunLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    5;

  friend void swap(SessionRunLog& a, SessionRunLog& b) {
    a.Swap(&b);
  }
  inline void Swap(SessionRunLog* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(SessionRunLog* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  SessionRunLog* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<SessionRunLog>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const SessionRunLog& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const SessionRunLog& from) {
    SessionRunLog::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SessionRunLog* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.SessionRunLog";
  }
  protected:
  explicit SessionRunLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // .tensorflow.serving.SessionRunRequest request = 1;
  bool has_request() const;
  private:
  bool _internal_has_request() const;
  public:
  void clear_request();
  const ::tensorflow::serving::SessionRunRequest& request() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::SessionRunRequest* release_request();
  ::tensorflow::serving::SessionRunRequest* mutable_request();
  void set_allocated_request(::tensorflow::serving::SessionRunRequest* request);
  private:
  const ::tensorflow::serving::SessionRunRequest& _internal_request() const;
  ::tensorflow::serving::SessionRunRequest* _internal_mutable_request();
  public:
  void unsafe_arena_set_allocated_request(
      ::tensorflow::serving::SessionRunRequest* request);
  ::tensorflow::serving::SessionRunRequest* unsafe_arena_release_request();

  // .tensorflow.serving.SessionRunResponse response = 2;
  bool has_response() const;
  private:
  bool _internal_has_response() const;
  public:
  void clear_response();
  const ::tensorflow::serving::SessionRunResponse& response() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::SessionRunResponse* release_response();
  ::tensorflow::serving::SessionRunResponse* mutable_response();
  void set_allocated_response(::tensorflow::serving::SessionRunResponse* response);
  private:
  const ::tensorflow::serving::SessionRunResponse& _internal_response() const;
  ::tensorflow::serving::SessionRunResponse* _internal_mutable_response();
  public:
  void unsafe_arena_set_allocated_response(
      ::tensorflow::serving::SessionRunResponse* response);
  ::tensorflow::serving::SessionRunResponse* unsafe_arena_release_response();

  // @@protoc_insertion_point(class_scope:tensorflow.serving.SessionRunLog)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::tensorflow::serving::SessionRunRequest* request_;
    ::tensorflow::serving::SessionRunResponse* response_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class PredictionLog final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.PredictionLog) */ {
 public:
  inline PredictionLog() : PredictionLog(nullptr) {}
  ~PredictionLog() override;
  explicit PROTOBUF_CONSTEXPR PredictionLog(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  PredictionLog(const PredictionLog& from);
  PredictionLog(PredictionLog&& from) noexcept
    : PredictionLog() {
    *this = ::std::move(from);
  }

  inline PredictionLog& operator=(const PredictionLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline PredictionLog& operator=(PredictionLog&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const PredictionLog& default_instance() {
    return *internal_default_instance();
  }
  enum LogTypeCase {
    kClassifyLog = 2,
    kRegressLog = 3,
    kPredictLog = 6,
    kPredictStreamedLog = 7,
    kMultiInferenceLog = 4,
    kSessionRunLog = 5,
    LOG_TYPE_NOT_SET = 0,
  };

  static inline const PredictionLog* internal_default_instance() {
    return reinterpret_cast<const PredictionLog*>(
               &_PredictionLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    6;

  friend void swap(PredictionLog& a, PredictionLog& b) {
    a.Swap(&b);
  }
  inline void Swap(PredictionLog* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(PredictionLog* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  PredictionLog* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<PredictionLog>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const PredictionLog& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const PredictionLog& from) {
    PredictionLog::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(PredictionLog* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.PredictionLog";
  }
  protected:
  explicit PredictionLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kLogMetadataFieldNumber = 1,
    kClassifyLogFieldNumber = 2,
    kRegressLogFieldNumber = 3,
    kPredictLogFieldNumber = 6,
    kPredictStreamedLogFieldNumber = 7,
    kMultiInferenceLogFieldNumber = 4,
    kSessionRunLogFieldNumber = 5,
  };
  // .tensorflow.serving.LogMetadata log_metadata = 1;
  bool has_log_metadata() const;
  private:
  bool _internal_has_log_metadata() const;
  public:
  void clear_log_metadata();
  const ::tensorflow::serving::LogMetadata& log_metadata() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::LogMetadata* release_log_metadata();
  ::tensorflow::serving::LogMetadata* mutable_log_metadata();
  void set_allocated_log_metadata(::tensorflow::serving::LogMetadata* log_metadata);
  private:
  const ::tensorflow::serving::LogMetadata& _internal_log_metadata() const;
  ::tensorflow::serving::LogMetadata* _internal_mutable_log_metadata();
  public:
  void unsafe_arena_set_allocated_log_metadata(
      ::tensorflow::serving::LogMetadata* log_metadata);
  ::tensorflow::serving::LogMetadata* unsafe_arena_release_log_metadata();

  // .tensorflow.serving.ClassifyLog classify_log = 2;
  bool has_classify_log() const;
  private:
  bool _internal_has_classify_log() const;
  public:
  void clear_classify_log();
  const ::tensorflow::serving::ClassifyLog& classify_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::ClassifyLog* release_classify_log();
  ::tensorflow::serving::ClassifyLog* mutable_classify_log();
  void set_allocated_classify_log(::tensorflow::serving::ClassifyLog* classify_log);
  private:
  const ::tensorflow::serving::ClassifyLog& _internal_classify_log() const;
  ::tensorflow::serving::ClassifyLog* _internal_mutable_classify_log();
  public:
  void unsafe_arena_set_allocated_classify_log(
      ::tensorflow::serving::ClassifyLog* classify_log);
  ::tensorflow::serving::ClassifyLog* unsafe_arena_release_classify_log();

  // .tensorflow.serving.RegressLog regress_log = 3;
  bool has_regress_log() const;
  private:
  bool _internal_has_regress_log() const;
  public:
  void clear_regress_log();
  const ::tensorflow::serving::RegressLog& regress_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::RegressLog* release_regress_log();
  ::tensorflow::serving::RegressLog* mutable_regress_log();
  void set_allocated_regress_log(::tensorflow::serving::RegressLog* regress_log);
  private:
  const ::tensorflow::serving::RegressLog& _internal_regress_log() const;
  ::tensorflow::serving::RegressLog* _internal_mutable_regress_log();
  public:
  void unsafe_arena_set_allocated_regress_log(
      ::tensorflow::serving::RegressLog* regress_log);
  ::tensorflow::serving::RegressLog* unsafe_arena_release_regress_log();

  // .tensorflow.serving.PredictLog predict_log = 6;
  bool has_predict_log() const;
  private:
  bool _internal_has_predict_log() const;
  public:
  void clear_predict_log();
  const ::tensorflow::serving::PredictLog& predict_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::PredictLog* release_predict_log();
  ::tensorflow::serving::PredictLog* mutable_predict_log();
  void set_allocated_predict_log(::tensorflow::serving::PredictLog* predict_log);
  private:
  const ::tensorflow::serving::PredictLog& _internal_predict_log() const;
  ::tensorflow::serving::PredictLog* _internal_mutable_predict_log();
  public:
  void unsafe_arena_set_allocated_predict_log(
      ::tensorflow::serving::PredictLog* predict_log);
  ::tensorflow::serving::PredictLog* unsafe_arena_release_predict_log();

  // .tensorflow.serving.PredictStreamedLog predict_streamed_log = 7;
  bool has_predict_streamed_log() const;
  private:
  bool _internal_has_predict_streamed_log() const;
  public:
  void clear_predict_streamed_log();
  const ::tensorflow::serving::PredictStreamedLog& predict_streamed_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::PredictStreamedLog* release_predict_streamed_log();
  ::tensorflow::serving::PredictStreamedLog* mutable_predict_streamed_log();
  void set_allocated_predict_streamed_log(::tensorflow::serving::PredictStreamedLog* predict_streamed_log);
  private:
  const ::tensorflow::serving::PredictStreamedLog& _internal_predict_streamed_log() const;
  ::tensorflow::serving::PredictStreamedLog* _internal_mutable_predict_streamed_log();
  public:
  void unsafe_arena_set_allocated_predict_streamed_log(
      ::tensorflow::serving::PredictStreamedLog* predict_streamed_log);
  ::tensorflow::serving::PredictStreamedLog* unsafe_arena_release_predict_streamed_log();

  // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
  bool has_multi_inference_log() const;
  private:
  bool _internal_has_multi_inference_log() const;
  public:
  void clear_multi_inference_log();
  const ::tensorflow::serving::MultiInferenceLog& multi_inference_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::MultiInferenceLog* release_multi_inference_log();
  ::tensorflow::serving::MultiInferenceLog* mutable_multi_inference_log();
  void set_allocated_multi_inference_log(::tensorflow::serving::MultiInferenceLog* multi_inference_log);
  private:
  const ::tensorflow::serving::MultiInferenceLog& _internal_multi_inference_log() const;
  ::tensorflow::serving::MultiInferenceLog* _internal_mutable_multi_inference_log();
  public:
  void unsafe_arena_set_allocated_multi_inference_log(
      ::tensorflow::serving::MultiInferenceLog* multi_inference_log);
  ::tensorflow::serving::MultiInferenceLog* unsafe_arena_release_multi_inference_log();

  // .tensorflow.serving.SessionRunLog session_run_log = 5;
  bool has_session_run_log() const;
  private:
  bool _internal_has_session_run_log() const;
  public:
  void clear_session_run_log();
  const ::tensorflow::serving::SessionRunLog& session_run_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::SessionRunLog* release_session_run_log();
  ::tensorflow::serving::SessionRunLog* mutable_session_run_log();
  void set_allocated_session_run_log(::tensorflow::serving::SessionRunLog* session_run_log);
  private:
  const ::tensorflow::serving::SessionRunLog& _internal_session_run_log() const;
  ::tensorflow::serving::SessionRunLog* _internal_mutable_session_run_log();
  public:
  void unsafe_arena_set_allocated_session_run_log(
      ::tensorflow::serving::SessionRunLog* session_run_log);
  ::tensorflow::serving::SessionRunLog* unsafe_arena_release_session_run_log();

  void clear_log_type();
  LogTypeCase log_type_case() const;
  // @@protoc_insertion_point(class_scope:tensorflow.serving.PredictionLog)
 private:
  class _Internal;
  void set_has_classify_log();
  void set_has_regress_log();
  void set_has_predict_log();
  void set_has_predict_streamed_log();
  void set_has_multi_inference_log();
  void set_has_session_run_log();

  inline bool has_log_type() const;
  inline void clear_has_log_type();

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::tensorflow::serving::LogMetadata* log_metadata_;
    union LogTypeUnion {
      constexpr LogTypeUnion() : _constinit_{} {}
        ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized _constinit_;
      ::tensorflow::serving::ClassifyLog* classify_log_;
      ::tensorflow::serving::RegressLog* regress_log_;
      ::tensorflow::serving::PredictLog* predict_log_;
      ::tensorflow::serving::PredictStreamedLog* predict_streamed_log_;
      ::tensorflow::serving::MultiInferenceLog* multi_inference_log_;
      ::tensorflow::serving::SessionRunLog* session_run_log_;
    } log_type_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
    uint32_t _oneof_case_[1];

  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// ClassifyLog

// .tensorflow.serving.ClassificationRequest request = 1;
inline bool ClassifyLog::_internal_has_request() const {
  return this != internal_default_instance() && _impl_.request_ != nullptr;
}
inline bool ClassifyLog::has_request() const {
  return _internal_has_request();
}
inline const ::tensorflow::serving::ClassificationRequest& ClassifyLog::_internal_request() const {
  const ::tensorflow::serving::ClassificationRequest* p = _impl_.request_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::ClassificationRequest&>(
      ::tensorflow::serving::_ClassificationRequest_default_instance_);
}
inline const ::tensorflow::serving::ClassificationRequest& ClassifyLog::request() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ClassifyLog.request)
  return _internal_request();
}
inline void ClassifyLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::ClassificationRequest* request) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_);
  }
  _impl_.request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ClassifyLog.request)
}
inline ::tensorflow::serving::ClassificationRequest* ClassifyLog::release_request() {
  
  ::tensorflow::serving::ClassificationRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::ClassificationRequest* ClassifyLog::unsafe_arena_release_request() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ClassifyLog.request)
  
  ::tensorflow::serving::ClassificationRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::ClassificationRequest* ClassifyLog::_internal_mutable_request() {
  
  if (_impl_.request_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::ClassificationRequest>(GetArenaForAllocation());
    _impl_.request_ = p;
  }
  return _impl_.request_;
}
inline ::tensorflow::serving::ClassificationRequest* ClassifyLog::mutable_request() {
  ::tensorflow::serving::ClassificationRequest* _msg = _internal_mutable_request();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ClassifyLog.request)
  return _msg;
}
inline void ClassifyLog::set_allocated_request(::tensorflow::serving::ClassificationRequest* request) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_);
  }
  if (request) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(request));
    if (message_arena != submessage_arena) {
      request = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, request, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.request_ = request;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ClassifyLog.request)
}

// .tensorflow.serving.ClassificationResponse response = 2;
inline bool ClassifyLog::_internal_has_response() const {
  return this != internal_default_instance() && _impl_.response_ != nullptr;
}
inline bool ClassifyLog::has_response() const {
  return _internal_has_response();
}
inline const ::tensorflow::serving::ClassificationResponse& ClassifyLog::_internal_response() const {
  const ::tensorflow::serving::ClassificationResponse* p = _impl_.response_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::ClassificationResponse&>(
      ::tensorflow::serving::_ClassificationResponse_default_instance_);
}
inline const ::tensorflow::serving::ClassificationResponse& ClassifyLog::response() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ClassifyLog.response)
  return _internal_response();
}
inline void ClassifyLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::ClassificationResponse* response) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.response_);
  }
  _impl_.response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ClassifyLog.response)
}
inline ::tensorflow::serving::ClassificationResponse* ClassifyLog::release_response() {
  
  ::tensorflow::serving::ClassificationResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::ClassificationResponse* ClassifyLog::unsafe_arena_release_response() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ClassifyLog.response)
  
  ::tensorflow::serving::ClassificationResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::ClassificationResponse* ClassifyLog::_internal_mutable_response() {
  
  if (_impl_.response_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::ClassificationResponse>(GetArenaForAllocation());
    _impl_.response_ = p;
  }
  return _impl_.response_;
}
inline ::tensorflow::serving::ClassificationResponse* ClassifyLog::mutable_response() {
  ::tensorflow::serving::ClassificationResponse* _msg = _internal_mutable_response();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ClassifyLog.response)
  return _msg;
}
inline void ClassifyLog::set_allocated_response(::tensorflow::serving::ClassificationResponse* response) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.response_);
  }
  if (response) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(response));
    if (message_arena != submessage_arena) {
      response = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, response, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.response_ = response;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ClassifyLog.response)
}

// -------------------------------------------------------------------

// RegressLog

// .tensorflow.serving.RegressionRequest request = 1;
inline bool RegressLog::_internal_has_request() const {
  return this != internal_default_instance() && _impl_.request_ != nullptr;
}
inline bool RegressLog::has_request() const {
  return _internal_has_request();
}
inline const ::tensorflow::serving::RegressionRequest& RegressLog::_internal_request() const {
  const ::tensorflow::serving::RegressionRequest* p = _impl_.request_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::RegressionRequest&>(
      ::tensorflow::serving::_RegressionRequest_default_instance_);
}
inline const ::tensorflow::serving::RegressionRequest& RegressLog::request() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.RegressLog.request)
  return _internal_request();
}
inline void RegressLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::RegressionRequest* request) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_);
  }
  _impl_.request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.RegressLog.request)
}
inline ::tensorflow::serving::RegressionRequest* RegressLog::release_request() {
  
  ::tensorflow::serving::RegressionRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::RegressionRequest* RegressLog::unsafe_arena_release_request() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.RegressLog.request)
  
  ::tensorflow::serving::RegressionRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::RegressionRequest* RegressLog::_internal_mutable_request() {
  
  if (_impl_.request_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::RegressionRequest>(GetArenaForAllocation());
    _impl_.request_ = p;
  }
  return _impl_.request_;
}
inline ::tensorflow::serving::RegressionRequest* RegressLog::mutable_request() {
  ::tensorflow::serving::RegressionRequest* _msg = _internal_mutable_request();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.RegressLog.request)
  return _msg;
}
inline void RegressLog::set_allocated_request(::tensorflow::serving::RegressionRequest* request) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_);
  }
  if (request) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(request));
    if (message_arena != submessage_arena) {
      request = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, request, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.request_ = request;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.RegressLog.request)
}

// .tensorflow.serving.RegressionResponse response = 2;
inline bool RegressLog::_internal_has_response() const {
  return this != internal_default_instance() && _impl_.response_ != nullptr;
}
inline bool RegressLog::has_response() const {
  return _internal_has_response();
}
inline const ::tensorflow::serving::RegressionResponse& RegressLog::_internal_response() const {
  const ::tensorflow::serving::RegressionResponse* p = _impl_.response_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::RegressionResponse&>(
      ::tensorflow::serving::_RegressionResponse_default_instance_);
}
inline const ::tensorflow::serving::RegressionResponse& RegressLog::response() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.RegressLog.response)
  return _internal_response();
}
inline void RegressLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::RegressionResponse* response) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.response_);
  }
  _impl_.response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.RegressLog.response)
}
inline ::tensorflow::serving::RegressionResponse* RegressLog::release_response() {
  
  ::tensorflow::serving::RegressionResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::RegressionResponse* RegressLog::unsafe_arena_release_response() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.RegressLog.response)
  
  ::tensorflow::serving::RegressionResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::RegressionResponse* RegressLog::_internal_mutable_response() {
  
  if (_impl_.response_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::RegressionResponse>(GetArenaForAllocation());
    _impl_.response_ = p;
  }
  return _impl_.response_;
}
inline ::tensorflow::serving::RegressionResponse* RegressLog::mutable_response() {
  ::tensorflow::serving::RegressionResponse* _msg = _internal_mutable_response();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.RegressLog.response)
  return _msg;
}
inline void RegressLog::set_allocated_response(::tensorflow::serving::RegressionResponse* response) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.response_);
  }
  if (response) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(response));
    if (message_arena != submessage_arena) {
      response = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, response, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.response_ = response;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.RegressLog.response)
}

// -------------------------------------------------------------------

// PredictLog

// .tensorflow.serving.PredictRequest request = 1;
inline bool PredictLog::_internal_has_request() const {
  return this != internal_default_instance() && _impl_.request_ != nullptr;
}
inline bool PredictLog::has_request() const {
  return _internal_has_request();
}
inline const ::tensorflow::serving::PredictRequest& PredictLog::_internal_request() const {
  const ::tensorflow::serving::PredictRequest* p = _impl_.request_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::PredictRequest&>(
      ::tensorflow::serving::_PredictRequest_default_instance_);
}
inline const ::tensorflow::serving::PredictRequest& PredictLog::request() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictLog.request)
  return _internal_request();
}
inline void PredictLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::PredictRequest* request) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_);
  }
  _impl_.request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictLog.request)
}
inline ::tensorflow::serving::PredictRequest* PredictLog::release_request() {
  
  ::tensorflow::serving::PredictRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::PredictRequest* PredictLog::unsafe_arena_release_request() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictLog.request)
  
  ::tensorflow::serving::PredictRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::PredictRequest* PredictLog::_internal_mutable_request() {
  
  if (_impl_.request_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::PredictRequest>(GetArenaForAllocation());
    _impl_.request_ = p;
  }
  return _impl_.request_;
}
inline ::tensorflow::serving::PredictRequest* PredictLog::mutable_request() {
  ::tensorflow::serving::PredictRequest* _msg = _internal_mutable_request();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictLog.request)
  return _msg;
}
inline void PredictLog::set_allocated_request(::tensorflow::serving::PredictRequest* request) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_);
  }
  if (request) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(request));
    if (message_arena != submessage_arena) {
      request = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, request, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.request_ = request;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictLog.request)
}

// .tensorflow.serving.PredictResponse response = 2;
inline bool PredictLog::_internal_has_response() const {
  return this != internal_default_instance() && _impl_.response_ != nullptr;
}
inline bool PredictLog::has_response() const {
  return _internal_has_response();
}
inline const ::tensorflow::serving::PredictResponse& PredictLog::_internal_response() const {
  const ::tensorflow::serving::PredictResponse* p = _impl_.response_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::PredictResponse&>(
      ::tensorflow::serving::_PredictResponse_default_instance_);
}
inline const ::tensorflow::serving::PredictResponse& PredictLog::response() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictLog.response)
  return _internal_response();
}
inline void PredictLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::PredictResponse* response) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.response_);
  }
  _impl_.response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictLog.response)
}
inline ::tensorflow::serving::PredictResponse* PredictLog::release_response() {
  
  ::tensorflow::serving::PredictResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::PredictResponse* PredictLog::unsafe_arena_release_response() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictLog.response)
  
  ::tensorflow::serving::PredictResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::PredictResponse* PredictLog::_internal_mutable_response() {
  
  if (_impl_.response_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::PredictResponse>(GetArenaForAllocation());
    _impl_.response_ = p;
  }
  return _impl_.response_;
}
inline ::tensorflow::serving::PredictResponse* PredictLog::mutable_response() {
  ::tensorflow::serving::PredictResponse* _msg = _internal_mutable_response();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictLog.response)
  return _msg;
}
inline void PredictLog::set_allocated_response(::tensorflow::serving::PredictResponse* response) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.response_);
  }
  if (response) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(response));
    if (message_arena != submessage_arena) {
      response = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, response, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.response_ = response;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictLog.response)
}

// -------------------------------------------------------------------

// PredictStreamedLog

// repeated .tensorflow.serving.PredictRequest request = 1;
inline int PredictStreamedLog::_internal_request_size() const {
  return _impl_.request_.size();
}
inline int PredictStreamedLog::request_size() const {
  return _internal_request_size();
}
inline ::tensorflow::serving::PredictRequest* PredictStreamedLog::mutable_request(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictStreamedLog.request)
  return _impl_.request_.Mutable(index);
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::tensorflow::serving::PredictRequest >*
PredictStreamedLog::mutable_request() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.PredictStreamedLog.request)
  return &_impl_.request_;
}
inline const ::tensorflow::serving::PredictRequest& PredictStreamedLog::_internal_request(int index) const {
  return _impl_.request_.Get(index);
}
inline const ::tensorflow::serving::PredictRequest& PredictStreamedLog::request(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictStreamedLog.request)
  return _internal_request(index);
}
inline ::tensorflow::serving::PredictRequest* PredictStreamedLog::_internal_add_request() {
  return _impl_.request_.Add();
}
inline ::tensorflow::serving::PredictRequest* PredictStreamedLog::add_request() {
  ::tensorflow::serving::PredictRequest* _add = _internal_add_request();
  // @@protoc_insertion_point(field_add:tensorflow.serving.PredictStreamedLog.request)
  return _add;
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::tensorflow::serving::PredictRequest >&
PredictStreamedLog::request() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.PredictStreamedLog.request)
  return _impl_.request_;
}

// repeated .tensorflow.serving.PredictResponse response = 2;
inline int PredictStreamedLog::_internal_response_size() const {
  return _impl_.response_.size();
}
inline int PredictStreamedLog::response_size() const {
  return _internal_response_size();
}
inline ::tensorflow::serving::PredictResponse* PredictStreamedLog::mutable_response(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictStreamedLog.response)
  return _impl_.response_.Mutable(index);
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::tensorflow::serving::PredictResponse >*
PredictStreamedLog::mutable_response() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.PredictStreamedLog.response)
  return &_impl_.response_;
}
inline const ::tensorflow::serving::PredictResponse& PredictStreamedLog::_internal_response(int index) const {
  return _impl_.response_.Get(index);
}
inline const ::tensorflow::serving::PredictResponse& PredictStreamedLog::response(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictStreamedLog.response)
  return _internal_response(index);
}
inline ::tensorflow::serving::PredictResponse* PredictStreamedLog::_internal_add_response() {
  return _impl_.response_.Add();
}
inline ::tensorflow::serving::PredictResponse* PredictStreamedLog::add_response() {
  ::tensorflow::serving::PredictResponse* _add = _internal_add_response();
  // @@protoc_insertion_point(field_add:tensorflow.serving.PredictStreamedLog.response)
  return _add;
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::tensorflow::serving::PredictResponse >&
PredictStreamedLog::response() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.PredictStreamedLog.response)
  return _impl_.response_;
}

// -------------------------------------------------------------------

// MultiInferenceLog

// .tensorflow.serving.MultiInferenceRequest request = 1;
inline bool MultiInferenceLog::_internal_has_request() const {
  return this != internal_default_instance() && _impl_.request_ != nullptr;
}
inline bool MultiInferenceLog::has_request() const {
  return _internal_has_request();
}
inline const ::tensorflow::serving::MultiInferenceRequest& MultiInferenceLog::_internal_request() const {
  const ::tensorflow::serving::MultiInferenceRequest* p = _impl_.request_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::MultiInferenceRequest&>(
      ::tensorflow::serving::_MultiInferenceRequest_default_instance_);
}
inline const ::tensorflow::serving::MultiInferenceRequest& MultiInferenceLog::request() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.MultiInferenceLog.request)
  return _internal_request();
}
inline void MultiInferenceLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::MultiInferenceRequest* request) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_);
  }
  _impl_.request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.MultiInferenceLog.request)
}
inline ::tensorflow::serving::MultiInferenceRequest* MultiInferenceLog::release_request() {
  
  ::tensorflow::serving::MultiInferenceRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::MultiInferenceRequest* MultiInferenceLog::unsafe_arena_release_request() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.MultiInferenceLog.request)
  
  ::tensorflow::serving::MultiInferenceRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::MultiInferenceRequest* MultiInferenceLog::_internal_mutable_request() {
  
  if (_impl_.request_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::MultiInferenceRequest>(GetArenaForAllocation());
    _impl_.request_ = p;
  }
  return _impl_.request_;
}
inline ::tensorflow::serving::MultiInferenceRequest* MultiInferenceLog::mutable_request() {
  ::tensorflow::serving::MultiInferenceRequest* _msg = _internal_mutable_request();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.MultiInferenceLog.request)
  return _msg;
}
inline void MultiInferenceLog::set_allocated_request(::tensorflow::serving::MultiInferenceRequest* request) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_);
  }
  if (request) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(request));
    if (message_arena != submessage_arena) {
      request = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, request, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.request_ = request;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.MultiInferenceLog.request)
}

// .tensorflow.serving.MultiInferenceResponse response = 2;
inline bool MultiInferenceLog::_internal_has_response() const {
  return this != internal_default_instance() && _impl_.response_ != nullptr;
}
inline bool MultiInferenceLog::has_response() const {
  return _internal_has_response();
}
inline const ::tensorflow::serving::MultiInferenceResponse& MultiInferenceLog::_internal_response() const {
  const ::tensorflow::serving::MultiInferenceResponse* p = _impl_.response_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::MultiInferenceResponse&>(
      ::tensorflow::serving::_MultiInferenceResponse_default_instance_);
}
inline const ::tensorflow::serving::MultiInferenceResponse& MultiInferenceLog::response() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.MultiInferenceLog.response)
  return _internal_response();
}
inline void MultiInferenceLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::MultiInferenceResponse* response) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.response_);
  }
  _impl_.response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.MultiInferenceLog.response)
}
inline ::tensorflow::serving::MultiInferenceResponse* MultiInferenceLog::release_response() {
  
  ::tensorflow::serving::MultiInferenceResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::MultiInferenceResponse* MultiInferenceLog::unsafe_arena_release_response() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.MultiInferenceLog.response)
  
  ::tensorflow::serving::MultiInferenceResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::MultiInferenceResponse* MultiInferenceLog::_internal_mutable_response() {
  
  if (_impl_.response_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::MultiInferenceResponse>(GetArenaForAllocation());
    _impl_.response_ = p;
  }
  return _impl_.response_;
}
inline ::tensorflow::serving::MultiInferenceResponse* MultiInferenceLog::mutable_response() {
  ::tensorflow::serving::MultiInferenceResponse* _msg = _internal_mutable_response();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.MultiInferenceLog.response)
  return _msg;
}
inline void MultiInferenceLog::set_allocated_response(::tensorflow::serving::MultiInferenceResponse* response) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.response_);
  }
  if (response) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(response));
    if (message_arena != submessage_arena) {
      response = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, response, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.response_ = response;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.MultiInferenceLog.response)
}

// -------------------------------------------------------------------

// SessionRunLog

// .tensorflow.serving.SessionRunRequest request = 1;
inline bool SessionRunLog::_internal_has_request() const {
  return this != internal_default_instance() && _impl_.request_ != nullptr;
}
inline bool SessionRunLog::has_request() const {
  return _internal_has_request();
}
inline const ::tensorflow::serving::SessionRunRequest& SessionRunLog::_internal_request() const {
  const ::tensorflow::serving::SessionRunRequest* p = _impl_.request_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::SessionRunRequest&>(
      ::tensorflow::serving::_SessionRunRequest_default_instance_);
}
inline const ::tensorflow::serving::SessionRunRequest& SessionRunLog::request() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunLog.request)
  return _internal_request();
}
inline void SessionRunLog::unsafe_arena_set_allocated_request(
    ::tensorflow::serving::SessionRunRequest* request) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_);
  }
  _impl_.request_ = request;
  if (request) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunLog.request)
}
inline ::tensorflow::serving::SessionRunRequest* SessionRunLog::release_request() {
  
  ::tensorflow::serving::SessionRunRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::SessionRunRequest* SessionRunLog::unsafe_arena_release_request() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionRunLog.request)
  
  ::tensorflow::serving::SessionRunRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::SessionRunRequest* SessionRunLog::_internal_mutable_request() {
  
  if (_impl_.request_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::SessionRunRequest>(GetArenaForAllocation());
    _impl_.request_ = p;
  }
  return _impl_.request_;
}
inline ::tensorflow::serving::SessionRunRequest* SessionRunLog::mutable_request() {
  ::tensorflow::serving::SessionRunRequest* _msg = _internal_mutable_request();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunLog.request)
  return _msg;
}
inline void SessionRunLog::set_allocated_request(::tensorflow::serving::SessionRunRequest* request) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_);
  }
  if (request) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(request));
    if (message_arena != submessage_arena) {
      request = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, request, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.request_ = request;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionRunLog.request)
}

// .tensorflow.serving.SessionRunResponse response = 2;
inline bool SessionRunLog::_internal_has_response() const {
  return this != internal_default_instance() && _impl_.response_ != nullptr;
}
inline bool SessionRunLog::has_response() const {
  return _internal_has_response();
}
inline const ::tensorflow::serving::SessionRunResponse& SessionRunLog::_internal_response() const {
  const ::tensorflow::serving::SessionRunResponse* p = _impl_.response_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::SessionRunResponse&>(
      ::tensorflow::serving::_SessionRunResponse_default_instance_);
}
inline const ::tensorflow::serving::SessionRunResponse& SessionRunLog::response() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunLog.response)
  return _internal_response();
}
inline void SessionRunLog::unsafe_arena_set_allocated_response(
    ::tensorflow::serving::SessionRunResponse* response) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.response_);
  }
  _impl_.response_ = response;
  if (response) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunLog.response)
}
inline ::tensorflow::serving::SessionRunResponse* SessionRunLog::release_response() {
  
  ::tensorflow::serving::SessionRunResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::SessionRunResponse* SessionRunLog::unsafe_arena_release_response() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionRunLog.response)
  
  ::tensorflow::serving::SessionRunResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::SessionRunResponse* SessionRunLog::_internal_mutable_response() {
  
  if (_impl_.response_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::SessionRunResponse>(GetArenaForAllocation());
    _impl_.response_ = p;
  }
  return _impl_.response_;
}
inline ::tensorflow::serving::SessionRunResponse* SessionRunLog::mutable_response() {
  ::tensorflow::serving::SessionRunResponse* _msg = _internal_mutable_response();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunLog.response)
  return _msg;
}
inline void SessionRunLog::set_allocated_response(::tensorflow::serving::SessionRunResponse* response) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.response_);
  }
  if (response) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(response));
    if (message_arena != submessage_arena) {
      response = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, response, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.response_ = response;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionRunLog.response)
}

// -------------------------------------------------------------------

// PredictionLog

// .tensorflow.serving.LogMetadata log_metadata = 1;
inline bool PredictionLog::_internal_has_log_metadata() const {
  return this != internal_default_instance() && _impl_.log_metadata_ != nullptr;
}
inline bool PredictionLog::has_log_metadata() const {
  return _internal_has_log_metadata();
}
inline const ::tensorflow::serving::LogMetadata& PredictionLog::_internal_log_metadata() const {
  const ::tensorflow::serving::LogMetadata* p = _impl_.log_metadata_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::LogMetadata&>(
      ::tensorflow::serving::_LogMetadata_default_instance_);
}
inline const ::tensorflow::serving::LogMetadata& PredictionLog::log_metadata() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.log_metadata)
  return _internal_log_metadata();
}
inline void PredictionLog::unsafe_arena_set_allocated_log_metadata(
    ::tensorflow::serving::LogMetadata* log_metadata) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.log_metadata_);
  }
  _impl_.log_metadata_ = log_metadata;
  if (log_metadata) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.log_metadata)
}
inline ::tensorflow::serving::LogMetadata* PredictionLog::release_log_metadata() {
  
  ::tensorflow::serving::LogMetadata* temp = _impl_.log_metadata_;
  _impl_.log_metadata_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::LogMetadata* PredictionLog::unsafe_arena_release_log_metadata() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.log_metadata)
  
  ::tensorflow::serving::LogMetadata* temp = _impl_.log_metadata_;
  _impl_.log_metadata_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::LogMetadata* PredictionLog::_internal_mutable_log_metadata() {
  
  if (_impl_.log_metadata_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::LogMetadata>(GetArenaForAllocation());
    _impl_.log_metadata_ = p;
  }
  return _impl_.log_metadata_;
}
inline ::tensorflow::serving::LogMetadata* PredictionLog::mutable_log_metadata() {
  ::tensorflow::serving::LogMetadata* _msg = _internal_mutable_log_metadata();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.log_metadata)
  return _msg;
}
inline void PredictionLog::set_allocated_log_metadata(::tensorflow::serving::LogMetadata* log_metadata) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.log_metadata_);
  }
  if (log_metadata) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(log_metadata));
    if (message_arena != submessage_arena) {
      log_metadata = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, log_metadata, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.log_metadata_ = log_metadata;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.log_metadata)
}

// .tensorflow.serving.ClassifyLog classify_log = 2;
inline bool PredictionLog::_internal_has_classify_log() const {
  return log_type_case() == kClassifyLog;
}
inline bool PredictionLog::has_classify_log() const {
  return _internal_has_classify_log();
}
inline void PredictionLog::set_has_classify_log() {
  _impl_._oneof_case_[0] = kClassifyLog;
}
inline void PredictionLog::clear_classify_log() {
  if (_internal_has_classify_log()) {
    if (GetArenaForAllocation() == nullptr) {
      delete _impl_.log_type_.classify_log_;
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::ClassifyLog* PredictionLog::release_classify_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.classify_log)
  if (_internal_has_classify_log()) {
    clear_has_log_type();
    ::tensorflow::serving::ClassifyLog* temp = _impl_.log_type_.classify_log_;
    if (GetArenaForAllocation() != nullptr) {
      temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.classify_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::ClassifyLog& PredictionLog::_internal_classify_log() const {
  return _internal_has_classify_log()
      ? *_impl_.log_type_.classify_log_
      : reinterpret_cast< ::tensorflow::serving::ClassifyLog&>(::tensorflow::serving::_ClassifyLog_default_instance_);
}
inline const ::tensorflow::serving::ClassifyLog& PredictionLog::classify_log() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.classify_log)
  return _internal_classify_log();
}
inline ::tensorflow::serving::ClassifyLog* PredictionLog::unsafe_arena_release_classify_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.classify_log)
  if (_internal_has_classify_log()) {
    clear_has_log_type();
    ::tensorflow::serving::ClassifyLog* temp = _impl_.log_type_.classify_log_;
    _impl_.log_type_.classify_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_classify_log(::tensorflow::serving::ClassifyLog* classify_log) {
  clear_log_type();
  if (classify_log) {
    set_has_classify_log();
    _impl_.log_type_.classify_log_ = classify_log;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.classify_log)
}
inline ::tensorflow::serving::ClassifyLog* PredictionLog::_internal_mutable_classify_log() {
  if (!_internal_has_classify_log()) {
    clear_log_type();
    set_has_classify_log();
    _impl_.log_type_.classify_log_ = CreateMaybeMessage< ::tensorflow::serving::ClassifyLog >(GetArenaForAllocation());
  }
  return _impl_.log_type_.classify_log_;
}
inline ::tensorflow::serving::ClassifyLog* PredictionLog::mutable_classify_log() {
  ::tensorflow::serving::ClassifyLog* _msg = _internal_mutable_classify_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.classify_log)
  return _msg;
}

// .tensorflow.serving.RegressLog regress_log = 3;
inline bool PredictionLog::_internal_has_regress_log() const {
  return log_type_case() == kRegressLog;
}
inline bool PredictionLog::has_regress_log() const {
  return _internal_has_regress_log();
}
inline void PredictionLog::set_has_regress_log() {
  _impl_._oneof_case_[0] = kRegressLog;
}
inline void PredictionLog::clear_regress_log() {
  if (_internal_has_regress_log()) {
    if (GetArenaForAllocation() == nullptr) {
      delete _impl_.log_type_.regress_log_;
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::RegressLog* PredictionLog::release_regress_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.regress_log)
  if (_internal_has_regress_log()) {
    clear_has_log_type();
    ::tensorflow::serving::RegressLog* temp = _impl_.log_type_.regress_log_;
    if (GetArenaForAllocation() != nullptr) {
      temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.regress_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::RegressLog& PredictionLog::_internal_regress_log() const {
  return _internal_has_regress_log()
      ? *_impl_.log_type_.regress_log_
      : reinterpret_cast< ::tensorflow::serving::RegressLog&>(::tensorflow::serving::_RegressLog_default_instance_);
}
inline const ::tensorflow::serving::RegressLog& PredictionLog::regress_log() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.regress_log)
  return _internal_regress_log();
}
inline ::tensorflow::serving::RegressLog* PredictionLog::unsafe_arena_release_regress_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.regress_log)
  if (_internal_has_regress_log()) {
    clear_has_log_type();
    ::tensorflow::serving::RegressLog* temp = _impl_.log_type_.regress_log_;
    _impl_.log_type_.regress_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_regress_log(::tensorflow::serving::RegressLog* regress_log) {
  clear_log_type();
  if (regress_log) {
    set_has_regress_log();
    _impl_.log_type_.regress_log_ = regress_log;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.regress_log)
}
inline ::tensorflow::serving::RegressLog* PredictionLog::_internal_mutable_regress_log() {
  if (!_internal_has_regress_log()) {
    clear_log_type();
    set_has_regress_log();
    _impl_.log_type_.regress_log_ = CreateMaybeMessage< ::tensorflow::serving::RegressLog >(GetArenaForAllocation());
  }
  return _impl_.log_type_.regress_log_;
}
inline ::tensorflow::serving::RegressLog* PredictionLog::mutable_regress_log() {
  ::tensorflow::serving::RegressLog* _msg = _internal_mutable_regress_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.regress_log)
  return _msg;
}

// .tensorflow.serving.PredictLog predict_log = 6;
inline bool PredictionLog::_internal_has_predict_log() const {
  return log_type_case() == kPredictLog;
}
inline bool PredictionLog::has_predict_log() const {
  return _internal_has_predict_log();
}
inline void PredictionLog::set_has_predict_log() {
  _impl_._oneof_case_[0] = kPredictLog;
}
inline void PredictionLog::clear_predict_log() {
  if (_internal_has_predict_log()) {
    if (GetArenaForAllocation() == nullptr) {
      delete _impl_.log_type_.predict_log_;
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::PredictLog* PredictionLog::release_predict_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.predict_log)
  if (_internal_has_predict_log()) {
    clear_has_log_type();
    ::tensorflow::serving::PredictLog* temp = _impl_.log_type_.predict_log_;
    if (GetArenaForAllocation() != nullptr) {
      temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.predict_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::PredictLog& PredictionLog::_internal_predict_log() const {
  return _internal_has_predict_log()
      ? *_impl_.log_type_.predict_log_
      : reinterpret_cast< ::tensorflow::serving::PredictLog&>(::tensorflow::serving::_PredictLog_default_instance_);
}
inline const ::tensorflow::serving::PredictLog& PredictionLog::predict_log() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.predict_log)
  return _internal_predict_log();
}
inline ::tensorflow::serving::PredictLog* PredictionLog::unsafe_arena_release_predict_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.predict_log)
  if (_internal_has_predict_log()) {
    clear_has_log_type();
    ::tensorflow::serving::PredictLog* temp = _impl_.log_type_.predict_log_;
    _impl_.log_type_.predict_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_predict_log(::tensorflow::serving::PredictLog* predict_log) {
  clear_log_type();
  if (predict_log) {
    set_has_predict_log();
    _impl_.log_type_.predict_log_ = predict_log;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.predict_log)
}
inline ::tensorflow::serving::PredictLog* PredictionLog::_internal_mutable_predict_log() {
  if (!_internal_has_predict_log()) {
    clear_log_type();
    set_has_predict_log();
    _impl_.log_type_.predict_log_ = CreateMaybeMessage< ::tensorflow::serving::PredictLog >(GetArenaForAllocation());
  }
  return _impl_.log_type_.predict_log_;
}
inline ::tensorflow::serving::PredictLog* PredictionLog::mutable_predict_log() {
  ::tensorflow::serving::PredictLog* _msg = _internal_mutable_predict_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.predict_log)
  return _msg;
}

// .tensorflow.serving.PredictStreamedLog predict_streamed_log = 7;
inline bool PredictionLog::_internal_has_predict_streamed_log() const {
  return log_type_case() == kPredictStreamedLog;
}
inline bool PredictionLog::has_predict_streamed_log() const {
  return _internal_has_predict_streamed_log();
}
inline void PredictionLog::set_has_predict_streamed_log() {
  _impl_._oneof_case_[0] = kPredictStreamedLog;
}
inline void PredictionLog::clear_predict_streamed_log() {
  if (_internal_has_predict_streamed_log()) {
    if (GetArenaForAllocation() == nullptr) {
      delete _impl_.log_type_.predict_streamed_log_;
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::PredictStreamedLog* PredictionLog::release_predict_streamed_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.predict_streamed_log)
  if (_internal_has_predict_streamed_log()) {
    clear_has_log_type();
    ::tensorflow::serving::PredictStreamedLog* temp = _impl_.log_type_.predict_streamed_log_;
    if (GetArenaForAllocation() != nullptr) {
      temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.predict_streamed_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::PredictStreamedLog& PredictionLog::_internal_predict_streamed_log() const {
  return _internal_has_predict_streamed_log()
      ? *_impl_.log_type_.predict_streamed_log_
      : reinterpret_cast< ::tensorflow::serving::PredictStreamedLog&>(::tensorflow::serving::_PredictStreamedLog_default_instance_);
}
inline const ::tensorflow::serving::PredictStreamedLog& PredictionLog::predict_streamed_log() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.predict_streamed_log)
  return _internal_predict_streamed_log();
}
inline ::tensorflow::serving::PredictStreamedLog* PredictionLog::unsafe_arena_release_predict_streamed_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.predict_streamed_log)
  if (_internal_has_predict_streamed_log()) {
    clear_has_log_type();
    ::tensorflow::serving::PredictStreamedLog* temp = _impl_.log_type_.predict_streamed_log_;
    _impl_.log_type_.predict_streamed_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_predict_streamed_log(::tensorflow::serving::PredictStreamedLog* predict_streamed_log) {
  clear_log_type();
  if (predict_streamed_log) {
    set_has_predict_streamed_log();
    _impl_.log_type_.predict_streamed_log_ = predict_streamed_log;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.predict_streamed_log)
}
inline ::tensorflow::serving::PredictStreamedLog* PredictionLog::_internal_mutable_predict_streamed_log() {
  if (!_internal_has_predict_streamed_log()) {
    clear_log_type();
    set_has_predict_streamed_log();
    _impl_.log_type_.predict_streamed_log_ = CreateMaybeMessage< ::tensorflow::serving::PredictStreamedLog >(GetArenaForAllocation());
  }
  return _impl_.log_type_.predict_streamed_log_;
}
inline ::tensorflow::serving::PredictStreamedLog* PredictionLog::mutable_predict_streamed_log() {
  ::tensorflow::serving::PredictStreamedLog* _msg = _internal_mutable_predict_streamed_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.predict_streamed_log)
  return _msg;
}

// .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
inline bool PredictionLog::_internal_has_multi_inference_log() const {
  return log_type_case() == kMultiInferenceLog;
}
inline bool PredictionLog::has_multi_inference_log() const {
  return _internal_has_multi_inference_log();
}
inline void PredictionLog::set_has_multi_inference_log() {
  _impl_._oneof_case_[0] = kMultiInferenceLog;
}
inline void PredictionLog::clear_multi_inference_log() {
  if (_internal_has_multi_inference_log()) {
    if (GetArenaForAllocation() == nullptr) {
      delete _impl_.log_type_.multi_inference_log_;
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::MultiInferenceLog* PredictionLog::release_multi_inference_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.multi_inference_log)
  if (_internal_has_multi_inference_log()) {
    clear_has_log_type();
    ::tensorflow::serving::MultiInferenceLog* temp = _impl_.log_type_.multi_inference_log_;
    if (GetArenaForAllocation() != nullptr) {
      temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.multi_inference_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::MultiInferenceLog& PredictionLog::_internal_multi_inference_log() const {
  return _internal_has_multi_inference_log()
      ? *_impl_.log_type_.multi_inference_log_
      : reinterpret_cast< ::tensorflow::serving::MultiInferenceLog&>(::tensorflow::serving::_MultiInferenceLog_default_instance_);
}
inline const ::tensorflow::serving::MultiInferenceLog& PredictionLog::multi_inference_log() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.multi_inference_log)
  return _internal_multi_inference_log();
}
inline ::tensorflow::serving::MultiInferenceLog* PredictionLog::unsafe_arena_release_multi_inference_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.multi_inference_log)
  if (_internal_has_multi_inference_log()) {
    clear_has_log_type();
    ::tensorflow::serving::MultiInferenceLog* temp = _impl_.log_type_.multi_inference_log_;
    _impl_.log_type_.multi_inference_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_multi_inference_log(::tensorflow::serving::MultiInferenceLog* multi_inference_log) {
  clear_log_type();
  if (multi_inference_log) {
    set_has_multi_inference_log();
    _impl_.log_type_.multi_inference_log_ = multi_inference_log;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.multi_inference_log)
}
inline ::tensorflow::serving::MultiInferenceLog* PredictionLog::_internal_mutable_multi_inference_log() {
  if (!_internal_has_multi_inference_log()) {
    clear_log_type();
    set_has_multi_inference_log();
    _impl_.log_type_.multi_inference_log_ = CreateMaybeMessage< ::tensorflow::serving::MultiInferenceLog >(GetArenaForAllocation());
  }
  return _impl_.log_type_.multi_inference_log_;
}
inline ::tensorflow::serving::MultiInferenceLog* PredictionLog::mutable_multi_inference_log() {
  ::tensorflow::serving::MultiInferenceLog* _msg = _internal_mutable_multi_inference_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.multi_inference_log)
  return _msg;
}

// .tensorflow.serving.SessionRunLog session_run_log = 5;
inline bool PredictionLog::_internal_has_session_run_log() const {
  return log_type_case() == kSessionRunLog;
}
inline bool PredictionLog::has_session_run_log() const {
  return _internal_has_session_run_log();
}
inline void PredictionLog::set_has_session_run_log() {
  _impl_._oneof_case_[0] = kSessionRunLog;
}
inline void PredictionLog::clear_session_run_log() {
  if (_internal_has_session_run_log()) {
    if (GetArenaForAllocation() == nullptr) {
      delete _impl_.log_type_.session_run_log_;
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::SessionRunLog* PredictionLog::release_session_run_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.session_run_log)
  if (_internal_has_session_run_log()) {
    clear_has_log_type();
    ::tensorflow::serving::SessionRunLog* temp = _impl_.log_type_.session_run_log_;
    if (GetArenaForAllocation() != nullptr) {
      temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.session_run_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::SessionRunLog& PredictionLog::_internal_session_run_log() const {
  return _internal_has_session_run_log()
      ? *_impl_.log_type_.session_run_log_
      : reinterpret_cast< ::tensorflow::serving::SessionRunLog&>(::tensorflow::serving::_SessionRunLog_default_instance_);
}
inline const ::tensorflow::serving::SessionRunLog& PredictionLog::session_run_log() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.session_run_log)
  return _internal_session_run_log();
}
inline ::tensorflow::serving::SessionRunLog* PredictionLog::unsafe_arena_release_session_run_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.session_run_log)
  if (_internal_has_session_run_log()) {
    clear_has_log_type();
    ::tensorflow::serving::SessionRunLog* temp = _impl_.log_type_.session_run_log_;
    _impl_.log_type_.session_run_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_session_run_log(::tensorflow::serving::SessionRunLog* session_run_log) {
  clear_log_type();
  if (session_run_log) {
    set_has_session_run_log();
    _impl_.log_type_.session_run_log_ = session_run_log;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.session_run_log)
}
inline ::tensorflow::serving::SessionRunLog* PredictionLog::_internal_mutable_session_run_log() {
  if (!_internal_has_session_run_log()) {
    clear_log_type();
    set_has_session_run_log();
    _impl_.log_type_.session_run_log_ = CreateMaybeMessage< ::tensorflow::serving::SessionRunLog >(GetArenaForAllocation());
  }
  return _impl_.log_type_.session_run_log_;
}
inline ::tensorflow::serving::SessionRunLog* PredictionLog::mutable_session_run_log() {
  ::tensorflow::serving::SessionRunLog* _msg = _internal_mutable_session_run_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.session_run_log)
  return _msg;
}

inline bool PredictionLog::has_log_type() const {
  return log_type_case() != LOG_TYPE_NOT_SET;
}
inline void PredictionLog::clear_has_log_type() {
  _impl_._oneof_case_[0] = LOG_TYPE_NOT_SET;
}
inline PredictionLog::LogTypeCase PredictionLog::log_type_case() const {
  return PredictionLog::LogTypeCase(_impl_._oneof_case_[0]);
}
#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace serving
}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)

#include <google/protobuf/port_undef.inc>
#endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto
