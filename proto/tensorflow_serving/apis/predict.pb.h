// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/predict.proto

#ifndef GOOGLE_PROTOBUF_INCLUDED_tensorflow_5fserving_2fapis_2fpredict_2eproto
#define GOOGLE_PROTOBUF_INCLUDED_tensorflow_5fserving_2fapis_2fpredict_2eproto

#include <limits>
#include <string>

#include <google/protobuf/port_def.inc>
#if PROTOBUF_VERSION < 3021000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers. Please update
#error your headers.
#endif
#if 3021012 < PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers. Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/port_undef.inc>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/metadata_lite.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/map.h>  // IWYU pragma: export
#include <google/protobuf/map_entry.h>
#include <google/protobuf/map_field_inl.h>
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
#include "tensorflow/core/framework/tensor.pb.h"
#include "tensorflow_serving/apis/model.pb.h"
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
#define PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fpredict_2eproto
PROTOBUF_NAMESPACE_OPEN
namespace internal {
class AnyMetadata;
}  // namespace internal
PROTOBUF_NAMESPACE_CLOSE

// Internal implementation detail -- do not use these members.
struct TableStruct_tensorflow_5fserving_2fapis_2fpredict_2eproto {
  static const uint32_t offsets[];
};
extern const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto;
namespace tensorflow {
namespace serving {
class PredictRequest;
struct PredictRequestDefaultTypeInternal;
extern PredictRequestDefaultTypeInternal _PredictRequest_default_instance_;
class PredictRequest_InputsEntry_DoNotUse;
struct PredictRequest_InputsEntry_DoNotUseDefaultTypeInternal;
extern PredictRequest_InputsEntry_DoNotUseDefaultTypeInternal _PredictRequest_InputsEntry_DoNotUse_default_instance_;
class PredictRequest_RequestOptions;
struct PredictRequest_RequestOptionsDefaultTypeInternal;
extern PredictRequest_RequestOptionsDefaultTypeInternal _PredictRequest_RequestOptions_default_instance_;
class PredictResponse;
struct PredictResponseDefaultTypeInternal;
extern PredictResponseDefaultTypeInternal _PredictResponse_default_instance_;
class PredictResponse_OutputsEntry_DoNotUse;
struct PredictResponse_OutputsEntry_DoNotUseDefaultTypeInternal;
extern PredictResponse_OutputsEntry_DoNotUseDefaultTypeInternal _PredictResponse_OutputsEntry_DoNotUse_default_instance_;
class PredictStreamedOptions;
struct PredictStreamedOptionsDefaultTypeInternal;
extern PredictStreamedOptionsDefaultTypeInternal _PredictStreamedOptions_default_instance_;
class PredictStreamedOptions_SplitDimensionsEntry_DoNotUse;
struct PredictStreamedOptions_SplitDimensionsEntry_DoNotUseDefaultTypeInternal;
extern PredictStreamedOptions_SplitDimensionsEntry_DoNotUseDefaultTypeInternal _PredictStreamedOptions_SplitDimensionsEntry_DoNotUse_default_instance_;
}  // namespace serving
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
template<> ::tensorflow::serving::PredictRequest* Arena::CreateMaybeMessage<::tensorflow::serving::PredictRequest>(Arena*);
template<> ::tensorflow::serving::PredictRequest_InputsEntry_DoNotUse* Arena::CreateMaybeMessage<::tensorflow::serving::PredictRequest_InputsEntry_DoNotUse>(Arena*);
template<> ::tensorflow::serving::PredictRequest_RequestOptions* Arena::CreateMaybeMessage<::tensorflow::serving::PredictRequest_RequestOptions>(Arena*);
template<> ::tensorflow::serving::PredictResponse* Arena::CreateMaybeMessage<::tensorflow::serving::PredictResponse>(Arena*);
template<> ::tensorflow::serving::PredictResponse_OutputsEntry_DoNotUse* Arena::CreateMaybeMessage<::tensorflow::serving::PredictResponse_OutputsEntry_DoNotUse>(Arena*);
template<> ::tensorflow::serving::PredictStreamedOptions* Arena::CreateMaybeMessage<::tensorflow::serving::PredictStreamedOptions>(Arena*);
template<> ::tensorflow::serving::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse* Arena::CreateMaybeMessage<::tensorflow::serving::PredictStreamedOptions_SplitDimensionsEntry_DoNotUse>(Arena*);
PROTOBUF_NAMESPACE_CLOSE
namespace tensorflow {
namespace serving {

enum PredictRequest_RequestOptions_DeterministicMode : int {
  PredictRequest_RequestOptions_DeterministicMode_DETERMINISTIC_MODE_UNSPECIFIED = 0,
  PredictRequest_RequestOptions_DeterministicMode_FIXED_DECODER_SLOT = 1,
  PredictRequest_RequestOptions_DeterministicMode_PredictRequest_RequestOptions_DeterministicMode_INT_MIN_SENTINEL_DO_NOT_USE_ = std::numeric_limits<int32_t>::min(),
  PredictRequest_RequestOptions_DeterministicMode_PredictRequest_RequestOptions_DeterministicMode_INT_MAX_SENTINEL_DO_NOT_USE_ = std::numeric_limits<int32_t>::max()
};
bool PredictRequest_RequestOptions_DeterministicMode_IsValid(int value);
constexpr PredictRequest_RequestOptions_DeterministicMode PredictRequest_RequestOptions_DeterministicMode_DeterministicMode_MIN = PredictRequest_RequestOptions_DeterministicMode_DETERMINISTIC_MODE_UNSPECIFIED;
constexpr PredictRequest_RequestOptions_DeterministicMode PredictRequest_RequestOptions_DeterministicMode_DeterministicMode_MAX = PredictRequest_RequestOptions_DeterministicMode_FIXED_DECODER_SLOT;
constexpr int PredictRequest_RequestOptions_DeterministicMode_DeterministicMode_ARRAYSIZE = PredictRequest_RequestOptions_DeterministicMode_DeterministicMode_MAX + 1;

const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* PredictRequest_RequestOptions_DeterministicMode_descriptor();
template<typename T>
inline const std::string& PredictRequest_RequestOptions_DeterministicMode_Name(T enum_t_value) {
  static_assert(::std::is_same<T, PredictRequest_RequestOptions_DeterministicMode>::value ||
    ::std::is_integral<T>::value,
    "Incorrect type passed to function PredictRequest_RequestOptions_DeterministicMode_Name.");
  return ::PROTOBUF_NAMESPACE_ID::internal::NameOfEnum(
    PredictRequest_RequestOptions_DeterministicMode_descriptor(), enum_t_value);
}
inline bool PredictRequest_RequestOptions_DeterministicMode_Parse(
    ::PROTOBUF_NAMESPACE_ID::ConstStringParam name, PredictRequest_RequestOptions_DeterministicMode* value) {
  return ::PROTOBUF_NAMESPACE_ID::internal::ParseNamedEnum<PredictRequest_RequestOptions_DeterministicMode>(
    PredictRequest_RequestOptions_DeterministicMode_descriptor(), name, value);
}
enum PredictStreamedOptions_RequestState : int {
  PredictStreamedOptions_RequestState_NONE = 0,
  PredictStreamedOptions_RequestState_SPLIT = 1,
  PredictStreamedOptions_RequestState_END_SPLIT = 2,
  PredictStreamedOptions_RequestState_PredictStreamedOptions_RequestState_INT_MIN_SENTINEL_DO_NOT_USE_ = std::numeric_limits<int32_t>::min(),
  PredictStreamedOptions_RequestState_PredictStreamedOptions_RequestState_INT_MAX_SENTINEL_DO_NOT_USE_ = std::numeric_limits<int32_t>::max()
};
bool PredictStreamedOptions_RequestState_IsValid(int value);
constexpr PredictStreamedOptions_RequestState PredictStreamedOptions_RequestState_RequestState_MIN = PredictStreamedOptions_RequestState_NONE;
constexpr PredictStreamedOptions_RequestState PredictStreamedOptions_RequestState_RequestState_MAX = PredictStreamedOptions_RequestState_END_SPLIT;
constexpr int PredictStreamedOptions_RequestState_RequestState_ARRAYSIZE = PredictStreamedOptions_RequestState_RequestState_MAX + 1;

const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* PredictStreamedOptions_RequestState_descriptor();
template<typename T>
inline const std::string& PredictStreamedOptions_RequestState_Name(T enum_t_value) {
  static_assert(::std::is_same<T, PredictStreamedOptions_RequestState>::value ||
    ::std::is_integral<T>::value,
    "Incorrect type passed to function PredictStreamedOptions_RequestState_Name.");
  return ::PROTOBUF_NAMESPACE_ID::internal::NameOfEnum(
    PredictStreamedOptions_RequestState_descriptor(), enum_t_value);
}
inline bool PredictStreamedOptions_RequestState_Parse(
    ::PROTOBUF_NAMESPACE_ID::ConstStringParam name, PredictStreamedOptions_RequestState* value) {
  return ::PROTOBUF_NAMESPACE_ID::internal::ParseNamedEnum<PredictStreamedOptions_RequestState>(
    PredictStreamedOptions_RequestState_descriptor(), name, value);
}
// ===================================================================

class PredictRequest_InputsEntry_DoNotUse : public ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<PredictRequest_InputsEntry_DoNotUse, 
    std::string, ::tensorflow::TensorProto,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> {
public:
  typedef ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<PredictRequest_InputsEntry_DoNotUse, 
    std::string, ::tensorflow::TensorProto,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> SuperType;
  PredictRequest_InputsEntry_DoNotUse();
  explicit PROTOBUF_CONSTEXPR PredictRequest_InputsEntry_DoNotUse(
      ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);
  explicit PredictRequest_InputsEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  void MergeFrom(const PredictRequest_InputsEntry_DoNotUse& other);
  static const PredictRequest_InputsEntry_DoNotUse* internal_default_instance() { return reinterpret_cast<const PredictRequest_InputsEntry_DoNotUse*>(&_PredictRequest_InputsEntry_DoNotUse_default_instance_); }
  static bool ValidateKey(std::string* s) {
    return ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(s->data(), static_cast<int>(s->size()), ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::PARSE, "tensorflow.serving.PredictRequest.InputsEntry.key");
 }
  static bool ValidateValue(void*) { return true; }
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fpredict_2eproto;
};

// -------------------------------------------------------------------

class PredictRequest_RequestOptions final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.PredictRequest.RequestOptions) */ {
 public:
  inline PredictRequest_RequestOptions() : PredictRequest_RequestOptions(nullptr) {}
  ~PredictRequest_RequestOptions() override;
  explicit PROTOBUF_CONSTEXPR PredictRequest_RequestOptions(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  PredictRequest_RequestOptions(const PredictRequest_RequestOptions& from);
  PredictRequest_RequestOptions(PredictRequest_RequestOptions&& from) noexcept
    : PredictRequest_RequestOptions() {
    *this = ::std::move(from);
  }

  inline PredictRequest_RequestOptions& operator=(const PredictRequest_RequestOptions& from) {
    CopyFrom(from);
    return *this;
  }
  inline PredictRequest_RequestOptions& operator=(PredictRequest_RequestOptions&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const PredictRequest_RequestOptions& default_instance() {
    return *internal_default_instance();
  }
  static inline const PredictRequest_RequestOptions* internal_default_instance() {
    return reinterpret_cast<const PredictRequest_RequestOptions*>(
               &_PredictRequest_RequestOptions_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  friend void swap(PredictRequest_RequestOptions& a, PredictRequest_RequestOptions& b) {
    a.Swap(&b);
  }
  inline void Swap(PredictRequest_RequestOptions* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(PredictRequest_RequestOptions* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  PredictRequest_RequestOptions* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<PredictRequest_RequestOptions>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const PredictRequest_RequestOptions& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const PredictRequest_RequestOptions& from) {
    PredictRequest_RequestOptions::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(PredictRequest_RequestOptions* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.PredictRequest.RequestOptions";
  }
  protected:
  explicit PredictRequest_RequestOptions(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef PredictRequest_RequestOptions_DeterministicMode DeterministicMode;
  static constexpr DeterministicMode DETERMINISTIC_MODE_UNSPECIFIED =
    PredictRequest_RequestOptions_DeterministicMode_DETERMINISTIC_MODE_UNSPECIFIED;
  static constexpr DeterministicMode FIXED_DECODER_SLOT =
    PredictRequest_RequestOptions_DeterministicMode_FIXED_DECODER_SLOT;
  static inline bool DeterministicMode_IsValid(int value) {
    return PredictRequest_RequestOptions_DeterministicMode_IsValid(value);
  }
  static constexpr DeterministicMode DeterministicMode_MIN =
    PredictRequest_RequestOptions_DeterministicMode_DeterministicMode_MIN;
  static constexpr DeterministicMode DeterministicMode_MAX =
    PredictRequest_RequestOptions_DeterministicMode_DeterministicMode_MAX;
  static constexpr int DeterministicMode_ARRAYSIZE =
    PredictRequest_RequestOptions_DeterministicMode_DeterministicMode_ARRAYSIZE;
  static inline const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor*
  DeterministicMode_descriptor() {
    return PredictRequest_RequestOptions_DeterministicMode_descriptor();
  }
  template<typename T>
  static inline const std::string& DeterministicMode_Name(T enum_t_value) {
    static_assert(::std::is_same<T, DeterministicMode>::value ||
      ::std::is_integral<T>::value,
      "Incorrect type passed to function DeterministicMode_Name.");
    return PredictRequest_RequestOptions_DeterministicMode_Name(enum_t_value);
  }
  static inline bool DeterministicMode_Parse(::PROTOBUF_NAMESPACE_ID::ConstStringParam name,
      DeterministicMode* value) {
    return PredictRequest_RequestOptions_DeterministicMode_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  enum : int {
    kClientIdFieldNumber = 1,
    kDeterministicModeFieldNumber = 2,
  };
  // optional bytes client_id = 1;
  bool has_client_id() const;
  private:
  bool _internal_has_client_id() const;
  public:
  void clear_client_id();
  const std::string& client_id() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_client_id(ArgT0&& arg0, ArgT... args);
  std::string* mutable_client_id();
  PROTOBUF_NODISCARD std::string* release_client_id();
  void set_allocated_client_id(std::string* client_id);
  private:
  const std::string& _internal_client_id() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_client_id(const std::string& value);
  std::string* _internal_mutable_client_id();
  public:

  // optional .tensorflow.serving.PredictRequest.RequestOptions.DeterministicMode deterministic_mode = 2;
  bool has_deterministic_mode() const;
  private:
  bool _internal_has_deterministic_mode() const;
  public:
  void clear_deterministic_mode();
  ::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode deterministic_mode() const;
  void set_deterministic_mode(::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode value);
  private:
  ::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode _internal_deterministic_mode() const;
  void _internal_set_deterministic_mode(::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode value);
  public:

  // @@protoc_insertion_point(class_scope:tensorflow.serving.PredictRequest.RequestOptions)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::PROTOBUF_NAMESPACE_ID::internal::HasBits<1> _has_bits_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr client_id_;
    int deterministic_mode_;
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fpredict_2eproto;
};
// -------------------------------------------------------------------

class PredictRequest final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.PredictRequest) */ {
 public:
  inline PredictRequest() : PredictRequest(nullptr) {}
  ~PredictRequest() override;
  explicit PROTOBUF_CONSTEXPR PredictRequest(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  PredictRequest(const PredictRequest& from);
  PredictRequest(PredictRequest&& from) noexcept
    : PredictRequest() {
    *this = ::std::move(from);
  }

  inline PredictRequest& operator=(const PredictRequest& from) {
    CopyFrom(from);
    return *this;
  }
  inline PredictRequest& operator=(PredictRequest&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const PredictRequest& default_instance() {
    return *internal_default_instance();
  }
  static inline const PredictRequest* internal_default_instance() {
    return reinterpret_cast<const PredictRequest*>(
               &_PredictRequest_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  friend void swap(PredictRequest& a, PredictRequest& b) {
    a.Swap(&b);
  }
  inline void Swap(PredictRequest* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(PredictRequest* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  PredictRequest* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<PredictRequest>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const PredictRequest& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const PredictRequest& from) {
    PredictRequest::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(PredictRequest* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.PredictRequest";
  }
  protected:
  explicit PredictRequest(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef PredictRequest_RequestOptions RequestOptions;

  // accessors -------------------------------------------------------

  enum : int {
    kInputsFieldNumber = 2,
    kOutputFilterFieldNumber = 3,
    kClientIdFieldNumber = 6,
    kModelSpecFieldNumber = 1,
    kPredictStreamedOptionsFieldNumber = 5,
    kRequestOptionsFieldNumber = 7,
  };
  // map<string, .tensorflow.TensorProto> inputs = 2;
  int inputs_size() const;
  private:
  int _internal_inputs_size() const;
  public:
  void clear_inputs();
  private:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >&
      _internal_inputs() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >*
      _internal_mutable_inputs();
  public:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >&
      inputs() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >*
      mutable_inputs();

  // repeated string output_filter = 3;
  int output_filter_size() const;
  private:
  int _internal_output_filter_size() const;
  public:
  void clear_output_filter();
  const std::string& output_filter(int index) const;
  std::string* mutable_output_filter(int index);
  void set_output_filter(int index, const std::string& value);
  void set_output_filter(int index, std::string&& value);
  void set_output_filter(int index, const char* value);
  void set_output_filter(int index, const char* value, size_t size);
  std::string* add_output_filter();
  void add_output_filter(const std::string& value);
  void add_output_filter(std::string&& value);
  void add_output_filter(const char* value);
  void add_output_filter(const char* value, size_t size);
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>& output_filter() const;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>* mutable_output_filter();
  private:
  const std::string& _internal_output_filter(int index) const;
  std::string* _internal_add_output_filter();
  public:

  // optional bytes client_id = 6;
  bool has_client_id() const;
  private:
  bool _internal_has_client_id() const;
  public:
  void clear_client_id();
  const std::string& client_id() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_client_id(ArgT0&& arg0, ArgT... args);
  std::string* mutable_client_id();
  PROTOBUF_NODISCARD std::string* release_client_id();
  void set_allocated_client_id(std::string* client_id);
  private:
  const std::string& _internal_client_id() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_client_id(const std::string& value);
  std::string* _internal_mutable_client_id();
  public:

  // .tensorflow.serving.ModelSpec model_spec = 1;
  bool has_model_spec() const;
  private:
  bool _internal_has_model_spec() const;
  public:
  void clear_model_spec();
  const ::tensorflow::serving::ModelSpec& model_spec() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::ModelSpec* release_model_spec();
  ::tensorflow::serving::ModelSpec* mutable_model_spec();
  void set_allocated_model_spec(::tensorflow::serving::ModelSpec* model_spec);
  private:
  const ::tensorflow::serving::ModelSpec& _internal_model_spec() const;
  ::tensorflow::serving::ModelSpec* _internal_mutable_model_spec();
  public:
  void unsafe_arena_set_allocated_model_spec(
      ::tensorflow::serving::ModelSpec* model_spec);
  ::tensorflow::serving::ModelSpec* unsafe_arena_release_model_spec();

  // .tensorflow.serving.PredictStreamedOptions predict_streamed_options = 5;
  bool has_predict_streamed_options() const;
  private:
  bool _internal_has_predict_streamed_options() const;
  public:
  void clear_predict_streamed_options();
  const ::tensorflow::serving::PredictStreamedOptions& predict_streamed_options() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::PredictStreamedOptions* release_predict_streamed_options();
  ::tensorflow::serving::PredictStreamedOptions* mutable_predict_streamed_options();
  void set_allocated_predict_streamed_options(::tensorflow::serving::PredictStreamedOptions* predict_streamed_options);
  private:
  const ::tensorflow::serving::PredictStreamedOptions& _internal_predict_streamed_options() const;
  ::tensorflow::serving::PredictStreamedOptions* _internal_mutable_predict_streamed_options();
  public:
  void unsafe_arena_set_allocated_predict_streamed_options(
      ::tensorflow::serving::PredictStreamedOptions* predict_streamed_options);
  ::tensorflow::serving::PredictStreamedOptions* unsafe_arena_release_predict_streamed_options();

  // optional .tensorflow.serving.PredictRequest.RequestOptions request_options = 7;
  bool has_request_options() const;
  private:
  bool _internal_has_request_options() const;
  public:
  void clear_request_options();
  const ::tensorflow::serving::PredictRequest_RequestOptions& request_options() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::PredictRequest_RequestOptions* release_request_options();
  ::tensorflow::serving::PredictRequest_RequestOptions* mutable_request_options();
  void set_allocated_request_options(::tensorflow::serving::PredictRequest_RequestOptions* request_options);
  private:
  const ::tensorflow::serving::PredictRequest_RequestOptions& _internal_request_options() const;
  ::tensorflow::serving::PredictRequest_RequestOptions* _internal_mutable_request_options();
  public:
  void unsafe_arena_set_allocated_request_options(
      ::tensorflow::serving::PredictRequest_RequestOptions* request_options);
  ::tensorflow::serving::PredictRequest_RequestOptions* unsafe_arena_release_request_options();

  // @@protoc_insertion_point(class_scope:tensorflow.serving.PredictRequest)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::PROTOBUF_NAMESPACE_ID::internal::HasBits<1> _has_bits_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
    ::PROTOBUF_NAMESPACE_ID::internal::MapField<
        PredictRequest_InputsEntry_DoNotUse,
        std::string, ::tensorflow::TensorProto,
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> inputs_;
    ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string> output_filter_;
    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr client_id_;
    ::tensorflow::serving::ModelSpec* model_spec_;
    ::tensorflow::serving::PredictStreamedOptions* predict_streamed_options_;
    ::tensorflow::serving::PredictRequest_RequestOptions* request_options_;
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fpredict_2eproto;
};
// -------------------------------------------------------------------

class PredictStreamedOptions_SplitDimensionsEntry_DoNotUse : public ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<PredictStreamedOptions_SplitDimensionsEntry_DoNotUse, 
    std::string, int32_t,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_INT32> {
public:
  typedef ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<PredictStreamedOptions_SplitDimensionsEntry_DoNotUse, 
    std::string, int32_t,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_INT32> SuperType;
  PredictStreamedOptions_SplitDimensionsEntry_DoNotUse();
  explicit PROTOBUF_CONSTEXPR PredictStreamedOptions_SplitDimensionsEntry_DoNotUse(
      ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);
  explicit PredictStreamedOptions_SplitDimensionsEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  void MergeFrom(const PredictStreamedOptions_SplitDimensionsEntry_DoNotUse& other);
  static const PredictStreamedOptions_SplitDimensionsEntry_DoNotUse* internal_default_instance() { return reinterpret_cast<const PredictStreamedOptions_SplitDimensionsEntry_DoNotUse*>(&_PredictStreamedOptions_SplitDimensionsEntry_DoNotUse_default_instance_); }
  static bool ValidateKey(std::string* s) {
    return ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(s->data(), static_cast<int>(s->size()), ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::PARSE, "tensorflow.serving.PredictStreamedOptions.SplitDimensionsEntry.key");
 }
  static bool ValidateValue(void*) { return true; }
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fpredict_2eproto;
};

// -------------------------------------------------------------------

class PredictStreamedOptions final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.PredictStreamedOptions) */ {
 public:
  inline PredictStreamedOptions() : PredictStreamedOptions(nullptr) {}
  ~PredictStreamedOptions() override;
  explicit PROTOBUF_CONSTEXPR PredictStreamedOptions(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  PredictStreamedOptions(const PredictStreamedOptions& from);
  PredictStreamedOptions(PredictStreamedOptions&& from) noexcept
    : PredictStreamedOptions() {
    *this = ::std::move(from);
  }

  inline PredictStreamedOptions& operator=(const PredictStreamedOptions& from) {
    CopyFrom(from);
    return *this;
  }
  inline PredictStreamedOptions& operator=(PredictStreamedOptions&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const PredictStreamedOptions& default_instance() {
    return *internal_default_instance();
  }
  static inline const PredictStreamedOptions* internal_default_instance() {
    return reinterpret_cast<const PredictStreamedOptions*>(
               &_PredictStreamedOptions_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    4;

  friend void swap(PredictStreamedOptions& a, PredictStreamedOptions& b) {
    a.Swap(&b);
  }
  inline void Swap(PredictStreamedOptions* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(PredictStreamedOptions* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  PredictStreamedOptions* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<PredictStreamedOptions>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const PredictStreamedOptions& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const PredictStreamedOptions& from) {
    PredictStreamedOptions::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(PredictStreamedOptions* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.PredictStreamedOptions";
  }
  protected:
  explicit PredictStreamedOptions(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------


  typedef PredictStreamedOptions_RequestState RequestState;
  static constexpr RequestState NONE =
    PredictStreamedOptions_RequestState_NONE;
  static constexpr RequestState SPLIT =
    PredictStreamedOptions_RequestState_SPLIT;
  static constexpr RequestState END_SPLIT =
    PredictStreamedOptions_RequestState_END_SPLIT;
  static inline bool RequestState_IsValid(int value) {
    return PredictStreamedOptions_RequestState_IsValid(value);
  }
  static constexpr RequestState RequestState_MIN =
    PredictStreamedOptions_RequestState_RequestState_MIN;
  static constexpr RequestState RequestState_MAX =
    PredictStreamedOptions_RequestState_RequestState_MAX;
  static constexpr int RequestState_ARRAYSIZE =
    PredictStreamedOptions_RequestState_RequestState_ARRAYSIZE;
  static inline const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor*
  RequestState_descriptor() {
    return PredictStreamedOptions_RequestState_descriptor();
  }
  template<typename T>
  static inline const std::string& RequestState_Name(T enum_t_value) {
    static_assert(::std::is_same<T, RequestState>::value ||
      ::std::is_integral<T>::value,
      "Incorrect type passed to function RequestState_Name.");
    return PredictStreamedOptions_RequestState_Name(enum_t_value);
  }
  static inline bool RequestState_Parse(::PROTOBUF_NAMESPACE_ID::ConstStringParam name,
      RequestState* value) {
    return PredictStreamedOptions_RequestState_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  enum : int {
    kSplitDimensionsFieldNumber = 2,
    kRequestStateFieldNumber = 1,
    kReturnSingleResponseFieldNumber = 3,
  };
  // map<string, int32> split_dimensions = 2;
  int split_dimensions_size() const;
  private:
  int _internal_split_dimensions_size() const;
  public:
  void clear_split_dimensions();
  private:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, int32_t >&
      _internal_split_dimensions() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, int32_t >*
      _internal_mutable_split_dimensions();
  public:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, int32_t >&
      split_dimensions() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, int32_t >*
      mutable_split_dimensions();

  // .tensorflow.serving.PredictStreamedOptions.RequestState request_state = 1;
  void clear_request_state();
  ::tensorflow::serving::PredictStreamedOptions_RequestState request_state() const;
  void set_request_state(::tensorflow::serving::PredictStreamedOptions_RequestState value);
  private:
  ::tensorflow::serving::PredictStreamedOptions_RequestState _internal_request_state() const;
  void _internal_set_request_state(::tensorflow::serving::PredictStreamedOptions_RequestState value);
  public:

  // bool return_single_response = 3;
  void clear_return_single_response();
  bool return_single_response() const;
  void set_return_single_response(bool value);
  private:
  bool _internal_return_single_response() const;
  void _internal_set_return_single_response(bool value);
  public:

  // @@protoc_insertion_point(class_scope:tensorflow.serving.PredictStreamedOptions)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::PROTOBUF_NAMESPACE_ID::internal::MapField<
        PredictStreamedOptions_SplitDimensionsEntry_DoNotUse,
        std::string, int32_t,
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_INT32> split_dimensions_;
    int request_state_;
    bool return_single_response_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fpredict_2eproto;
};
// -------------------------------------------------------------------

class PredictResponse_OutputsEntry_DoNotUse : public ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<PredictResponse_OutputsEntry_DoNotUse, 
    std::string, ::tensorflow::TensorProto,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> {
public:
  typedef ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<PredictResponse_OutputsEntry_DoNotUse, 
    std::string, ::tensorflow::TensorProto,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> SuperType;
  PredictResponse_OutputsEntry_DoNotUse();
  explicit PROTOBUF_CONSTEXPR PredictResponse_OutputsEntry_DoNotUse(
      ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);
  explicit PredictResponse_OutputsEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  void MergeFrom(const PredictResponse_OutputsEntry_DoNotUse& other);
  static const PredictResponse_OutputsEntry_DoNotUse* internal_default_instance() { return reinterpret_cast<const PredictResponse_OutputsEntry_DoNotUse*>(&_PredictResponse_OutputsEntry_DoNotUse_default_instance_); }
  static bool ValidateKey(std::string* s) {
    return ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(s->data(), static_cast<int>(s->size()), ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::PARSE, "tensorflow.serving.PredictResponse.OutputsEntry.key");
 }
  static bool ValidateValue(void*) { return true; }
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fpredict_2eproto;
};

// -------------------------------------------------------------------

class PredictResponse final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:tensorflow.serving.PredictResponse) */ {
 public:
  inline PredictResponse() : PredictResponse(nullptr) {}
  ~PredictResponse() override;
  explicit PROTOBUF_CONSTEXPR PredictResponse(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  PredictResponse(const PredictResponse& from);
  PredictResponse(PredictResponse&& from) noexcept
    : PredictResponse() {
    *this = ::std::move(from);
  }

  inline PredictResponse& operator=(const PredictResponse& from) {
    CopyFrom(from);
    return *this;
  }
  inline PredictResponse& operator=(PredictResponse&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const PredictResponse& default_instance() {
    return *internal_default_instance();
  }
  static inline const PredictResponse* internal_default_instance() {
    return reinterpret_cast<const PredictResponse*>(
               &_PredictResponse_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    6;

  friend void swap(PredictResponse& a, PredictResponse& b) {
    a.Swap(&b);
  }
  inline void Swap(PredictResponse* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(PredictResponse* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  PredictResponse* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<PredictResponse>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const PredictResponse& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom( const PredictResponse& from) {
    PredictResponse::MergeImpl(*this, from);
  }
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(PredictResponse* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "tensorflow.serving.PredictResponse";
  }
  protected:
  explicit PredictResponse(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------


  // accessors -------------------------------------------------------

  enum : int {
    kOutputsFieldNumber = 1,
    kModelSpecFieldNumber = 2,
  };
  // map<string, .tensorflow.TensorProto> outputs = 1;
  int outputs_size() const;
  private:
  int _internal_outputs_size() const;
  public:
  void clear_outputs();
  private:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >&
      _internal_outputs() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >*
      _internal_mutable_outputs();
  public:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >&
      outputs() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >*
      mutable_outputs();

  // .tensorflow.serving.ModelSpec model_spec = 2;
  bool has_model_spec() const;
  private:
  bool _internal_has_model_spec() const;
  public:
  void clear_model_spec();
  const ::tensorflow::serving::ModelSpec& model_spec() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::ModelSpec* release_model_spec();
  ::tensorflow::serving::ModelSpec* mutable_model_spec();
  void set_allocated_model_spec(::tensorflow::serving::ModelSpec* model_spec);
  private:
  const ::tensorflow::serving::ModelSpec& _internal_model_spec() const;
  ::tensorflow::serving::ModelSpec* _internal_mutable_model_spec();
  public:
  void unsafe_arena_set_allocated_model_spec(
      ::tensorflow::serving::ModelSpec* model_spec);
  ::tensorflow::serving::ModelSpec* unsafe_arena_release_model_spec();

  // @@protoc_insertion_point(class_scope:tensorflow.serving.PredictResponse)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  struct Impl_ {
    ::PROTOBUF_NAMESPACE_ID::internal::MapField<
        PredictResponse_OutputsEntry_DoNotUse,
        std::string, ::tensorflow::TensorProto,
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> outputs_;
    ::tensorflow::serving::ModelSpec* model_spec_;
    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fpredict_2eproto;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// -------------------------------------------------------------------

// PredictRequest_RequestOptions

// optional bytes client_id = 1;
inline bool PredictRequest_RequestOptions::_internal_has_client_id() const {
  bool value = (_impl_._has_bits_[0] & 0x00000001u) != 0;
  return value;
}
inline bool PredictRequest_RequestOptions::has_client_id() const {
  return _internal_has_client_id();
}
inline void PredictRequest_RequestOptions::clear_client_id() {
  _impl_.client_id_.ClearToEmpty();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
inline const std::string& PredictRequest_RequestOptions::client_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictRequest.RequestOptions.client_id)
  return _internal_client_id();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void PredictRequest_RequestOptions::set_client_id(ArgT0&& arg0, ArgT... args) {
 _impl_._has_bits_[0] |= 0x00000001u;
 _impl_.client_id_.SetBytes(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:tensorflow.serving.PredictRequest.RequestOptions.client_id)
}
inline std::string* PredictRequest_RequestOptions::mutable_client_id() {
  std::string* _s = _internal_mutable_client_id();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictRequest.RequestOptions.client_id)
  return _s;
}
inline const std::string& PredictRequest_RequestOptions::_internal_client_id() const {
  return _impl_.client_id_.Get();
}
inline void PredictRequest_RequestOptions::_internal_set_client_id(const std::string& value) {
  _impl_._has_bits_[0] |= 0x00000001u;
  _impl_.client_id_.Set(value, GetArenaForAllocation());
}
inline std::string* PredictRequest_RequestOptions::_internal_mutable_client_id() {
  _impl_._has_bits_[0] |= 0x00000001u;
  return _impl_.client_id_.Mutable(GetArenaForAllocation());
}
inline std::string* PredictRequest_RequestOptions::release_client_id() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictRequest.RequestOptions.client_id)
  if (!_internal_has_client_id()) {
    return nullptr;
  }
  _impl_._has_bits_[0] &= ~0x00000001u;
  auto* p = _impl_.client_id_.Release();
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (_impl_.client_id_.IsDefault()) {
    _impl_.client_id_.Set("", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  return p;
}
inline void PredictRequest_RequestOptions::set_allocated_client_id(std::string* client_id) {
  if (client_id != nullptr) {
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }
  _impl_.client_id_.SetAllocated(client_id, GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (_impl_.client_id_.IsDefault()) {
    _impl_.client_id_.Set("", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictRequest.RequestOptions.client_id)
}

// optional .tensorflow.serving.PredictRequest.RequestOptions.DeterministicMode deterministic_mode = 2;
inline bool PredictRequest_RequestOptions::_internal_has_deterministic_mode() const {
  bool value = (_impl_._has_bits_[0] & 0x00000002u) != 0;
  return value;
}
inline bool PredictRequest_RequestOptions::has_deterministic_mode() const {
  return _internal_has_deterministic_mode();
}
inline void PredictRequest_RequestOptions::clear_deterministic_mode() {
  _impl_.deterministic_mode_ = 0;
  _impl_._has_bits_[0] &= ~0x00000002u;
}
inline ::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode PredictRequest_RequestOptions::_internal_deterministic_mode() const {
  return static_cast< ::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode >(_impl_.deterministic_mode_);
}
inline ::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode PredictRequest_RequestOptions::deterministic_mode() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictRequest.RequestOptions.deterministic_mode)
  return _internal_deterministic_mode();
}
inline void PredictRequest_RequestOptions::_internal_set_deterministic_mode(::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode value) {
  _impl_._has_bits_[0] |= 0x00000002u;
  _impl_.deterministic_mode_ = value;
}
inline void PredictRequest_RequestOptions::set_deterministic_mode(::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode value) {
  _internal_set_deterministic_mode(value);
  // @@protoc_insertion_point(field_set:tensorflow.serving.PredictRequest.RequestOptions.deterministic_mode)
}

// -------------------------------------------------------------------

// PredictRequest

// .tensorflow.serving.ModelSpec model_spec = 1;
inline bool PredictRequest::_internal_has_model_spec() const {
  return this != internal_default_instance() && _impl_.model_spec_ != nullptr;
}
inline bool PredictRequest::has_model_spec() const {
  return _internal_has_model_spec();
}
inline const ::tensorflow::serving::ModelSpec& PredictRequest::_internal_model_spec() const {
  const ::tensorflow::serving::ModelSpec* p = _impl_.model_spec_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::ModelSpec&>(
      ::tensorflow::serving::_ModelSpec_default_instance_);
}
inline const ::tensorflow::serving::ModelSpec& PredictRequest::model_spec() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictRequest.model_spec)
  return _internal_model_spec();
}
inline void PredictRequest::unsafe_arena_set_allocated_model_spec(
    ::tensorflow::serving::ModelSpec* model_spec) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.model_spec_);
  }
  _impl_.model_spec_ = model_spec;
  if (model_spec) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictRequest.model_spec)
}
inline ::tensorflow::serving::ModelSpec* PredictRequest::release_model_spec() {
  
  ::tensorflow::serving::ModelSpec* temp = _impl_.model_spec_;
  _impl_.model_spec_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::ModelSpec* PredictRequest::unsafe_arena_release_model_spec() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictRequest.model_spec)
  
  ::tensorflow::serving::ModelSpec* temp = _impl_.model_spec_;
  _impl_.model_spec_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::ModelSpec* PredictRequest::_internal_mutable_model_spec() {
  
  if (_impl_.model_spec_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::ModelSpec>(GetArenaForAllocation());
    _impl_.model_spec_ = p;
  }
  return _impl_.model_spec_;
}
inline ::tensorflow::serving::ModelSpec* PredictRequest::mutable_model_spec() {
  ::tensorflow::serving::ModelSpec* _msg = _internal_mutable_model_spec();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictRequest.model_spec)
  return _msg;
}
inline void PredictRequest::set_allocated_model_spec(::tensorflow::serving::ModelSpec* model_spec) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.model_spec_);
  }
  if (model_spec) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(model_spec));
    if (message_arena != submessage_arena) {
      model_spec = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, model_spec, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.model_spec_ = model_spec;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictRequest.model_spec)
}

// map<string, .tensorflow.TensorProto> inputs = 2;
inline int PredictRequest::_internal_inputs_size() const {
  return _impl_.inputs_.size();
}
inline int PredictRequest::inputs_size() const {
  return _internal_inputs_size();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >&
PredictRequest::_internal_inputs() const {
  return _impl_.inputs_.GetMap();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >&
PredictRequest::inputs() const {
  // @@protoc_insertion_point(field_map:tensorflow.serving.PredictRequest.inputs)
  return _internal_inputs();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >*
PredictRequest::_internal_mutable_inputs() {
  return _impl_.inputs_.MutableMap();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >*
PredictRequest::mutable_inputs() {
  // @@protoc_insertion_point(field_mutable_map:tensorflow.serving.PredictRequest.inputs)
  return _internal_mutable_inputs();
}

// repeated string output_filter = 3;
inline int PredictRequest::_internal_output_filter_size() const {
  return _impl_.output_filter_.size();
}
inline int PredictRequest::output_filter_size() const {
  return _internal_output_filter_size();
}
inline void PredictRequest::clear_output_filter() {
  _impl_.output_filter_.Clear();
}
inline std::string* PredictRequest::add_output_filter() {
  std::string* _s = _internal_add_output_filter();
  // @@protoc_insertion_point(field_add_mutable:tensorflow.serving.PredictRequest.output_filter)
  return _s;
}
inline const std::string& PredictRequest::_internal_output_filter(int index) const {
  return _impl_.output_filter_.Get(index);
}
inline const std::string& PredictRequest::output_filter(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictRequest.output_filter)
  return _internal_output_filter(index);
}
inline std::string* PredictRequest::mutable_output_filter(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictRequest.output_filter)
  return _impl_.output_filter_.Mutable(index);
}
inline void PredictRequest::set_output_filter(int index, const std::string& value) {
  _impl_.output_filter_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set:tensorflow.serving.PredictRequest.output_filter)
}
inline void PredictRequest::set_output_filter(int index, std::string&& value) {
  _impl_.output_filter_.Mutable(index)->assign(std::move(value));
  // @@protoc_insertion_point(field_set:tensorflow.serving.PredictRequest.output_filter)
}
inline void PredictRequest::set_output_filter(int index, const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  _impl_.output_filter_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.PredictRequest.output_filter)
}
inline void PredictRequest::set_output_filter(int index, const char* value, size_t size) {
  _impl_.output_filter_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.PredictRequest.output_filter)
}
inline std::string* PredictRequest::_internal_add_output_filter() {
  return _impl_.output_filter_.Add();
}
inline void PredictRequest::add_output_filter(const std::string& value) {
  _impl_.output_filter_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.serving.PredictRequest.output_filter)
}
inline void PredictRequest::add_output_filter(std::string&& value) {
  _impl_.output_filter_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:tensorflow.serving.PredictRequest.output_filter)
}
inline void PredictRequest::add_output_filter(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  _impl_.output_filter_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.serving.PredictRequest.output_filter)
}
inline void PredictRequest::add_output_filter(const char* value, size_t size) {
  _impl_.output_filter_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.serving.PredictRequest.output_filter)
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>&
PredictRequest::output_filter() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.PredictRequest.output_filter)
  return _impl_.output_filter_;
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>*
PredictRequest::mutable_output_filter() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.PredictRequest.output_filter)
  return &_impl_.output_filter_;
}

// .tensorflow.serving.PredictStreamedOptions predict_streamed_options = 5;
inline bool PredictRequest::_internal_has_predict_streamed_options() const {
  return this != internal_default_instance() && _impl_.predict_streamed_options_ != nullptr;
}
inline bool PredictRequest::has_predict_streamed_options() const {
  return _internal_has_predict_streamed_options();
}
inline void PredictRequest::clear_predict_streamed_options() {
  if (GetArenaForAllocation() == nullptr && _impl_.predict_streamed_options_ != nullptr) {
    delete _impl_.predict_streamed_options_;
  }
  _impl_.predict_streamed_options_ = nullptr;
}
inline const ::tensorflow::serving::PredictStreamedOptions& PredictRequest::_internal_predict_streamed_options() const {
  const ::tensorflow::serving::PredictStreamedOptions* p = _impl_.predict_streamed_options_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::PredictStreamedOptions&>(
      ::tensorflow::serving::_PredictStreamedOptions_default_instance_);
}
inline const ::tensorflow::serving::PredictStreamedOptions& PredictRequest::predict_streamed_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictRequest.predict_streamed_options)
  return _internal_predict_streamed_options();
}
inline void PredictRequest::unsafe_arena_set_allocated_predict_streamed_options(
    ::tensorflow::serving::PredictStreamedOptions* predict_streamed_options) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.predict_streamed_options_);
  }
  _impl_.predict_streamed_options_ = predict_streamed_options;
  if (predict_streamed_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictRequest.predict_streamed_options)
}
inline ::tensorflow::serving::PredictStreamedOptions* PredictRequest::release_predict_streamed_options() {
  
  ::tensorflow::serving::PredictStreamedOptions* temp = _impl_.predict_streamed_options_;
  _impl_.predict_streamed_options_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::PredictStreamedOptions* PredictRequest::unsafe_arena_release_predict_streamed_options() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictRequest.predict_streamed_options)
  
  ::tensorflow::serving::PredictStreamedOptions* temp = _impl_.predict_streamed_options_;
  _impl_.predict_streamed_options_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::PredictStreamedOptions* PredictRequest::_internal_mutable_predict_streamed_options() {
  
  if (_impl_.predict_streamed_options_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::PredictStreamedOptions>(GetArenaForAllocation());
    _impl_.predict_streamed_options_ = p;
  }
  return _impl_.predict_streamed_options_;
}
inline ::tensorflow::serving::PredictStreamedOptions* PredictRequest::mutable_predict_streamed_options() {
  ::tensorflow::serving::PredictStreamedOptions* _msg = _internal_mutable_predict_streamed_options();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictRequest.predict_streamed_options)
  return _msg;
}
inline void PredictRequest::set_allocated_predict_streamed_options(::tensorflow::serving::PredictStreamedOptions* predict_streamed_options) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete _impl_.predict_streamed_options_;
  }
  if (predict_streamed_options) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(predict_streamed_options);
    if (message_arena != submessage_arena) {
      predict_streamed_options = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, predict_streamed_options, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.predict_streamed_options_ = predict_streamed_options;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictRequest.predict_streamed_options)
}

// optional bytes client_id = 6;
inline bool PredictRequest::_internal_has_client_id() const {
  bool value = (_impl_._has_bits_[0] & 0x00000001u) != 0;
  return value;
}
inline bool PredictRequest::has_client_id() const {
  return _internal_has_client_id();
}
inline void PredictRequest::clear_client_id() {
  _impl_.client_id_.ClearToEmpty();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
inline const std::string& PredictRequest::client_id() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictRequest.client_id)
  return _internal_client_id();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void PredictRequest::set_client_id(ArgT0&& arg0, ArgT... args) {
 _impl_._has_bits_[0] |= 0x00000001u;
 _impl_.client_id_.SetBytes(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:tensorflow.serving.PredictRequest.client_id)
}
inline std::string* PredictRequest::mutable_client_id() {
  std::string* _s = _internal_mutable_client_id();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictRequest.client_id)
  return _s;
}
inline const std::string& PredictRequest::_internal_client_id() const {
  return _impl_.client_id_.Get();
}
inline void PredictRequest::_internal_set_client_id(const std::string& value) {
  _impl_._has_bits_[0] |= 0x00000001u;
  _impl_.client_id_.Set(value, GetArenaForAllocation());
}
inline std::string* PredictRequest::_internal_mutable_client_id() {
  _impl_._has_bits_[0] |= 0x00000001u;
  return _impl_.client_id_.Mutable(GetArenaForAllocation());
}
inline std::string* PredictRequest::release_client_id() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictRequest.client_id)
  if (!_internal_has_client_id()) {
    return nullptr;
  }
  _impl_._has_bits_[0] &= ~0x00000001u;
  auto* p = _impl_.client_id_.Release();
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (_impl_.client_id_.IsDefault()) {
    _impl_.client_id_.Set("", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  return p;
}
inline void PredictRequest::set_allocated_client_id(std::string* client_id) {
  if (client_id != nullptr) {
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }
  _impl_.client_id_.SetAllocated(client_id, GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (_impl_.client_id_.IsDefault()) {
    _impl_.client_id_.Set("", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictRequest.client_id)
}

// optional .tensorflow.serving.PredictRequest.RequestOptions request_options = 7;
inline bool PredictRequest::_internal_has_request_options() const {
  bool value = (_impl_._has_bits_[0] & 0x00000002u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.request_options_ != nullptr);
  return value;
}
inline bool PredictRequest::has_request_options() const {
  return _internal_has_request_options();
}
inline void PredictRequest::clear_request_options() {
  if (_impl_.request_options_ != nullptr) _impl_.request_options_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002u;
}
inline const ::tensorflow::serving::PredictRequest_RequestOptions& PredictRequest::_internal_request_options() const {
  const ::tensorflow::serving::PredictRequest_RequestOptions* p = _impl_.request_options_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::PredictRequest_RequestOptions&>(
      ::tensorflow::serving::_PredictRequest_RequestOptions_default_instance_);
}
inline const ::tensorflow::serving::PredictRequest_RequestOptions& PredictRequest::request_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictRequest.request_options)
  return _internal_request_options();
}
inline void PredictRequest::unsafe_arena_set_allocated_request_options(
    ::tensorflow::serving::PredictRequest_RequestOptions* request_options) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.request_options_);
  }
  _impl_.request_options_ = request_options;
  if (request_options) {
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictRequest.request_options)
}
inline ::tensorflow::serving::PredictRequest_RequestOptions* PredictRequest::release_request_options() {
  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::PredictRequest_RequestOptions* temp = _impl_.request_options_;
  _impl_.request_options_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::PredictRequest_RequestOptions* PredictRequest::unsafe_arena_release_request_options() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictRequest.request_options)
  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::PredictRequest_RequestOptions* temp = _impl_.request_options_;
  _impl_.request_options_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::PredictRequest_RequestOptions* PredictRequest::_internal_mutable_request_options() {
  _impl_._has_bits_[0] |= 0x00000002u;
  if (_impl_.request_options_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::PredictRequest_RequestOptions>(GetArenaForAllocation());
    _impl_.request_options_ = p;
  }
  return _impl_.request_options_;
}
inline ::tensorflow::serving::PredictRequest_RequestOptions* PredictRequest::mutable_request_options() {
  ::tensorflow::serving::PredictRequest_RequestOptions* _msg = _internal_mutable_request_options();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictRequest.request_options)
  return _msg;
}
inline void PredictRequest::set_allocated_request_options(::tensorflow::serving::PredictRequest_RequestOptions* request_options) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete _impl_.request_options_;
  }
  if (request_options) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(request_options);
    if (message_arena != submessage_arena) {
      request_options = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, request_options, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }
  _impl_.request_options_ = request_options;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictRequest.request_options)
}

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// PredictStreamedOptions

// .tensorflow.serving.PredictStreamedOptions.RequestState request_state = 1;
inline void PredictStreamedOptions::clear_request_state() {
  _impl_.request_state_ = 0;
}
inline ::tensorflow::serving::PredictStreamedOptions_RequestState PredictStreamedOptions::_internal_request_state() const {
  return static_cast< ::tensorflow::serving::PredictStreamedOptions_RequestState >(_impl_.request_state_);
}
inline ::tensorflow::serving::PredictStreamedOptions_RequestState PredictStreamedOptions::request_state() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictStreamedOptions.request_state)
  return _internal_request_state();
}
inline void PredictStreamedOptions::_internal_set_request_state(::tensorflow::serving::PredictStreamedOptions_RequestState value) {
  
  _impl_.request_state_ = value;
}
inline void PredictStreamedOptions::set_request_state(::tensorflow::serving::PredictStreamedOptions_RequestState value) {
  _internal_set_request_state(value);
  // @@protoc_insertion_point(field_set:tensorflow.serving.PredictStreamedOptions.request_state)
}

// map<string, int32> split_dimensions = 2;
inline int PredictStreamedOptions::_internal_split_dimensions_size() const {
  return _impl_.split_dimensions_.size();
}
inline int PredictStreamedOptions::split_dimensions_size() const {
  return _internal_split_dimensions_size();
}
inline void PredictStreamedOptions::clear_split_dimensions() {
  _impl_.split_dimensions_.Clear();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, int32_t >&
PredictStreamedOptions::_internal_split_dimensions() const {
  return _impl_.split_dimensions_.GetMap();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, int32_t >&
PredictStreamedOptions::split_dimensions() const {
  // @@protoc_insertion_point(field_map:tensorflow.serving.PredictStreamedOptions.split_dimensions)
  return _internal_split_dimensions();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, int32_t >*
PredictStreamedOptions::_internal_mutable_split_dimensions() {
  return _impl_.split_dimensions_.MutableMap();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, int32_t >*
PredictStreamedOptions::mutable_split_dimensions() {
  // @@protoc_insertion_point(field_mutable_map:tensorflow.serving.PredictStreamedOptions.split_dimensions)
  return _internal_mutable_split_dimensions();
}

// bool return_single_response = 3;
inline void PredictStreamedOptions::clear_return_single_response() {
  _impl_.return_single_response_ = false;
}
inline bool PredictStreamedOptions::_internal_return_single_response() const {
  return _impl_.return_single_response_;
}
inline bool PredictStreamedOptions::return_single_response() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictStreamedOptions.return_single_response)
  return _internal_return_single_response();
}
inline void PredictStreamedOptions::_internal_set_return_single_response(bool value) {
  
  _impl_.return_single_response_ = value;
}
inline void PredictStreamedOptions::set_return_single_response(bool value) {
  _internal_set_return_single_response(value);
  // @@protoc_insertion_point(field_set:tensorflow.serving.PredictStreamedOptions.return_single_response)
}

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// PredictResponse

// .tensorflow.serving.ModelSpec model_spec = 2;
inline bool PredictResponse::_internal_has_model_spec() const {
  return this != internal_default_instance() && _impl_.model_spec_ != nullptr;
}
inline bool PredictResponse::has_model_spec() const {
  return _internal_has_model_spec();
}
inline const ::tensorflow::serving::ModelSpec& PredictResponse::_internal_model_spec() const {
  const ::tensorflow::serving::ModelSpec* p = _impl_.model_spec_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::ModelSpec&>(
      ::tensorflow::serving::_ModelSpec_default_instance_);
}
inline const ::tensorflow::serving::ModelSpec& PredictResponse::model_spec() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictResponse.model_spec)
  return _internal_model_spec();
}
inline void PredictResponse::unsafe_arena_set_allocated_model_spec(
    ::tensorflow::serving::ModelSpec* model_spec) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.model_spec_);
  }
  _impl_.model_spec_ = model_spec;
  if (model_spec) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictResponse.model_spec)
}
inline ::tensorflow::serving::ModelSpec* PredictResponse::release_model_spec() {
  
  ::tensorflow::serving::ModelSpec* temp = _impl_.model_spec_;
  _impl_.model_spec_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::tensorflow::serving::ModelSpec* PredictResponse::unsafe_arena_release_model_spec() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictResponse.model_spec)
  
  ::tensorflow::serving::ModelSpec* temp = _impl_.model_spec_;
  _impl_.model_spec_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::ModelSpec* PredictResponse::_internal_mutable_model_spec() {
  
  if (_impl_.model_spec_ == nullptr) {
    auto* p = CreateMaybeMessage<::tensorflow::serving::ModelSpec>(GetArenaForAllocation());
    _impl_.model_spec_ = p;
  }
  return _impl_.model_spec_;
}
inline ::tensorflow::serving::ModelSpec* PredictResponse::mutable_model_spec() {
  ::tensorflow::serving::ModelSpec* _msg = _internal_mutable_model_spec();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictResponse.model_spec)
  return _msg;
}
inline void PredictResponse::set_allocated_model_spec(::tensorflow::serving::ModelSpec* model_spec) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.model_spec_);
  }
  if (model_spec) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(model_spec));
    if (message_arena != submessage_arena) {
      model_spec = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, model_spec, submessage_arena);
    }
    
  } else {
    
  }
  _impl_.model_spec_ = model_spec;
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictResponse.model_spec)
}

// map<string, .tensorflow.TensorProto> outputs = 1;
inline int PredictResponse::_internal_outputs_size() const {
  return _impl_.outputs_.size();
}
inline int PredictResponse::outputs_size() const {
  return _internal_outputs_size();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >&
PredictResponse::_internal_outputs() const {
  return _impl_.outputs_.GetMap();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >&
PredictResponse::outputs() const {
  // @@protoc_insertion_point(field_map:tensorflow.serving.PredictResponse.outputs)
  return _internal_outputs();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >*
PredictResponse::_internal_mutable_outputs() {
  return _impl_.outputs_.MutableMap();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::tensorflow::TensorProto >*
PredictResponse::mutable_outputs() {
  // @@protoc_insertion_point(field_mutable_map:tensorflow.serving.PredictResponse.outputs)
  return _internal_mutable_outputs();
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace serving
}  // namespace tensorflow

PROTOBUF_NAMESPACE_OPEN

template <> struct is_proto_enum< ::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode>() {
  return ::tensorflow::serving::PredictRequest_RequestOptions_DeterministicMode_descriptor();
}
template <> struct is_proto_enum< ::tensorflow::serving::PredictStreamedOptions_RequestState> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::tensorflow::serving::PredictStreamedOptions_RequestState>() {
  return ::tensorflow::serving::PredictStreamedOptions_RequestState_descriptor();
}

PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)

#include <google/protobuf/port_undef.inc>
#endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_tensorflow_5fserving_2fapis_2fpredict_2eproto
