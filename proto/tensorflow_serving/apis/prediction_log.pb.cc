// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/apis/prediction_log.proto

#include "tensorflow_serving/apis/prediction_log.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG

namespace _pb = ::PROTOBUF_NAMESPACE_ID;
namespace _pbi = _pb::internal;

namespace tensorflow {
namespace serving {
PROTOBUF_CONSTEXPR ClassifyLog::ClassifyLog(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.request_)*/nullptr
  , /*decltype(_impl_.response_)*/nullptr
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct ClassifyLogDefaultTypeInternal {
  PROTOBUF_CONSTEXPR ClassifyLogDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~ClassifyLogDefaultTypeInternal() {}
  union {
    ClassifyLog _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 ClassifyLogDefaultTypeInternal _ClassifyLog_default_instance_;
PROTOBUF_CONSTEXPR RegressLog::RegressLog(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.request_)*/nullptr
  , /*decltype(_impl_.response_)*/nullptr
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct RegressLogDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RegressLogDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~RegressLogDefaultTypeInternal() {}
  union {
    RegressLog _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RegressLogDefaultTypeInternal _RegressLog_default_instance_;
PROTOBUF_CONSTEXPR PredictLog::PredictLog(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.request_)*/nullptr
  , /*decltype(_impl_.response_)*/nullptr
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct PredictLogDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PredictLogDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~PredictLogDefaultTypeInternal() {}
  union {
    PredictLog _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PredictLogDefaultTypeInternal _PredictLog_default_instance_;
PROTOBUF_CONSTEXPR PredictStreamedLog::PredictStreamedLog(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.request_)*/{}
  , /*decltype(_impl_.response_)*/{}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct PredictStreamedLogDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PredictStreamedLogDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~PredictStreamedLogDefaultTypeInternal() {}
  union {
    PredictStreamedLog _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PredictStreamedLogDefaultTypeInternal _PredictStreamedLog_default_instance_;
PROTOBUF_CONSTEXPR MultiInferenceLog::MultiInferenceLog(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.request_)*/nullptr
  , /*decltype(_impl_.response_)*/nullptr
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct MultiInferenceLogDefaultTypeInternal {
  PROTOBUF_CONSTEXPR MultiInferenceLogDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~MultiInferenceLogDefaultTypeInternal() {}
  union {
    MultiInferenceLog _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 MultiInferenceLogDefaultTypeInternal _MultiInferenceLog_default_instance_;
PROTOBUF_CONSTEXPR SessionRunLog::SessionRunLog(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.request_)*/nullptr
  , /*decltype(_impl_.response_)*/nullptr
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct SessionRunLogDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SessionRunLogDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~SessionRunLogDefaultTypeInternal() {}
  union {
    SessionRunLog _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SessionRunLogDefaultTypeInternal _SessionRunLog_default_instance_;
PROTOBUF_CONSTEXPR PredictionLog::PredictionLog(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.log_metadata_)*/nullptr
  , /*decltype(_impl_.log_type_)*/{}
  , /*decltype(_impl_._cached_size_)*/{}
  , /*decltype(_impl_._oneof_case_)*/{}} {}
struct PredictionLogDefaultTypeInternal {
  PROTOBUF_CONSTEXPR PredictionLogDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~PredictionLogDefaultTypeInternal() {}
  union {
    PredictionLog _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 PredictionLogDefaultTypeInternal _PredictionLog_default_instance_;
}  // namespace serving
}  // namespace tensorflow
static ::_pb::Metadata file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[7];
static constexpr ::_pb::EnumDescriptor const** file_level_enum_descriptors_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto = nullptr;
static constexpr ::_pb::ServiceDescriptor const** file_level_service_descriptors_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto = nullptr;

const uint32_t TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::ClassifyLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::ClassifyLog, _impl_.request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::ClassifyLog, _impl_.response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::RegressLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::RegressLog, _impl_.request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::RegressLog, _impl_.response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictLog, _impl_.request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictLog, _impl_.response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedLog, _impl_.request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictStreamedLog, _impl_.response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::MultiInferenceLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::MultiInferenceLog, _impl_.request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::MultiInferenceLog, _impl_.response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::SessionRunLog, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::SessionRunLog, _impl_.request_),
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::SessionRunLog, _impl_.response_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictionLog, _internal_metadata_),
  ~0u,  // no _extensions_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictionLog, _impl_._oneof_case_[0]),
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictionLog, _impl_.log_metadata_),
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  ::_pbi::kInvalidFieldOffsetTag,
  PROTOBUF_FIELD_OFFSET(::tensorflow::serving::PredictionLog, _impl_.log_type_),
};
static const ::_pbi::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, -1, sizeof(::tensorflow::serving::ClassifyLog)},
  { 8, -1, -1, sizeof(::tensorflow::serving::RegressLog)},
  { 16, -1, -1, sizeof(::tensorflow::serving::PredictLog)},
  { 24, -1, -1, sizeof(::tensorflow::serving::PredictStreamedLog)},
  { 32, -1, -1, sizeof(::tensorflow::serving::MultiInferenceLog)},
  { 40, -1, -1, sizeof(::tensorflow::serving::SessionRunLog)},
  { 48, -1, -1, sizeof(::tensorflow::serving::PredictionLog)},
};

static const ::_pb::Message* const file_default_instances[] = {
  &::tensorflow::serving::_ClassifyLog_default_instance_._instance,
  &::tensorflow::serving::_RegressLog_default_instance_._instance,
  &::tensorflow::serving::_PredictLog_default_instance_._instance,
  &::tensorflow::serving::_PredictStreamedLog_default_instance_._instance,
  &::tensorflow::serving::_MultiInferenceLog_default_instance_._instance,
  &::tensorflow::serving::_SessionRunLog_default_instance_._instance,
  &::tensorflow::serving::_PredictionLog_default_instance_._instance,
};

const char descriptor_table_protodef_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n,tensorflow_serving/apis/prediction_log"
  ".proto\022\022tensorflow.serving\032,tensorflow_s"
  "erving/apis/classification.proto\032\'tensor"
  "flow_serving/apis/inference.proto\032%tenso"
  "rflow_serving/apis/logging.proto\032%tensor"
  "flow_serving/apis/predict.proto\032(tensorf"
  "low_serving/apis/regression.proto\032-tenso"
  "rflow_serving/apis/session_service.proto"
  "\"\207\001\n\013ClassifyLog\022:\n\007request\030\001 \001(\0132).tens"
  "orflow.serving.ClassificationRequest\022<\n\010"
  "response\030\002 \001(\0132*.tensorflow.serving.Clas"
  "sificationResponse\"~\n\nRegressLog\0226\n\007requ"
  "est\030\001 \001(\0132%.tensorflow.serving.Regressio"
  "nRequest\0228\n\010response\030\002 \001(\0132&.tensorflow."
  "serving.RegressionResponse\"x\n\nPredictLog"
  "\0223\n\007request\030\001 \001(\0132\".tensorflow.serving.P"
  "redictRequest\0225\n\010response\030\002 \001(\0132#.tensor"
  "flow.serving.PredictResponse\"\200\001\n\022Predict"
  "StreamedLog\0223\n\007request\030\001 \003(\0132\".tensorflo"
  "w.serving.PredictRequest\0225\n\010response\030\002 \003"
  "(\0132#.tensorflow.serving.PredictResponse\""
  "\215\001\n\021MultiInferenceLog\022:\n\007request\030\001 \001(\0132)"
  ".tensorflow.serving.MultiInferenceReques"
  "t\022<\n\010response\030\002 \001(\0132*.tensorflow.serving"
  ".MultiInferenceResponse\"\201\001\n\rSessionRunLo"
  "g\0226\n\007request\030\001 \001(\0132%.tensorflow.serving."
  "SessionRunRequest\0228\n\010response\030\002 \001(\0132&.te"
  "nsorflow.serving.SessionRunResponse\"\305\003\n\r"
  "PredictionLog\0225\n\014log_metadata\030\001 \001(\0132\037.te"
  "nsorflow.serving.LogMetadata\0227\n\014classify"
  "_log\030\002 \001(\0132\037.tensorflow.serving.Classify"
  "LogH\000\0225\n\013regress_log\030\003 \001(\0132\036.tensorflow."
  "serving.RegressLogH\000\0225\n\013predict_log\030\006 \001("
  "\0132\036.tensorflow.serving.PredictLogH\000\022F\n\024p"
  "redict_streamed_log\030\007 \001(\0132&.tensorflow.s"
  "erving.PredictStreamedLogH\000\022D\n\023multi_inf"
  "erence_log\030\004 \001(\0132%.tensorflow.serving.Mu"
  "ltiInferenceLogH\000\022<\n\017session_run_log\030\005 \001"
  "(\0132!.tensorflow.serving.SessionRunLogH\000B"
  "\n\n\010log_typeB\003\370\001\001b\006proto3"
  ;
static const ::_pbi::DescriptorTable* const descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_deps[6] = {
  &::descriptor_table_tensorflow_5fserving_2fapis_2fclassification_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fapis_2finference_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fapis_2flogging_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fapis_2fpredict_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fapis_2fregression_2eproto,
  &::descriptor_table_tensorflow_5fserving_2fapis_2fsession_5fservice_2eproto,
};
static ::_pbi::once_flag descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once;
const ::_pbi::DescriptorTable descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto = {
    false, false, 1584, descriptor_table_protodef_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto,
    "tensorflow_serving/apis/prediction_log.proto",
    &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once, descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_deps, 6, 7,
    schemas, file_default_instances, TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto::offsets,
    file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto, file_level_enum_descriptors_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto,
    file_level_service_descriptors_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::_pbi::DescriptorTable* descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_getter() {
  return &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::_pbi::AddDescriptorsRunner dynamic_init_dummy_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto(&descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto);
namespace tensorflow {
namespace serving {

// ===================================================================

class ClassifyLog::_Internal {
 public:
  static const ::tensorflow::serving::ClassificationRequest& request(const ClassifyLog* msg);
  static const ::tensorflow::serving::ClassificationResponse& response(const ClassifyLog* msg);
};

const ::tensorflow::serving::ClassificationRequest&
ClassifyLog::_Internal::request(const ClassifyLog* msg) {
  return *msg->_impl_.request_;
}
const ::tensorflow::serving::ClassificationResponse&
ClassifyLog::_Internal::response(const ClassifyLog* msg) {
  return *msg->_impl_.response_;
}
void ClassifyLog::clear_request() {
  if (GetArenaForAllocation() == nullptr && _impl_.request_ != nullptr) {
    delete _impl_.request_;
  }
  _impl_.request_ = nullptr;
}
void ClassifyLog::clear_response() {
  if (GetArenaForAllocation() == nullptr && _impl_.response_ != nullptr) {
    delete _impl_.response_;
  }
  _impl_.response_ = nullptr;
}
ClassifyLog::ClassifyLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ClassifyLog)
}
ClassifyLog::ClassifyLog(const ClassifyLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  ClassifyLog* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){nullptr}
    , decltype(_impl_.response_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_request()) {
    _this->_impl_.request_ = new ::tensorflow::serving::ClassificationRequest(*from._impl_.request_);
  }
  if (from._internal_has_response()) {
    _this->_impl_.response_ = new ::tensorflow::serving::ClassificationResponse(*from._impl_.response_);
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ClassifyLog)
}

inline void ClassifyLog::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){nullptr}
    , decltype(_impl_.response_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

ClassifyLog::~ClassifyLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ClassifyLog)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void ClassifyLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete _impl_.request_;
  if (this != internal_default_instance()) delete _impl_.response_;
}

void ClassifyLog::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void ClassifyLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ClassifyLog)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && _impl_.request_ != nullptr) {
    delete _impl_.request_;
  }
  _impl_.request_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.response_ != nullptr) {
    delete _impl_.response_;
  }
  _impl_.response_ = nullptr;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ClassifyLog::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.serving.ClassificationRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_request(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.ClassificationResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_response(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ClassifyLog::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ClassifyLog)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.ClassificationRequest request = 1;
  if (this->_internal_has_request()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, _Internal::request(this),
        _Internal::request(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.ClassificationResponse response = 2;
  if (this->_internal_has_response()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::response(this),
        _Internal::response(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ClassifyLog)
  return target;
}

size_t ClassifyLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ClassifyLog)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.ClassificationRequest request = 1;
  if (this->_internal_has_request()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.request_);
  }

  // .tensorflow.serving.ClassificationResponse response = 2;
  if (this->_internal_has_response()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.response_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ClassifyLog::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    ClassifyLog::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ClassifyLog::GetClassData() const { return &_class_data_; }


void ClassifyLog::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<ClassifyLog*>(&to_msg);
  auto& from = static_cast<const ClassifyLog&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ClassifyLog)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_request()) {
    _this->_internal_mutable_request()->::tensorflow::serving::ClassificationRequest::MergeFrom(
        from._internal_request());
  }
  if (from._internal_has_response()) {
    _this->_internal_mutable_response()->::tensorflow::serving::ClassificationResponse::MergeFrom(
        from._internal_response());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ClassifyLog::CopyFrom(const ClassifyLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ClassifyLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ClassifyLog::IsInitialized() const {
  return true;
}

void ClassifyLog::InternalSwap(ClassifyLog* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(ClassifyLog, _impl_.response_)
      + sizeof(ClassifyLog::_impl_.response_)
      - PROTOBUF_FIELD_OFFSET(ClassifyLog, _impl_.request_)>(
          reinterpret_cast<char*>(&_impl_.request_),
          reinterpret_cast<char*>(&other->_impl_.request_));
}

::PROTOBUF_NAMESPACE_ID::Metadata ClassifyLog::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[0]);
}

// ===================================================================

class RegressLog::_Internal {
 public:
  static const ::tensorflow::serving::RegressionRequest& request(const RegressLog* msg);
  static const ::tensorflow::serving::RegressionResponse& response(const RegressLog* msg);
};

const ::tensorflow::serving::RegressionRequest&
RegressLog::_Internal::request(const RegressLog* msg) {
  return *msg->_impl_.request_;
}
const ::tensorflow::serving::RegressionResponse&
RegressLog::_Internal::response(const RegressLog* msg) {
  return *msg->_impl_.response_;
}
void RegressLog::clear_request() {
  if (GetArenaForAllocation() == nullptr && _impl_.request_ != nullptr) {
    delete _impl_.request_;
  }
  _impl_.request_ = nullptr;
}
void RegressLog::clear_response() {
  if (GetArenaForAllocation() == nullptr && _impl_.response_ != nullptr) {
    delete _impl_.response_;
  }
  _impl_.response_ = nullptr;
}
RegressLog::RegressLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.RegressLog)
}
RegressLog::RegressLog(const RegressLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  RegressLog* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){nullptr}
    , decltype(_impl_.response_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_request()) {
    _this->_impl_.request_ = new ::tensorflow::serving::RegressionRequest(*from._impl_.request_);
  }
  if (from._internal_has_response()) {
    _this->_impl_.response_ = new ::tensorflow::serving::RegressionResponse(*from._impl_.response_);
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.RegressLog)
}

inline void RegressLog::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){nullptr}
    , decltype(_impl_.response_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

RegressLog::~RegressLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.RegressLog)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void RegressLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete _impl_.request_;
  if (this != internal_default_instance()) delete _impl_.response_;
}

void RegressLog::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void RegressLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.RegressLog)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && _impl_.request_ != nullptr) {
    delete _impl_.request_;
  }
  _impl_.request_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.response_ != nullptr) {
    delete _impl_.response_;
  }
  _impl_.response_ = nullptr;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* RegressLog::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.serving.RegressionRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_request(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.RegressionResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_response(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* RegressLog::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.RegressLog)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.RegressionRequest request = 1;
  if (this->_internal_has_request()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, _Internal::request(this),
        _Internal::request(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.RegressionResponse response = 2;
  if (this->_internal_has_response()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::response(this),
        _Internal::response(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.RegressLog)
  return target;
}

size_t RegressLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.RegressLog)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.RegressionRequest request = 1;
  if (this->_internal_has_request()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.request_);
  }

  // .tensorflow.serving.RegressionResponse response = 2;
  if (this->_internal_has_response()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.response_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData RegressLog::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    RegressLog::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*RegressLog::GetClassData() const { return &_class_data_; }


void RegressLog::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<RegressLog*>(&to_msg);
  auto& from = static_cast<const RegressLog&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.RegressLog)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_request()) {
    _this->_internal_mutable_request()->::tensorflow::serving::RegressionRequest::MergeFrom(
        from._internal_request());
  }
  if (from._internal_has_response()) {
    _this->_internal_mutable_response()->::tensorflow::serving::RegressionResponse::MergeFrom(
        from._internal_response());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void RegressLog::CopyFrom(const RegressLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.RegressLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RegressLog::IsInitialized() const {
  return true;
}

void RegressLog::InternalSwap(RegressLog* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RegressLog, _impl_.response_)
      + sizeof(RegressLog::_impl_.response_)
      - PROTOBUF_FIELD_OFFSET(RegressLog, _impl_.request_)>(
          reinterpret_cast<char*>(&_impl_.request_),
          reinterpret_cast<char*>(&other->_impl_.request_));
}

::PROTOBUF_NAMESPACE_ID::Metadata RegressLog::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[1]);
}

// ===================================================================

class PredictLog::_Internal {
 public:
  static const ::tensorflow::serving::PredictRequest& request(const PredictLog* msg);
  static const ::tensorflow::serving::PredictResponse& response(const PredictLog* msg);
};

const ::tensorflow::serving::PredictRequest&
PredictLog::_Internal::request(const PredictLog* msg) {
  return *msg->_impl_.request_;
}
const ::tensorflow::serving::PredictResponse&
PredictLog::_Internal::response(const PredictLog* msg) {
  return *msg->_impl_.response_;
}
void PredictLog::clear_request() {
  if (GetArenaForAllocation() == nullptr && _impl_.request_ != nullptr) {
    delete _impl_.request_;
  }
  _impl_.request_ = nullptr;
}
void PredictLog::clear_response() {
  if (GetArenaForAllocation() == nullptr && _impl_.response_ != nullptr) {
    delete _impl_.response_;
  }
  _impl_.response_ = nullptr;
}
PredictLog::PredictLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictLog)
}
PredictLog::PredictLog(const PredictLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  PredictLog* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){nullptr}
    , decltype(_impl_.response_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_request()) {
    _this->_impl_.request_ = new ::tensorflow::serving::PredictRequest(*from._impl_.request_);
  }
  if (from._internal_has_response()) {
    _this->_impl_.response_ = new ::tensorflow::serving::PredictResponse(*from._impl_.response_);
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictLog)
}

inline void PredictLog::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){nullptr}
    , decltype(_impl_.response_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

PredictLog::~PredictLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictLog)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void PredictLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete _impl_.request_;
  if (this != internal_default_instance()) delete _impl_.response_;
}

void PredictLog::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void PredictLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictLog)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && _impl_.request_ != nullptr) {
    delete _impl_.request_;
  }
  _impl_.request_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.response_ != nullptr) {
    delete _impl_.response_;
  }
  _impl_.response_ = nullptr;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* PredictLog::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.serving.PredictRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_request(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.PredictResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_response(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* PredictLog::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictLog)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.PredictRequest request = 1;
  if (this->_internal_has_request()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, _Internal::request(this),
        _Internal::request(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.PredictResponse response = 2;
  if (this->_internal_has_response()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::response(this),
        _Internal::response(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictLog)
  return target;
}

size_t PredictLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictLog)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.PredictRequest request = 1;
  if (this->_internal_has_request()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.request_);
  }

  // .tensorflow.serving.PredictResponse response = 2;
  if (this->_internal_has_response()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.response_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData PredictLog::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    PredictLog::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*PredictLog::GetClassData() const { return &_class_data_; }


void PredictLog::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<PredictLog*>(&to_msg);
  auto& from = static_cast<const PredictLog&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictLog)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_request()) {
    _this->_internal_mutable_request()->::tensorflow::serving::PredictRequest::MergeFrom(
        from._internal_request());
  }
  if (from._internal_has_response()) {
    _this->_internal_mutable_response()->::tensorflow::serving::PredictResponse::MergeFrom(
        from._internal_response());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void PredictLog::CopyFrom(const PredictLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictLog::IsInitialized() const {
  return true;
}

void PredictLog::InternalSwap(PredictLog* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(PredictLog, _impl_.response_)
      + sizeof(PredictLog::_impl_.response_)
      - PROTOBUF_FIELD_OFFSET(PredictLog, _impl_.request_)>(
          reinterpret_cast<char*>(&_impl_.request_),
          reinterpret_cast<char*>(&other->_impl_.request_));
}

::PROTOBUF_NAMESPACE_ID::Metadata PredictLog::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[2]);
}

// ===================================================================

class PredictStreamedLog::_Internal {
 public:
};

void PredictStreamedLog::clear_request() {
  _impl_.request_.Clear();
}
void PredictStreamedLog::clear_response() {
  _impl_.response_.Clear();
}
PredictStreamedLog::PredictStreamedLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictStreamedLog)
}
PredictStreamedLog::PredictStreamedLog(const PredictStreamedLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  PredictStreamedLog* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){from._impl_.request_}
    , decltype(_impl_.response_){from._impl_.response_}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictStreamedLog)
}

inline void PredictStreamedLog::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){arena}
    , decltype(_impl_.response_){arena}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

PredictStreamedLog::~PredictStreamedLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictStreamedLog)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void PredictStreamedLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.request_.~RepeatedPtrField();
  _impl_.response_.~RepeatedPtrField();
}

void PredictStreamedLog::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void PredictStreamedLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictStreamedLog)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.request_.Clear();
  _impl_.response_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* PredictStreamedLog::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // repeated .tensorflow.serving.PredictRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_request(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<10>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .tensorflow.serving.PredictResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_response(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<18>(ptr));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* PredictStreamedLog::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictStreamedLog)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated .tensorflow.serving.PredictRequest request = 1;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_request_size()); i < n; i++) {
    const auto& repfield = this->_internal_request(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(1, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated .tensorflow.serving.PredictResponse response = 2;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_response_size()); i < n; i++) {
    const auto& repfield = this->_internal_response(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(2, repfield, repfield.GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictStreamedLog)
  return target;
}

size_t PredictStreamedLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictStreamedLog)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .tensorflow.serving.PredictRequest request = 1;
  total_size += 1UL * this->_internal_request_size();
  for (const auto& msg : this->_impl_.request_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .tensorflow.serving.PredictResponse response = 2;
  total_size += 1UL * this->_internal_response_size();
  for (const auto& msg : this->_impl_.response_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData PredictStreamedLog::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    PredictStreamedLog::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*PredictStreamedLog::GetClassData() const { return &_class_data_; }


void PredictStreamedLog::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<PredictStreamedLog*>(&to_msg);
  auto& from = static_cast<const PredictStreamedLog&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictStreamedLog)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.request_.MergeFrom(from._impl_.request_);
  _this->_impl_.response_.MergeFrom(from._impl_.response_);
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void PredictStreamedLog::CopyFrom(const PredictStreamedLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictStreamedLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictStreamedLog::IsInitialized() const {
  return true;
}

void PredictStreamedLog::InternalSwap(PredictStreamedLog* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.request_.InternalSwap(&other->_impl_.request_);
  _impl_.response_.InternalSwap(&other->_impl_.response_);
}

::PROTOBUF_NAMESPACE_ID::Metadata PredictStreamedLog::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[3]);
}

// ===================================================================

class MultiInferenceLog::_Internal {
 public:
  static const ::tensorflow::serving::MultiInferenceRequest& request(const MultiInferenceLog* msg);
  static const ::tensorflow::serving::MultiInferenceResponse& response(const MultiInferenceLog* msg);
};

const ::tensorflow::serving::MultiInferenceRequest&
MultiInferenceLog::_Internal::request(const MultiInferenceLog* msg) {
  return *msg->_impl_.request_;
}
const ::tensorflow::serving::MultiInferenceResponse&
MultiInferenceLog::_Internal::response(const MultiInferenceLog* msg) {
  return *msg->_impl_.response_;
}
void MultiInferenceLog::clear_request() {
  if (GetArenaForAllocation() == nullptr && _impl_.request_ != nullptr) {
    delete _impl_.request_;
  }
  _impl_.request_ = nullptr;
}
void MultiInferenceLog::clear_response() {
  if (GetArenaForAllocation() == nullptr && _impl_.response_ != nullptr) {
    delete _impl_.response_;
  }
  _impl_.response_ = nullptr;
}
MultiInferenceLog::MultiInferenceLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.MultiInferenceLog)
}
MultiInferenceLog::MultiInferenceLog(const MultiInferenceLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  MultiInferenceLog* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){nullptr}
    , decltype(_impl_.response_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_request()) {
    _this->_impl_.request_ = new ::tensorflow::serving::MultiInferenceRequest(*from._impl_.request_);
  }
  if (from._internal_has_response()) {
    _this->_impl_.response_ = new ::tensorflow::serving::MultiInferenceResponse(*from._impl_.response_);
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.MultiInferenceLog)
}

inline void MultiInferenceLog::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){nullptr}
    , decltype(_impl_.response_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

MultiInferenceLog::~MultiInferenceLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.MultiInferenceLog)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void MultiInferenceLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete _impl_.request_;
  if (this != internal_default_instance()) delete _impl_.response_;
}

void MultiInferenceLog::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void MultiInferenceLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.MultiInferenceLog)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && _impl_.request_ != nullptr) {
    delete _impl_.request_;
  }
  _impl_.request_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.response_ != nullptr) {
    delete _impl_.response_;
  }
  _impl_.response_ = nullptr;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* MultiInferenceLog::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.serving.MultiInferenceRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_request(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.MultiInferenceResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_response(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* MultiInferenceLog::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.MultiInferenceLog)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.MultiInferenceRequest request = 1;
  if (this->_internal_has_request()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, _Internal::request(this),
        _Internal::request(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.MultiInferenceResponse response = 2;
  if (this->_internal_has_response()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::response(this),
        _Internal::response(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.MultiInferenceLog)
  return target;
}

size_t MultiInferenceLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.MultiInferenceLog)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.MultiInferenceRequest request = 1;
  if (this->_internal_has_request()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.request_);
  }

  // .tensorflow.serving.MultiInferenceResponse response = 2;
  if (this->_internal_has_response()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.response_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData MultiInferenceLog::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    MultiInferenceLog::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*MultiInferenceLog::GetClassData() const { return &_class_data_; }


void MultiInferenceLog::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<MultiInferenceLog*>(&to_msg);
  auto& from = static_cast<const MultiInferenceLog&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.MultiInferenceLog)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_request()) {
    _this->_internal_mutable_request()->::tensorflow::serving::MultiInferenceRequest::MergeFrom(
        from._internal_request());
  }
  if (from._internal_has_response()) {
    _this->_internal_mutable_response()->::tensorflow::serving::MultiInferenceResponse::MergeFrom(
        from._internal_response());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void MultiInferenceLog::CopyFrom(const MultiInferenceLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.MultiInferenceLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool MultiInferenceLog::IsInitialized() const {
  return true;
}

void MultiInferenceLog::InternalSwap(MultiInferenceLog* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(MultiInferenceLog, _impl_.response_)
      + sizeof(MultiInferenceLog::_impl_.response_)
      - PROTOBUF_FIELD_OFFSET(MultiInferenceLog, _impl_.request_)>(
          reinterpret_cast<char*>(&_impl_.request_),
          reinterpret_cast<char*>(&other->_impl_.request_));
}

::PROTOBUF_NAMESPACE_ID::Metadata MultiInferenceLog::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[4]);
}

// ===================================================================

class SessionRunLog::_Internal {
 public:
  static const ::tensorflow::serving::SessionRunRequest& request(const SessionRunLog* msg);
  static const ::tensorflow::serving::SessionRunResponse& response(const SessionRunLog* msg);
};

const ::tensorflow::serving::SessionRunRequest&
SessionRunLog::_Internal::request(const SessionRunLog* msg) {
  return *msg->_impl_.request_;
}
const ::tensorflow::serving::SessionRunResponse&
SessionRunLog::_Internal::response(const SessionRunLog* msg) {
  return *msg->_impl_.response_;
}
void SessionRunLog::clear_request() {
  if (GetArenaForAllocation() == nullptr && _impl_.request_ != nullptr) {
    delete _impl_.request_;
  }
  _impl_.request_ = nullptr;
}
void SessionRunLog::clear_response() {
  if (GetArenaForAllocation() == nullptr && _impl_.response_ != nullptr) {
    delete _impl_.response_;
  }
  _impl_.response_ = nullptr;
}
SessionRunLog::SessionRunLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.SessionRunLog)
}
SessionRunLog::SessionRunLog(const SessionRunLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  SessionRunLog* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){nullptr}
    , decltype(_impl_.response_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_request()) {
    _this->_impl_.request_ = new ::tensorflow::serving::SessionRunRequest(*from._impl_.request_);
  }
  if (from._internal_has_response()) {
    _this->_impl_.response_ = new ::tensorflow::serving::SessionRunResponse(*from._impl_.response_);
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.SessionRunLog)
}

inline void SessionRunLog::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.request_){nullptr}
    , decltype(_impl_.response_){nullptr}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

SessionRunLog::~SessionRunLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.SessionRunLog)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void SessionRunLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete _impl_.request_;
  if (this != internal_default_instance()) delete _impl_.response_;
}

void SessionRunLog::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void SessionRunLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.SessionRunLog)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && _impl_.request_ != nullptr) {
    delete _impl_.request_;
  }
  _impl_.request_ = nullptr;
  if (GetArenaForAllocation() == nullptr && _impl_.response_ != nullptr) {
    delete _impl_.response_;
  }
  _impl_.response_ = nullptr;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* SessionRunLog::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.serving.SessionRunRequest request = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_request(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.SessionRunResponse response = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_response(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* SessionRunLog::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.SessionRunLog)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.SessionRunRequest request = 1;
  if (this->_internal_has_request()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, _Internal::request(this),
        _Internal::request(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.SessionRunResponse response = 2;
  if (this->_internal_has_response()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::response(this),
        _Internal::response(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.SessionRunLog)
  return target;
}

size_t SessionRunLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.SessionRunLog)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.SessionRunRequest request = 1;
  if (this->_internal_has_request()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.request_);
  }

  // .tensorflow.serving.SessionRunResponse response = 2;
  if (this->_internal_has_response()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.response_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData SessionRunLog::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    SessionRunLog::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*SessionRunLog::GetClassData() const { return &_class_data_; }


void SessionRunLog::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<SessionRunLog*>(&to_msg);
  auto& from = static_cast<const SessionRunLog&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.SessionRunLog)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_request()) {
    _this->_internal_mutable_request()->::tensorflow::serving::SessionRunRequest::MergeFrom(
        from._internal_request());
  }
  if (from._internal_has_response()) {
    _this->_internal_mutable_response()->::tensorflow::serving::SessionRunResponse::MergeFrom(
        from._internal_response());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void SessionRunLog::CopyFrom(const SessionRunLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.SessionRunLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SessionRunLog::IsInitialized() const {
  return true;
}

void SessionRunLog::InternalSwap(SessionRunLog* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(SessionRunLog, _impl_.response_)
      + sizeof(SessionRunLog::_impl_.response_)
      - PROTOBUF_FIELD_OFFSET(SessionRunLog, _impl_.request_)>(
          reinterpret_cast<char*>(&_impl_.request_),
          reinterpret_cast<char*>(&other->_impl_.request_));
}

::PROTOBUF_NAMESPACE_ID::Metadata SessionRunLog::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[5]);
}

// ===================================================================

class PredictionLog::_Internal {
 public:
  static const ::tensorflow::serving::LogMetadata& log_metadata(const PredictionLog* msg);
  static const ::tensorflow::serving::ClassifyLog& classify_log(const PredictionLog* msg);
  static const ::tensorflow::serving::RegressLog& regress_log(const PredictionLog* msg);
  static const ::tensorflow::serving::PredictLog& predict_log(const PredictionLog* msg);
  static const ::tensorflow::serving::PredictStreamedLog& predict_streamed_log(const PredictionLog* msg);
  static const ::tensorflow::serving::MultiInferenceLog& multi_inference_log(const PredictionLog* msg);
  static const ::tensorflow::serving::SessionRunLog& session_run_log(const PredictionLog* msg);
};

const ::tensorflow::serving::LogMetadata&
PredictionLog::_Internal::log_metadata(const PredictionLog* msg) {
  return *msg->_impl_.log_metadata_;
}
const ::tensorflow::serving::ClassifyLog&
PredictionLog::_Internal::classify_log(const PredictionLog* msg) {
  return *msg->_impl_.log_type_.classify_log_;
}
const ::tensorflow::serving::RegressLog&
PredictionLog::_Internal::regress_log(const PredictionLog* msg) {
  return *msg->_impl_.log_type_.regress_log_;
}
const ::tensorflow::serving::PredictLog&
PredictionLog::_Internal::predict_log(const PredictionLog* msg) {
  return *msg->_impl_.log_type_.predict_log_;
}
const ::tensorflow::serving::PredictStreamedLog&
PredictionLog::_Internal::predict_streamed_log(const PredictionLog* msg) {
  return *msg->_impl_.log_type_.predict_streamed_log_;
}
const ::tensorflow::serving::MultiInferenceLog&
PredictionLog::_Internal::multi_inference_log(const PredictionLog* msg) {
  return *msg->_impl_.log_type_.multi_inference_log_;
}
const ::tensorflow::serving::SessionRunLog&
PredictionLog::_Internal::session_run_log(const PredictionLog* msg) {
  return *msg->_impl_.log_type_.session_run_log_;
}
void PredictionLog::clear_log_metadata() {
  if (GetArenaForAllocation() == nullptr && _impl_.log_metadata_ != nullptr) {
    delete _impl_.log_metadata_;
  }
  _impl_.log_metadata_ = nullptr;
}
void PredictionLog::set_allocated_classify_log(::tensorflow::serving::ClassifyLog* classify_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_log_type();
  if (classify_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(classify_log);
    if (message_arena != submessage_arena) {
      classify_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, classify_log, submessage_arena);
    }
    set_has_classify_log();
    _impl_.log_type_.classify_log_ = classify_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.classify_log)
}
void PredictionLog::set_allocated_regress_log(::tensorflow::serving::RegressLog* regress_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_log_type();
  if (regress_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(regress_log);
    if (message_arena != submessage_arena) {
      regress_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, regress_log, submessage_arena);
    }
    set_has_regress_log();
    _impl_.log_type_.regress_log_ = regress_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.regress_log)
}
void PredictionLog::set_allocated_predict_log(::tensorflow::serving::PredictLog* predict_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_log_type();
  if (predict_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(predict_log);
    if (message_arena != submessage_arena) {
      predict_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, predict_log, submessage_arena);
    }
    set_has_predict_log();
    _impl_.log_type_.predict_log_ = predict_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.predict_log)
}
void PredictionLog::set_allocated_predict_streamed_log(::tensorflow::serving::PredictStreamedLog* predict_streamed_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_log_type();
  if (predict_streamed_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(predict_streamed_log);
    if (message_arena != submessage_arena) {
      predict_streamed_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, predict_streamed_log, submessage_arena);
    }
    set_has_predict_streamed_log();
    _impl_.log_type_.predict_streamed_log_ = predict_streamed_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.predict_streamed_log)
}
void PredictionLog::set_allocated_multi_inference_log(::tensorflow::serving::MultiInferenceLog* multi_inference_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_log_type();
  if (multi_inference_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(multi_inference_log);
    if (message_arena != submessage_arena) {
      multi_inference_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, multi_inference_log, submessage_arena);
    }
    set_has_multi_inference_log();
    _impl_.log_type_.multi_inference_log_ = multi_inference_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.multi_inference_log)
}
void PredictionLog::set_allocated_session_run_log(::tensorflow::serving::SessionRunLog* session_run_log) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_log_type();
  if (session_run_log) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(session_run_log);
    if (message_arena != submessage_arena) {
      session_run_log = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, session_run_log, submessage_arena);
    }
    set_has_session_run_log();
    _impl_.log_type_.session_run_log_ = session_run_log;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.session_run_log)
}
PredictionLog::PredictionLog(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.PredictionLog)
}
PredictionLog::PredictionLog(const PredictionLog& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  PredictionLog* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.log_metadata_){nullptr}
    , decltype(_impl_.log_type_){}
    , /*decltype(_impl_._cached_size_)*/{}
    , /*decltype(_impl_._oneof_case_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_log_metadata()) {
    _this->_impl_.log_metadata_ = new ::tensorflow::serving::LogMetadata(*from._impl_.log_metadata_);
  }
  clear_has_log_type();
  switch (from.log_type_case()) {
    case kClassifyLog: {
      _this->_internal_mutable_classify_log()->::tensorflow::serving::ClassifyLog::MergeFrom(
          from._internal_classify_log());
      break;
    }
    case kRegressLog: {
      _this->_internal_mutable_regress_log()->::tensorflow::serving::RegressLog::MergeFrom(
          from._internal_regress_log());
      break;
    }
    case kPredictLog: {
      _this->_internal_mutable_predict_log()->::tensorflow::serving::PredictLog::MergeFrom(
          from._internal_predict_log());
      break;
    }
    case kPredictStreamedLog: {
      _this->_internal_mutable_predict_streamed_log()->::tensorflow::serving::PredictStreamedLog::MergeFrom(
          from._internal_predict_streamed_log());
      break;
    }
    case kMultiInferenceLog: {
      _this->_internal_mutable_multi_inference_log()->::tensorflow::serving::MultiInferenceLog::MergeFrom(
          from._internal_multi_inference_log());
      break;
    }
    case kSessionRunLog: {
      _this->_internal_mutable_session_run_log()->::tensorflow::serving::SessionRunLog::MergeFrom(
          from._internal_session_run_log());
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.PredictionLog)
}

inline void PredictionLog::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.log_metadata_){nullptr}
    , decltype(_impl_.log_type_){}
    , /*decltype(_impl_._cached_size_)*/{}
    , /*decltype(_impl_._oneof_case_)*/{}
  };
  clear_has_log_type();
}

PredictionLog::~PredictionLog() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.PredictionLog)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void PredictionLog::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete _impl_.log_metadata_;
  if (has_log_type()) {
    clear_log_type();
  }
}

void PredictionLog::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void PredictionLog::clear_log_type() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.serving.PredictionLog)
  switch (log_type_case()) {
    case kClassifyLog: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.log_type_.classify_log_;
      }
      break;
    }
    case kRegressLog: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.log_type_.regress_log_;
      }
      break;
    }
    case kPredictLog: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.log_type_.predict_log_;
      }
      break;
    }
    case kPredictStreamedLog: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.log_type_.predict_streamed_log_;
      }
      break;
    }
    case kMultiInferenceLog: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.log_type_.multi_inference_log_;
      }
      break;
    }
    case kSessionRunLog: {
      if (GetArenaForAllocation() == nullptr) {
        delete _impl_.log_type_.session_run_log_;
      }
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = LOG_TYPE_NOT_SET;
}


void PredictionLog::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.PredictionLog)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && _impl_.log_metadata_ != nullptr) {
    delete _impl_.log_metadata_;
  }
  _impl_.log_metadata_ = nullptr;
  clear_log_type();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* PredictionLog::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .tensorflow.serving.LogMetadata log_metadata = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_log_metadata(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.ClassifyLog classify_log = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_classify_log(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.RegressLog regress_log = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ctx->ParseMessage(_internal_mutable_regress_log(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          ptr = ctx->ParseMessage(_internal_mutable_multi_inference_log(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.SessionRunLog session_run_log = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 42)) {
          ptr = ctx->ParseMessage(_internal_mutable_session_run_log(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.PredictLog predict_log = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 50)) {
          ptr = ctx->ParseMessage(_internal_mutable_predict_log(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .tensorflow.serving.PredictStreamedLog predict_streamed_log = 7;
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 58)) {
          ptr = ctx->ParseMessage(_internal_mutable_predict_streamed_log(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* PredictionLog::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.PredictionLog)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .tensorflow.serving.LogMetadata log_metadata = 1;
  if (this->_internal_has_log_metadata()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, _Internal::log_metadata(this),
        _Internal::log_metadata(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.ClassifyLog classify_log = 2;
  if (_internal_has_classify_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::classify_log(this),
        _Internal::classify_log(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.RegressLog regress_log = 3;
  if (_internal_has_regress_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(3, _Internal::regress_log(this),
        _Internal::regress_log(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
  if (_internal_has_multi_inference_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(4, _Internal::multi_inference_log(this),
        _Internal::multi_inference_log(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.SessionRunLog session_run_log = 5;
  if (_internal_has_session_run_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(5, _Internal::session_run_log(this),
        _Internal::session_run_log(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.PredictLog predict_log = 6;
  if (_internal_has_predict_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(6, _Internal::predict_log(this),
        _Internal::predict_log(this).GetCachedSize(), target, stream);
  }

  // .tensorflow.serving.PredictStreamedLog predict_streamed_log = 7;
  if (_internal_has_predict_streamed_log()) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(7, _Internal::predict_streamed_log(this),
        _Internal::predict_streamed_log(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.PredictionLog)
  return target;
}

size_t PredictionLog::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.PredictionLog)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .tensorflow.serving.LogMetadata log_metadata = 1;
  if (this->_internal_has_log_metadata()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *_impl_.log_metadata_);
  }

  switch (log_type_case()) {
    // .tensorflow.serving.ClassifyLog classify_log = 2;
    case kClassifyLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.log_type_.classify_log_);
      break;
    }
    // .tensorflow.serving.RegressLog regress_log = 3;
    case kRegressLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.log_type_.regress_log_);
      break;
    }
    // .tensorflow.serving.PredictLog predict_log = 6;
    case kPredictLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.log_type_.predict_log_);
      break;
    }
    // .tensorflow.serving.PredictStreamedLog predict_streamed_log = 7;
    case kPredictStreamedLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.log_type_.predict_streamed_log_);
      break;
    }
    // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
    case kMultiInferenceLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.log_type_.multi_inference_log_);
      break;
    }
    // .tensorflow.serving.SessionRunLog session_run_log = 5;
    case kSessionRunLog: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *_impl_.log_type_.session_run_log_);
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData PredictionLog::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    PredictionLog::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*PredictionLog::GetClassData() const { return &_class_data_; }


void PredictionLog::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<PredictionLog*>(&to_msg);
  auto& from = static_cast<const PredictionLog&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.PredictionLog)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_log_metadata()) {
    _this->_internal_mutable_log_metadata()->::tensorflow::serving::LogMetadata::MergeFrom(
        from._internal_log_metadata());
  }
  switch (from.log_type_case()) {
    case kClassifyLog: {
      _this->_internal_mutable_classify_log()->::tensorflow::serving::ClassifyLog::MergeFrom(
          from._internal_classify_log());
      break;
    }
    case kRegressLog: {
      _this->_internal_mutable_regress_log()->::tensorflow::serving::RegressLog::MergeFrom(
          from._internal_regress_log());
      break;
    }
    case kPredictLog: {
      _this->_internal_mutable_predict_log()->::tensorflow::serving::PredictLog::MergeFrom(
          from._internal_predict_log());
      break;
    }
    case kPredictStreamedLog: {
      _this->_internal_mutable_predict_streamed_log()->::tensorflow::serving::PredictStreamedLog::MergeFrom(
          from._internal_predict_streamed_log());
      break;
    }
    case kMultiInferenceLog: {
      _this->_internal_mutable_multi_inference_log()->::tensorflow::serving::MultiInferenceLog::MergeFrom(
          from._internal_multi_inference_log());
      break;
    }
    case kSessionRunLog: {
      _this->_internal_mutable_session_run_log()->::tensorflow::serving::SessionRunLog::MergeFrom(
          from._internal_session_run_log());
      break;
    }
    case LOG_TYPE_NOT_SET: {
      break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void PredictionLog::CopyFrom(const PredictionLog& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.PredictionLog)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool PredictionLog::IsInitialized() const {
  return true;
}

void PredictionLog::InternalSwap(PredictionLog* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.log_metadata_, other->_impl_.log_metadata_);
  swap(_impl_.log_type_, other->_impl_.log_type_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::PROTOBUF_NAMESPACE_ID::Metadata PredictionLog::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_getter, &descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_once,
      file_level_metadata_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto[6]);
}

// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::tensorflow::serving::ClassifyLog*
Arena::CreateMaybeMessage< ::tensorflow::serving::ClassifyLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::ClassifyLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::RegressLog*
Arena::CreateMaybeMessage< ::tensorflow::serving::RegressLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::RegressLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictLog*
Arena::CreateMaybeMessage< ::tensorflow::serving::PredictLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictStreamedLog*
Arena::CreateMaybeMessage< ::tensorflow::serving::PredictStreamedLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictStreamedLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::MultiInferenceLog*
Arena::CreateMaybeMessage< ::tensorflow::serving::MultiInferenceLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::MultiInferenceLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::SessionRunLog*
Arena::CreateMaybeMessage< ::tensorflow::serving::SessionRunLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::SessionRunLog >(arena);
}
template<> PROTOBUF_NOINLINE ::tensorflow::serving::PredictionLog*
Arena::CreateMaybeMessage< ::tensorflow::serving::PredictionLog >(Arena* arena) {
  return Arena::CreateMessageInternal< ::tensorflow::serving::PredictionLog >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
